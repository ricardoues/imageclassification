{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Image Classification\n",
    "In this project, you'll classify images from the [CIFAR-10 dataset](https://www.cs.toronto.edu/~kriz/cifar.html).  The dataset consists of airplanes, dogs, cats, and other objects. You'll preprocess the images, then train a convolutional neural network on all the samples. The images need to be normalized and the labels need to be one-hot encoded.  You'll get to apply what you learned and build a convolutional, max pooling, dropout, and fully connected layers.  At the end, you'll get to see your neural network's predictions on the sample images.\n",
    "## Get the Data\n",
    "Run the following cell to download the [CIFAR-10 dataset for python](https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CIFAR-10 Dataset: 171MB [00:31, 5.42MB/s]                              \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All files found!\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "from urllib.request import urlretrieve\n",
    "from os.path import isfile, isdir\n",
    "from tqdm import tqdm\n",
    "import problem_unittests as tests\n",
    "import tarfile\n",
    "\n",
    "cifar10_dataset_folder_path = 'cifar-10-batches-py'\n",
    "\n",
    "# Use Floyd's cifar-10 dataset if present\n",
    "floyd_cifar10_location = '/input/cifar-10/python.tar.gz'\n",
    "if isfile(floyd_cifar10_location):\n",
    "    tar_gz_path = floyd_cifar10_location\n",
    "else:\n",
    "    tar_gz_path = 'cifar-10-python.tar.gz'\n",
    "\n",
    "class DLProgress(tqdm):\n",
    "    last_block = 0\n",
    "\n",
    "    def hook(self, block_num=1, block_size=1, total_size=None):\n",
    "        self.total = total_size\n",
    "        self.update((block_num - self.last_block) * block_size)\n",
    "        self.last_block = block_num\n",
    "\n",
    "if not isfile(tar_gz_path):\n",
    "    with DLProgress(unit='B', unit_scale=True, miniters=1, desc='CIFAR-10 Dataset') as pbar:\n",
    "        urlretrieve(\n",
    "            'https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz',\n",
    "            tar_gz_path,\n",
    "            pbar.hook)\n",
    "\n",
    "if not isdir(cifar10_dataset_folder_path):\n",
    "    with tarfile.open(tar_gz_path) as tar:\n",
    "        tar.extractall()\n",
    "        tar.close()\n",
    "\n",
    "\n",
    "tests.test_folder_path(cifar10_dataset_folder_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Explore the Data\n",
    "The dataset is broken into batches to prevent your machine from running out of memory.  The CIFAR-10 dataset consists of 5 batches, named `data_batch_1`, `data_batch_2`, etc.. Each batch contains the labels and images that are one of the following:\n",
    "* airplane\n",
    "* automobile\n",
    "* bird\n",
    "* cat\n",
    "* deer\n",
    "* dog\n",
    "* frog\n",
    "* horse\n",
    "* ship\n",
    "* truck\n",
    "\n",
    "Understanding a dataset is part of making predictions on the data.  Play around with the code cell below by changing the `batch_id` and `sample_id`. The `batch_id` is the id for a batch (1-5). The `sample_id` is the id for a image and label pair in the batch.\n",
    "\n",
    "Ask yourself \"What are all possible labels?\", \"What is the range of values for the image data?\", \"Are the labels in order or random?\".  Answers to questions like these will help you preprocess the data and end up with better predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Stats of batch 1:\n",
      "Samples: 10000\n",
      "Label Counts: {0: 1005, 1: 974, 2: 1032, 3: 1016, 4: 999, 5: 937, 6: 1030, 7: 1001, 8: 1025, 9: 981}\n",
      "First 20 Labels: [6, 9, 9, 4, 1, 1, 2, 7, 8, 3, 4, 7, 7, 2, 9, 9, 9, 3, 2, 6]\n",
      "\n",
      "Example of Image 71:\n",
      "Image - Min Value: 0 Max Value: 255\n",
      "Image - Shape: (32, 32, 3)\n",
      "Label - Label Id: 9 Name: truck\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfoAAAH0CAYAAADVH+85AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f589c658a90>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 250,
       "width": 253
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import helper\n",
    "import numpy as np\n",
    "\n",
    "# Explore the dataset\n",
    "#batch_id = 1\n",
    "#sample_id = 5\n",
    "batch_id = 1\n",
    "sample_id = 71\n",
    "helper.display_stats(cifar10_dataset_folder_path, batch_id, sample_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Implement Preprocess Functions\n",
    "### Normalize\n",
    "In the cell below, implement the `normalize` function to take in image data, `x`, and return it as a normalized Numpy array. The values should be in the range of 0 to 1, inclusive.  The return object should be the same shape as `x`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def normalize(x):\n",
    "    \"\"\"\n",
    "    Normalize a list of sample image data in the range of 0 to 1\n",
    "    : x: List of image data.  The image shape is (32, 32, 3)\n",
    "    : return: Numpy array of normalize data\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    a = 0\n",
    "    b = 1\n",
    "    grayscale_min = 0\n",
    "    grayscale_max = 255\n",
    "    return a + ( ( (x - grayscale_min)*(b - a) )/( grayscale_max - grayscale_min ) )\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_normalize(normalize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### One-hot encode\n",
    "Just like the previous code cell, you'll be implementing a function for preprocessing.  This time, you'll implement the `one_hot_encode` function. The input, `x`, are a list of labels.  Implement the function to return the list of labels as One-Hot encoded Numpy array.  The possible values for labels are 0 to 9. The one-hot encoding function should return the same encoding for each value between each call to `one_hot_encode`.  Make sure to save the map of encodings outside the function.\n",
    "\n",
    "Hint: Don't reinvent the wheel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "x = [0,1,2,3,4,5,6,7,8,9]\n",
    "lb = preprocessing.LabelBinarizer()\n",
    "lb.fit(x)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def one_hot_encode(x):\n",
    "    \"\"\"\n",
    "    One hot encode a list of sample labels. Return a one-hot encoded vector for each label.\n",
    "    : x: List of sample Labels\n",
    "    : return: Numpy array of one-hot encoded labels\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    return(np.array(lb.transform(x)))\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_one_hot_encode(one_hot_encode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Randomize Data\n",
    "As you saw from exploring the data above, the order of the samples are randomized.  It doesn't hurt to randomize it again, but you don't need to for this dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Preprocess all the data and save it\n",
    "Running the code cell below will preprocess all the CIFAR-10 data and save it to file. The code below also uses 10% of the training data for validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "# Preprocess Training, Validation, and Testing Data\n",
    "helper.preprocess_and_save_data(cifar10_dataset_folder_path, normalize, one_hot_encode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Check Point\n",
    "This is your first checkpoint.  If you ever decide to come back to this notebook or have to restart the notebook, you can start from here.  The preprocessed data has been saved to disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "import pickle\n",
    "import problem_unittests as tests\n",
    "import helper\n",
    "\n",
    "# Load the Preprocessed Validation data\n",
    "valid_features, valid_labels = pickle.load(open('preprocess_validation.p', mode='rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Build the network\n",
    "For the neural network, you'll build each layer into a function.  Most of the code you've seen has been outside of functions. To test your code more thoroughly, we require that you put each layer in a function.  This allows us to give you better feedback and test for simple mistakes using our unittests before you submit your project.\n",
    "\n",
    ">**Note:** If you're finding it hard to dedicate enough time for this course each week, we've provided a small shortcut to this part of the project. In the next couple of problems, you'll have the option to use classes from the [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) or [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers) packages to build each layer, except the layers you build in the \"Convolutional and Max Pooling Layer\" section.  TF Layers is similar to Keras's and TFLearn's abstraction to layers, so it's easy to pickup.\n",
    "\n",
    ">However, if you would like to get the most out of this course, try to solve all the problems _without_ using anything from the TF Layers packages. You **can** still use classes from other packages that happen to have the same name as ones you find in TF Layers! For example, instead of using the TF Layers version of the `conv2d` class, [tf.layers.conv2d](https://www.tensorflow.org/api_docs/python/tf/layers/conv2d), you would want to use the TF Neural Network version of `conv2d`, [tf.nn.conv2d](https://www.tensorflow.org/api_docs/python/tf/nn/conv2d). \n",
    "\n",
    "Let's begin!\n",
    "\n",
    "### Input\n",
    "The neural network needs to read the image data, one-hot encoded labels, and dropout keep probability. Implement the following functions\n",
    "* Implement `neural_net_image_input`\n",
    " * Return a [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder)\n",
    " * Set the shape using `image_shape` with batch size set to `None`.\n",
    " * Name the TensorFlow placeholder \"x\" using the TensorFlow `name` parameter in the [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder).\n",
    "* Implement `neural_net_label_input`\n",
    " * Return a [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder)\n",
    " * Set the shape using `n_classes` with batch size set to `None`.\n",
    " * Name the TensorFlow placeholder \"y\" using the TensorFlow `name` parameter in the [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder).\n",
    "* Implement `neural_net_keep_prob_input`\n",
    " * Return a [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder) for dropout keep probability.\n",
    " * Name the TensorFlow placeholder \"keep_prob\" using the TensorFlow `name` parameter in the [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder).\n",
    "\n",
    "These names will be used at the end of the project to load your saved model.\n",
    "\n",
    "Note: `None` for shapes in TensorFlow allow for a dynamic size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image Input Tests Passed.\n",
      "Label Input Tests Passed.\n",
      "Keep Prob Tests Passed.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def neural_net_image_input(image_shape):\n",
    "    \"\"\"\n",
    "    Return a Tensor for a batch of image input\n",
    "    : image_shape: Shape of the images\n",
    "    : return: Tensor for image input.\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    #return None\n",
    "    return(tf.placeholder(tf.float32, shape=[None, image_shape[0], image_shape[1], image_shape[2] ], name=\"x\"))\n",
    "\n",
    "\n",
    "def neural_net_label_input(n_classes):\n",
    "    \"\"\"\n",
    "    Return a Tensor for a batch of label input\n",
    "    : n_classes: Number of classes\n",
    "    : return: Tensor for label input.\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    #return None\n",
    "    return(tf.placeholder(tf.float32, [None, n_classes], name=\"y\"))\n",
    "\n",
    "\n",
    "def neural_net_keep_prob_input():\n",
    "    \"\"\"\n",
    "    Return a Tensor for keep probability\n",
    "    : return: Tensor for keep probability.\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    #return None\n",
    "    return(tf.placeholder(tf.float32, name=\"keep_prob\"))\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tf.reset_default_graph()\n",
    "tests.test_nn_image_inputs(neural_net_image_input)\n",
    "tests.test_nn_label_inputs(neural_net_label_input)\n",
    "tests.test_nn_keep_prob_inputs(neural_net_keep_prob_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Convolution and Max Pooling Layer\n",
    "Convolution layers have a lot of success with images. For this code cell, you should implement the function `conv2d_maxpool` to apply convolution then max pooling:\n",
    "* Create the weight and bias using `conv_ksize`, `conv_num_outputs` and the shape of `x_tensor`.\n",
    "* Apply a convolution to `x_tensor` using weight and `conv_strides`.\n",
    " * We recommend you use same padding, but you're welcome to use any padding.\n",
    "* Add bias\n",
    "* Add a nonlinear activation to the convolution.\n",
    "* Apply Max Pooling using `pool_ksize` and `pool_strides`.\n",
    " * We recommend you use same padding, but you're welcome to use any padding.\n",
    "\n",
    "**Note:** You **can't** use [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) or [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers) for **this** layer, but you can still use TensorFlow's [Neural Network](https://www.tensorflow.org/api_docs/python/tf/nn) package. You may still use the shortcut option for all the **other** layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def conv2d_maxpool(x_tensor, conv_num_outputs, conv_ksize, conv_strides, pool_ksize, pool_strides):\n",
    "    \"\"\"\n",
    "    Apply convolution then max pooling to x_tensor\n",
    "    :param x_tensor: TensorFlow Tensor\n",
    "    :param conv_num_outputs: Number of outputs for the convolutional layer\n",
    "    :param conv_ksize: kernal size 2-D Tuple for the convolutional layer\n",
    "    :param conv_strides: Stride 2-D Tuple for convolution\n",
    "    :param pool_ksize: kernal size 2-D Tuple for pool\n",
    "    :param pool_strides: Stride 2-D Tuple for pool\n",
    "    : return: A tensor that represents convolution and max pooling of x_tensor\n",
    "    \"\"\"\n",
    "        \n",
    "    \n",
    "    # TODO: Implement Function\n",
    "    \n",
    "    weight = tf.Variable(tf.truncated_normal([conv_ksize[0], conv_ksize[1], x_tensor.get_shape().as_list()[3], conv_num_outputs], stddev=0.01))\n",
    "    \n",
    "    bias = tf.Variable(tf.zeros(conv_num_outputs))\n",
    "                \n",
    "    \n",
    "    # Apply Convolution \n",
    "    conv_layer = tf.nn.conv2d(x_tensor, weight, strides = [1, conv_strides[0], conv_strides[1], 1], padding='SAME')\n",
    "    \n",
    "    ## Add bias\n",
    "    conv_layer = tf.nn.bias_add(conv_layer, bias)\n",
    "    ## Apply nonlinear activation function\n",
    "    conv_layer = tf.nn.relu(conv_layer)\n",
    "    ## Apply Max Pooling\n",
    "    conv_layer = tf.nn.max_pool(conv_layer, ksize=[1, pool_ksize[0], pool_ksize[1], 1], strides=[1, pool_strides[0], pool_strides[1], 1], padding='SAME')\n",
    "    \n",
    "    return(conv_layer)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_con_pool(conv2d_maxpool)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Flatten Layer\n",
    "Implement the `flatten` function to change the dimension of `x_tensor` from a 4-D tensor to a 2-D tensor.  The output should be the shape (*Batch Size*, *Flattened Image Size*). Shortcut option: you can use classes from the [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) or [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers) packages for this layer. For more of a challenge, only use other TensorFlow packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def flatten(x_tensor):\n",
    "    \"\"\"\n",
    "    Flatten x_tensor to (Batch Size, Flattened Image Size)\n",
    "    : x_tensor: A tensor of size (Batch Size, ...), where ... are the image dimensions.\n",
    "    : return: A tensor of size (Batch Size, Flattened Image Size).\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    \n",
    "    flattened_img_size = x_tensor.get_shape().as_list()[1] * x_tensor.get_shape().as_list()[2] * x_tensor.get_shape().as_list()[3]\n",
    "    \n",
    "    return(tf.reshape(x_tensor, [-1, flattened_img_size]))\n",
    "    \n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_flatten(flatten)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Fully-Connected Layer\n",
    "Implement the `fully_conn` function to apply a fully connected layer to `x_tensor` with the shape (*Batch Size*, *num_outputs*). Shortcut option: you can use classes from the [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) or [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers) packages for this layer. For more of a challenge, only use other TensorFlow packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def fully_conn(x_tensor, num_outputs):\n",
    "    \"\"\"\n",
    "    Apply a fully connected layer to x_tensor using weight and bias\n",
    "    : x_tensor: A 2-D tensor where the first dimension is batch size.\n",
    "    : num_outputs: The number of output that the new tensor should be.\n",
    "    : return: A 2-D tensor where the second dimension is num_outputs.\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    \n",
    "    weights = tf.Variable(tf.truncated_normal([x_tensor.get_shape().as_list()[1], num_outputs], stddev=0.01))\n",
    "    biases = tf.Variable(tf.zeros(num_outputs))\n",
    "\n",
    "    \n",
    "    ## Fully Connected Layer\n",
    "    fc = tf.add(tf.matmul(x_tensor, weights), biases)\n",
    "    fc = tf.nn.relu(fc)\n",
    "\n",
    "        \n",
    "    return(fc)\n",
    "    \n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_fully_conn(fully_conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Output Layer\n",
    "Implement the `output` function to apply a fully connected layer to `x_tensor` with the shape (*Batch Size*, *num_outputs*). Shortcut option: you can use classes from the [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) or [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers) packages for this layer. For more of a challenge, only use other TensorFlow packages.\n",
    "\n",
    "**Note:** Activation, softmax, or cross entropy should **not** be applied to this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def output(x_tensor, num_outputs):\n",
    "    \"\"\"\n",
    "    Apply a output layer to x_tensor using weight and bias\n",
    "    : x_tensor: A 2-D tensor where the first dimension is batch size.\n",
    "    : num_outputs: The number of output that the new tensor should be.\n",
    "    : return: A 2-D tensor where the second dimension is num_outputs.\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "\n",
    "    weights = tf.Variable(tf.truncated_normal([x_tensor.get_shape().as_list()[1], num_outputs], stddev=0.01))\n",
    "    biases = tf.Variable(tf.zeros(num_outputs))\n",
    "    \n",
    "    ## Output Layer\n",
    "    out = tf.add(tf.matmul(x_tensor, weights), biases)\n",
    "    \n",
    "    return(out)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_output(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Create Convolutional Model\n",
    "Implement the function `conv_net` to create a convolutional neural network model. The function takes in a batch of images, `x`, and outputs logits.  Use the layers you created above to create this model:\n",
    "\n",
    "* Apply 1, 2, or 3 Convolution and Max Pool layers\n",
    "* Apply a Flatten Layer\n",
    "* Apply 1, 2, or 3 Fully Connected Layers\n",
    "* Apply an Output Layer\n",
    "* Return the output\n",
    "* Apply [TensorFlow's Dropout](https://www.tensorflow.org/api_docs/python/tf/nn/dropout) to one or more layers in the model using `keep_prob`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural Network Built!\n"
     ]
    }
   ],
   "source": [
    "def conv_net(x, keep_prob):\n",
    "    \"\"\"\n",
    "    Create a convolutional neural network model\n",
    "    : x: Placeholder tensor that holds image data.\n",
    "    : keep_prob: Placeholder tensor that hold dropout keep probability.\n",
    "    : return: Tensor that represents logits\n",
    "    \"\"\"\n",
    "    # TODO: Apply 1, 2, or 3 Convolution and Max Pool layers\n",
    "    #    Play around with different number of outputs, kernel size and stride\n",
    "    # Function Definition from Above:\n",
    "    #    conv2d_maxpool(x_tensor, conv_num_outputs, conv_ksize, conv_strides, pool_ksize, pool_strides)\n",
    "    \n",
    "    conv_num_outputs = 10\n",
    "    \n",
    "    conv_ksize = (10,10)\n",
    "    conv_strides = (1,1)    \n",
    "    pool_ksize = (10,10)\n",
    "    pool_strides = (2,2)\n",
    "    \n",
    "    \n",
    "    conv1 = conv2d_maxpool(x, conv_num_outputs, conv_ksize, conv_strides, pool_ksize, pool_strides)\n",
    "        \n",
    "    conv_num_outputs = 20\n",
    "    conv_ksize = (5,5)\n",
    "    pool_ksize = (5,5)\n",
    "    \n",
    "    conv2 = conv2d_maxpool(conv1, conv_num_outputs, conv_ksize, conv_strides, pool_ksize, pool_strides)\n",
    "\n",
    "    conv_num_outputs = 30\n",
    "    conv_ksize = (2,2)\n",
    "    pool_ksize = (2,2)\n",
    "\n",
    "        \n",
    "    conv3 = conv2d_maxpool(conv2, conv_num_outputs, conv_ksize, conv_strides, pool_ksize, pool_strides)\n",
    "    \n",
    "    \n",
    "        \n",
    "\n",
    "    # TODO: Apply a Flatten Layer\n",
    "    # Function Definition from Above:\n",
    "    #   flatten(x_tensor)\n",
    "    conv3 = flatten(conv3)\n",
    "    \n",
    "    \n",
    "    # TODO: Apply 1, 2, or 3 Fully Connected Layers\n",
    "    #    Play around with different number of outputs\n",
    "    # Function Definition from Above:\n",
    "    #   fully_conn(x_tensor, num_outputs)\n",
    "    num_outputs = 10 \n",
    "    fc1 = fully_conn(conv3, num_outputs)\n",
    "    \n",
    "    ## Applying Drop Out\n",
    "    fc1 = tf.nn.dropout(fc1, keep_prob)\n",
    "    \n",
    "    # TODO: Apply an Output Layer\n",
    "    #    Set this to the number of classes\n",
    "    # Function Definition from Above:\n",
    "    #   output(x_tensor, num_outputs)\n",
    "    out = output(fc1, num_outputs)\n",
    "    \n",
    "    # TODO: return output\n",
    "    #return None\n",
    "    return(out)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "\n",
    "##############################\n",
    "## Build the Neural Network ##\n",
    "##############################\n",
    "\n",
    "# Remove previous weights, bias, inputs, etc..\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# Inputs\n",
    "x = neural_net_image_input((32, 32, 3))\n",
    "y = neural_net_label_input(10)\n",
    "keep_prob = neural_net_keep_prob_input()\n",
    "\n",
    "# Model\n",
    "logits = conv_net(x, keep_prob)\n",
    "\n",
    "# Name logits Tensor, so that is can be loaded from disk after training\n",
    "logits = tf.identity(logits, name='logits')\n",
    "\n",
    "# Loss and Optimizer\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=y))\n",
    "optimizer = tf.train.AdamOptimizer().minimize(cost)\n",
    "\n",
    "# Accuracy\n",
    "correct_pred = tf.equal(tf.argmax(logits, 1), tf.argmax(y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32), name='accuracy')\n",
    "\n",
    "tests.test_conv_net(conv_net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Train the Neural Network\n",
    "### Single Optimization\n",
    "Implement the function `train_neural_network` to do a single optimization.  The optimization should use `optimizer` to optimize in `session` with a `feed_dict` of the following:\n",
    "* `x` for image input\n",
    "* `y` for labels\n",
    "* `keep_prob` for keep probability for dropout\n",
    "\n",
    "This function will be called for each batch, so `tf.global_variables_initializer()` has already been called.\n",
    "\n",
    "Note: Nothing needs to be returned. This function is only optimizing the neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def train_neural_network(session, optimizer, keep_probability, feature_batch, label_batch):\n",
    "    \"\"\"\n",
    "    Optimize the session on a batch of images and labels\n",
    "    : session: Current TensorFlow session\n",
    "    : optimizer: TensorFlow optimizer function\n",
    "    : keep_probability: keep probability\n",
    "    : feature_batch: Batch of Numpy image data\n",
    "    : label_batch: Batch of Numpy label data\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    session.run(optimizer, feed_dict={x: feature_batch, y: label_batch, keep_prob: keep_probability})\n",
    "    \n",
    "    pass\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_train_nn(train_neural_network)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Show Stats\n",
    "Implement the function `print_stats` to print loss and validation accuracy.  Use the global variables `valid_features` and `valid_labels` to calculate validation accuracy.  Use a keep probability of `1.0` to calculate the loss and validation accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def print_stats(session, feature_batch, label_batch, cost, accuracy):\n",
    "    \"\"\"\n",
    "    Print information about loss and validation accuracy\n",
    "    : session: Current TensorFlow session\n",
    "    : feature_batch: Batch of Numpy image data\n",
    "    : label_batch: Batch of Numpy label data\n",
    "    : cost: TensorFlow cost function\n",
    "    : accuracy: TensorFlow accuracy function\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    \n",
    "    loss = session.run(cost, feed_dict={x: feature_batch, y: label_batch, keep_prob: 1.})\n",
    "    \n",
    "    valid_acc = sess.run(accuracy, feed_dict={\n",
    "        x: valid_features,\n",
    "        y: valid_labels,\n",
    "        keep_prob: 1.})\n",
    "    \n",
    "    \n",
    "    print('Loss: {:>10.4f} Validation Accuracy: {:.6f}'.format(loss, valid_acc))\n",
    "\n",
    "\n",
    "    \n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Hyperparameters\n",
    "Tune the following parameters:\n",
    "* Set `epochs` to the number of iterations until the network stops learning or start overfitting\n",
    "* Set `batch_size` to the highest number that your machine has memory for.  Most people set them to common sizes of memory:\n",
    " * 64\n",
    " * 128\n",
    " * 256\n",
    " * ...\n",
    "* Set `keep_probability` to the probability of keeping a node using dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# TODO: Tune Parameters\n",
    "#epochs = None\n",
    "#batch_size = None\n",
    "#keep_probability = None\n",
    "epochs = 500\n",
    "batch_size = 4096\n",
    "keep_probability = 0.95"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Train on a Single CIFAR-10 Batch\n",
    "Instead of training the neural network on all the CIFAR-10 batches of data, let's use a single batch. This should save time while you iterate on the model to get a better accuracy.  Once the final validation accuracy is 50% or greater, run the model on all the data in the next section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking the Training on a Single Batch...\n",
      "Epoch  1, CIFAR-10 Batch 1:  Loss:     2.3026 Validation Accuracy: 0.105000\n",
      "Epoch  2, CIFAR-10 Batch 1:  Loss:     2.3025 Validation Accuracy: 0.105000\n",
      "Epoch  3, CIFAR-10 Batch 1:  Loss:     2.3023 Validation Accuracy: 0.110400\n",
      "Epoch  4, CIFAR-10 Batch 1:  Loss:     2.3012 Validation Accuracy: 0.097600\n",
      "Epoch  5, CIFAR-10 Batch 1:  Loss:     2.2978 Validation Accuracy: 0.097800\n",
      "Epoch  6, CIFAR-10 Batch 1:  Loss:     2.2934 Validation Accuracy: 0.097800\n",
      "Epoch  7, CIFAR-10 Batch 1:  Loss:     2.2887 Validation Accuracy: 0.097600\n",
      "Epoch  8, CIFAR-10 Batch 1:  Loss:     2.2805 Validation Accuracy: 0.090400\n",
      "Epoch  9, CIFAR-10 Batch 1:  Loss:     2.2637 Validation Accuracy: 0.092600\n",
      "Epoch 10, CIFAR-10 Batch 1:  Loss:     2.2399 Validation Accuracy: 0.097000\n",
      "Epoch 11, CIFAR-10 Batch 1:  Loss:     2.2187 Validation Accuracy: 0.105000\n",
      "Epoch 12, CIFAR-10 Batch 1:  Loss:     2.2150 Validation Accuracy: 0.123400\n",
      "Epoch 13, CIFAR-10 Batch 1:  Loss:     2.2042 Validation Accuracy: 0.135800\n",
      "Epoch 14, CIFAR-10 Batch 1:  Loss:     2.1930 Validation Accuracy: 0.138000\n",
      "Epoch 15, CIFAR-10 Batch 1:  Loss:     2.1863 Validation Accuracy: 0.145200\n",
      "Epoch 16, CIFAR-10 Batch 1:  Loss:     2.1758 Validation Accuracy: 0.167800\n",
      "Epoch 17, CIFAR-10 Batch 1:  Loss:     2.1619 Validation Accuracy: 0.173800\n",
      "Epoch 18, CIFAR-10 Batch 1:  Loss:     2.1503 Validation Accuracy: 0.178200\n",
      "Epoch 19, CIFAR-10 Batch 1:  Loss:     2.1409 Validation Accuracy: 0.194200\n",
      "Epoch 20, CIFAR-10 Batch 1:  Loss:     2.1303 Validation Accuracy: 0.190600\n",
      "Epoch 21, CIFAR-10 Batch 1:  Loss:     2.1210 Validation Accuracy: 0.198600\n",
      "Epoch 22, CIFAR-10 Batch 1:  Loss:     2.1133 Validation Accuracy: 0.204200\n",
      "Epoch 23, CIFAR-10 Batch 1:  Loss:     2.1018 Validation Accuracy: 0.195400\n",
      "Epoch 24, CIFAR-10 Batch 1:  Loss:     2.0887 Validation Accuracy: 0.202200\n",
      "Epoch 25, CIFAR-10 Batch 1:  Loss:     2.0741 Validation Accuracy: 0.209000\n",
      "Epoch 26, CIFAR-10 Batch 1:  Loss:     2.0593 Validation Accuracy: 0.227600\n",
      "Epoch 27, CIFAR-10 Batch 1:  Loss:     2.0443 Validation Accuracy: 0.213800\n",
      "Epoch 28, CIFAR-10 Batch 1:  Loss:     2.0297 Validation Accuracy: 0.213800\n",
      "Epoch 29, CIFAR-10 Batch 1:  Loss:     2.0213 Validation Accuracy: 0.211800\n",
      "Epoch 30, CIFAR-10 Batch 1:  Loss:     2.0184 Validation Accuracy: 0.228400\n",
      "Epoch 31, CIFAR-10 Batch 1:  Loss:     2.0068 Validation Accuracy: 0.238200\n",
      "Epoch 32, CIFAR-10 Batch 1:  Loss:     1.9907 Validation Accuracy: 0.249200\n",
      "Epoch 33, CIFAR-10 Batch 1:  Loss:     1.9852 Validation Accuracy: 0.255000\n",
      "Epoch 34, CIFAR-10 Batch 1:  Loss:     1.9772 Validation Accuracy: 0.257000\n",
      "Epoch 35, CIFAR-10 Batch 1:  Loss:     1.9722 Validation Accuracy: 0.267800\n",
      "Epoch 36, CIFAR-10 Batch 1:  Loss:     1.9689 Validation Accuracy: 0.267800\n",
      "Epoch 37, CIFAR-10 Batch 1:  Loss:     1.9694 Validation Accuracy: 0.260200\n",
      "Epoch 38, CIFAR-10 Batch 1:  Loss:     1.9709 Validation Accuracy: 0.259800\n",
      "Epoch 39, CIFAR-10 Batch 1:  Loss:     1.9672 Validation Accuracy: 0.256200\n",
      "Epoch 40, CIFAR-10 Batch 1:  Loss:     1.9536 Validation Accuracy: 0.268600\n",
      "Epoch 41, CIFAR-10 Batch 1:  Loss:     1.9498 Validation Accuracy: 0.276200\n",
      "Epoch 42, CIFAR-10 Batch 1:  Loss:     1.9456 Validation Accuracy: 0.278200\n",
      "Epoch 43, CIFAR-10 Batch 1:  Loss:     1.9409 Validation Accuracy: 0.274600\n",
      "Epoch 44, CIFAR-10 Batch 1:  Loss:     1.9392 Validation Accuracy: 0.269000\n",
      "Epoch 45, CIFAR-10 Batch 1:  Loss:     1.9418 Validation Accuracy: 0.269000\n",
      "Epoch 46, CIFAR-10 Batch 1:  Loss:     1.9428 Validation Accuracy: 0.265400\n",
      "Epoch 47, CIFAR-10 Batch 1:  Loss:     1.9385 Validation Accuracy: 0.271800\n",
      "Epoch 48, CIFAR-10 Batch 1:  Loss:     1.9236 Validation Accuracy: 0.279000\n",
      "Epoch 49, CIFAR-10 Batch 1:  Loss:     1.9203 Validation Accuracy: 0.283000\n",
      "Epoch 50, CIFAR-10 Batch 1:  Loss:     1.9160 Validation Accuracy: 0.281600\n",
      "Epoch 51, CIFAR-10 Batch 1:  Loss:     1.9116 Validation Accuracy: 0.283600\n",
      "Epoch 52, CIFAR-10 Batch 1:  Loss:     1.9103 Validation Accuracy: 0.283200\n",
      "Epoch 53, CIFAR-10 Batch 1:  Loss:     1.9137 Validation Accuracy: 0.280800\n",
      "Epoch 54, CIFAR-10 Batch 1:  Loss:     1.9208 Validation Accuracy: 0.275800\n",
      "Epoch 55, CIFAR-10 Batch 1:  Loss:     1.9142 Validation Accuracy: 0.277800\n",
      "Epoch 56, CIFAR-10 Batch 1:  Loss:     1.8967 Validation Accuracy: 0.285800\n",
      "Epoch 57, CIFAR-10 Batch 1:  Loss:     1.8914 Validation Accuracy: 0.286800\n",
      "Epoch 58, CIFAR-10 Batch 1:  Loss:     1.8883 Validation Accuracy: 0.286200\n",
      "Epoch 59, CIFAR-10 Batch 1:  Loss:     1.8852 Validation Accuracy: 0.285800\n",
      "Epoch 60, CIFAR-10 Batch 1:  Loss:     1.8822 Validation Accuracy: 0.285600\n",
      "Epoch 61, CIFAR-10 Batch 1:  Loss:     1.8794 Validation Accuracy: 0.286400\n",
      "Epoch 62, CIFAR-10 Batch 1:  Loss:     1.8816 Validation Accuracy: 0.286000\n",
      "Epoch 63, CIFAR-10 Batch 1:  Loss:     1.8919 Validation Accuracy: 0.287000\n",
      "Epoch 64, CIFAR-10 Batch 1:  Loss:     1.8950 Validation Accuracy: 0.283600\n",
      "Epoch 65, CIFAR-10 Batch 1:  Loss:     1.8730 Validation Accuracy: 0.289600\n",
      "Epoch 66, CIFAR-10 Batch 1:  Loss:     1.8677 Validation Accuracy: 0.286800\n",
      "Epoch 67, CIFAR-10 Batch 1:  Loss:     1.8656 Validation Accuracy: 0.288600\n",
      "Epoch 68, CIFAR-10 Batch 1:  Loss:     1.8619 Validation Accuracy: 0.290800\n",
      "Epoch 69, CIFAR-10 Batch 1:  Loss:     1.8659 Validation Accuracy: 0.286200\n",
      "Epoch 70, CIFAR-10 Batch 1:  Loss:     1.8712 Validation Accuracy: 0.287200\n",
      "Epoch 71, CIFAR-10 Batch 1:  Loss:     1.8624 Validation Accuracy: 0.289000\n",
      "Epoch 72, CIFAR-10 Batch 1:  Loss:     1.8573 Validation Accuracy: 0.292200\n",
      "Epoch 73, CIFAR-10 Batch 1:  Loss:     1.8539 Validation Accuracy: 0.292200\n",
      "Epoch 74, CIFAR-10 Batch 1:  Loss:     1.8512 Validation Accuracy: 0.292800\n",
      "Epoch 75, CIFAR-10 Batch 1:  Loss:     1.8520 Validation Accuracy: 0.290600\n",
      "Epoch 76, CIFAR-10 Batch 1:  Loss:     1.8506 Validation Accuracy: 0.290800\n",
      "Epoch 77, CIFAR-10 Batch 1:  Loss:     1.8531 Validation Accuracy: 0.290800\n",
      "Epoch 78, CIFAR-10 Batch 1:  Loss:     1.8552 Validation Accuracy: 0.294800\n",
      "Epoch 79, CIFAR-10 Batch 1:  Loss:     1.8499 Validation Accuracy: 0.292600\n",
      "Epoch 80, CIFAR-10 Batch 1:  Loss:     1.8420 Validation Accuracy: 0.297400\n",
      "Epoch 81, CIFAR-10 Batch 1:  Loss:     1.8361 Validation Accuracy: 0.298800\n",
      "Epoch 82, CIFAR-10 Batch 1:  Loss:     1.8334 Validation Accuracy: 0.297800\n",
      "Epoch 83, CIFAR-10 Batch 1:  Loss:     1.8304 Validation Accuracy: 0.298600\n",
      "Epoch 84, CIFAR-10 Batch 1:  Loss:     1.8284 Validation Accuracy: 0.298000\n",
      "Epoch 85, CIFAR-10 Batch 1:  Loss:     1.8290 Validation Accuracy: 0.298600\n",
      "Epoch 86, CIFAR-10 Batch 1:  Loss:     1.8318 Validation Accuracy: 0.296600\n",
      "Epoch 87, CIFAR-10 Batch 1:  Loss:     1.8381 Validation Accuracy: 0.299400\n",
      "Epoch 88, CIFAR-10 Batch 1:  Loss:     1.8348 Validation Accuracy: 0.295000\n",
      "Epoch 89, CIFAR-10 Batch 1:  Loss:     1.8234 Validation Accuracy: 0.298600\n",
      "Epoch 90, CIFAR-10 Batch 1:  Loss:     1.8156 Validation Accuracy: 0.301600\n",
      "Epoch 91, CIFAR-10 Batch 1:  Loss:     1.8119 Validation Accuracy: 0.303200\n",
      "Epoch 92, CIFAR-10 Batch 1:  Loss:     1.8108 Validation Accuracy: 0.301400\n",
      "Epoch 93, CIFAR-10 Batch 1:  Loss:     1.8101 Validation Accuracy: 0.301400\n",
      "Epoch 94, CIFAR-10 Batch 1:  Loss:     1.8120 Validation Accuracy: 0.301800\n",
      "Epoch 95, CIFAR-10 Batch 1:  Loss:     1.8097 Validation Accuracy: 0.302800\n",
      "Epoch 96, CIFAR-10 Batch 1:  Loss:     1.8069 Validation Accuracy: 0.303600\n",
      "Epoch 97, CIFAR-10 Batch 1:  Loss:     1.8078 Validation Accuracy: 0.304800\n",
      "Epoch 98, CIFAR-10 Batch 1:  Loss:     1.8046 Validation Accuracy: 0.303000\n",
      "Epoch 99, CIFAR-10 Batch 1:  Loss:     1.8061 Validation Accuracy: 0.304400\n",
      "Epoch 100, CIFAR-10 Batch 1:  Loss:     1.8061 Validation Accuracy: 0.303600\n",
      "Epoch 101, CIFAR-10 Batch 1:  Loss:     1.8072 Validation Accuracy: 0.302800\n",
      "Epoch 102, CIFAR-10 Batch 1:  Loss:     1.8024 Validation Accuracy: 0.305400\n",
      "Epoch 103, CIFAR-10 Batch 1:  Loss:     1.7942 Validation Accuracy: 0.309000\n",
      "Epoch 104, CIFAR-10 Batch 1:  Loss:     1.7886 Validation Accuracy: 0.309400\n",
      "Epoch 105, CIFAR-10 Batch 1:  Loss:     1.7868 Validation Accuracy: 0.310000\n",
      "Epoch 106, CIFAR-10 Batch 1:  Loss:     1.7848 Validation Accuracy: 0.313400\n",
      "Epoch 107, CIFAR-10 Batch 1:  Loss:     1.7834 Validation Accuracy: 0.309000\n",
      "Epoch 108, CIFAR-10 Batch 1:  Loss:     1.7821 Validation Accuracy: 0.312200\n",
      "Epoch 109, CIFAR-10 Batch 1:  Loss:     1.7839 Validation Accuracy: 0.312600\n",
      "Epoch 110, CIFAR-10 Batch 1:  Loss:     1.7896 Validation Accuracy: 0.310600\n",
      "Epoch 111, CIFAR-10 Batch 1:  Loss:     1.7987 Validation Accuracy: 0.309800\n",
      "Epoch 112, CIFAR-10 Batch 1:  Loss:     1.8036 Validation Accuracy: 0.306600\n",
      "Epoch 113, CIFAR-10 Batch 1:  Loss:     1.7922 Validation Accuracy: 0.313400\n",
      "Epoch 114, CIFAR-10 Batch 1:  Loss:     1.7778 Validation Accuracy: 0.312200\n",
      "Epoch 115, CIFAR-10 Batch 1:  Loss:     1.7696 Validation Accuracy: 0.315800\n",
      "Epoch 116, CIFAR-10 Batch 1:  Loss:     1.7678 Validation Accuracy: 0.313600\n",
      "Epoch 117, CIFAR-10 Batch 1:  Loss:     1.7663 Validation Accuracy: 0.320200\n",
      "Epoch 118, CIFAR-10 Batch 1:  Loss:     1.7637 Validation Accuracy: 0.318400\n",
      "Epoch 119, CIFAR-10 Batch 1:  Loss:     1.7659 Validation Accuracy: 0.321200\n",
      "Epoch 120, CIFAR-10 Batch 1:  Loss:     1.7679 Validation Accuracy: 0.319000\n",
      "Epoch 121, CIFAR-10 Batch 1:  Loss:     1.7664 Validation Accuracy: 0.319400\n",
      "Epoch 122, CIFAR-10 Batch 1:  Loss:     1.7671 Validation Accuracy: 0.318200\n",
      "Epoch 123, CIFAR-10 Batch 1:  Loss:     1.7706 Validation Accuracy: 0.317200\n",
      "Epoch 124, CIFAR-10 Batch 1:  Loss:     1.7679 Validation Accuracy: 0.319200\n",
      "Epoch 125, CIFAR-10 Batch 1:  Loss:     1.7537 Validation Accuracy: 0.319800\n",
      "Epoch 126, CIFAR-10 Batch 1:  Loss:     1.7537 Validation Accuracy: 0.322000\n",
      "Epoch 127, CIFAR-10 Batch 1:  Loss:     1.7633 Validation Accuracy: 0.317200\n",
      "Epoch 128, CIFAR-10 Batch 1:  Loss:     1.7690 Validation Accuracy: 0.313800\n",
      "Epoch 129, CIFAR-10 Batch 1:  Loss:     1.7580 Validation Accuracy: 0.316400\n",
      "Epoch 130, CIFAR-10 Batch 1:  Loss:     1.7462 Validation Accuracy: 0.321800\n",
      "Epoch 131, CIFAR-10 Batch 1:  Loss:     1.7440 Validation Accuracy: 0.320600\n",
      "Epoch 132, CIFAR-10 Batch 1:  Loss:     1.7460 Validation Accuracy: 0.324000\n",
      "Epoch 133, CIFAR-10 Batch 1:  Loss:     1.7404 Validation Accuracy: 0.322600\n",
      "Epoch 134, CIFAR-10 Batch 1:  Loss:     1.7370 Validation Accuracy: 0.324000\n",
      "Epoch 135, CIFAR-10 Batch 1:  Loss:     1.7364 Validation Accuracy: 0.325400\n",
      "Epoch 136, CIFAR-10 Batch 1:  Loss:     1.7356 Validation Accuracy: 0.325200\n",
      "Epoch 137, CIFAR-10 Batch 1:  Loss:     1.7374 Validation Accuracy: 0.321600\n",
      "Epoch 138, CIFAR-10 Batch 1:  Loss:     1.7373 Validation Accuracy: 0.320000\n",
      "Epoch 139, CIFAR-10 Batch 1:  Loss:     1.7304 Validation Accuracy: 0.321200\n",
      "Epoch 140, CIFAR-10 Batch 1:  Loss:     1.7281 Validation Accuracy: 0.326000\n",
      "Epoch 141, CIFAR-10 Batch 1:  Loss:     1.7230 Validation Accuracy: 0.326000\n",
      "Epoch 142, CIFAR-10 Batch 1:  Loss:     1.7205 Validation Accuracy: 0.329000\n",
      "Epoch 143, CIFAR-10 Batch 1:  Loss:     1.7173 Validation Accuracy: 0.325200\n",
      "Epoch 144, CIFAR-10 Batch 1:  Loss:     1.7166 Validation Accuracy: 0.330200\n",
      "Epoch 145, CIFAR-10 Batch 1:  Loss:     1.7134 Validation Accuracy: 0.328400\n",
      "Epoch 146, CIFAR-10 Batch 1:  Loss:     1.7135 Validation Accuracy: 0.329000\n",
      "Epoch 147, CIFAR-10 Batch 1:  Loss:     1.7101 Validation Accuracy: 0.328000\n",
      "Epoch 148, CIFAR-10 Batch 1:  Loss:     1.7086 Validation Accuracy: 0.329800\n",
      "Epoch 149, CIFAR-10 Batch 1:  Loss:     1.7056 Validation Accuracy: 0.331200\n",
      "Epoch 150, CIFAR-10 Batch 1:  Loss:     1.7014 Validation Accuracy: 0.331600\n",
      "Epoch 151, CIFAR-10 Batch 1:  Loss:     1.6999 Validation Accuracy: 0.331400\n",
      "Epoch 152, CIFAR-10 Batch 1:  Loss:     1.6975 Validation Accuracy: 0.331000\n",
      "Epoch 153, CIFAR-10 Batch 1:  Loss:     1.6950 Validation Accuracy: 0.330600\n",
      "Epoch 154, CIFAR-10 Batch 1:  Loss:     1.6930 Validation Accuracy: 0.335200\n",
      "Epoch 155, CIFAR-10 Batch 1:  Loss:     1.6906 Validation Accuracy: 0.333600\n",
      "Epoch 156, CIFAR-10 Batch 1:  Loss:     1.6877 Validation Accuracy: 0.334800\n",
      "Epoch 157, CIFAR-10 Batch 1:  Loss:     1.6847 Validation Accuracy: 0.335000\n",
      "Epoch 158, CIFAR-10 Batch 1:  Loss:     1.6825 Validation Accuracy: 0.337800\n",
      "Epoch 159, CIFAR-10 Batch 1:  Loss:     1.6823 Validation Accuracy: 0.337000\n",
      "Epoch 160, CIFAR-10 Batch 1:  Loss:     1.6806 Validation Accuracy: 0.338200\n",
      "Epoch 161, CIFAR-10 Batch 1:  Loss:     1.6829 Validation Accuracy: 0.337600\n",
      "Epoch 162, CIFAR-10 Batch 1:  Loss:     1.6880 Validation Accuracy: 0.337400\n",
      "Epoch 163, CIFAR-10 Batch 1:  Loss:     1.6835 Validation Accuracy: 0.340000\n",
      "Epoch 164, CIFAR-10 Batch 1:  Loss:     1.6901 Validation Accuracy: 0.335800\n",
      "Epoch 165, CIFAR-10 Batch 1:  Loss:     1.6903 Validation Accuracy: 0.337800\n",
      "Epoch 166, CIFAR-10 Batch 1:  Loss:     1.6828 Validation Accuracy: 0.337000\n",
      "Epoch 167, CIFAR-10 Batch 1:  Loss:     1.6793 Validation Accuracy: 0.337400\n",
      "Epoch 168, CIFAR-10 Batch 1:  Loss:     1.6773 Validation Accuracy: 0.339200\n",
      "Epoch 169, CIFAR-10 Batch 1:  Loss:     1.6644 Validation Accuracy: 0.337400\n",
      "Epoch 170, CIFAR-10 Batch 1:  Loss:     1.6555 Validation Accuracy: 0.340200\n",
      "Epoch 171, CIFAR-10 Batch 1:  Loss:     1.6639 Validation Accuracy: 0.339200\n",
      "Epoch 172, CIFAR-10 Batch 1:  Loss:     1.6693 Validation Accuracy: 0.340400\n",
      "Epoch 173, CIFAR-10 Batch 1:  Loss:     1.6539 Validation Accuracy: 0.344800\n",
      "Epoch 174, CIFAR-10 Batch 1:  Loss:     1.6448 Validation Accuracy: 0.345000\n",
      "Epoch 175, CIFAR-10 Batch 1:  Loss:     1.6425 Validation Accuracy: 0.341800\n",
      "Epoch 176, CIFAR-10 Batch 1:  Loss:     1.6435 Validation Accuracy: 0.342800\n",
      "Epoch 177, CIFAR-10 Batch 1:  Loss:     1.6383 Validation Accuracy: 0.343600\n",
      "Epoch 178, CIFAR-10 Batch 1:  Loss:     1.6335 Validation Accuracy: 0.346200\n",
      "Epoch 179, CIFAR-10 Batch 1:  Loss:     1.6325 Validation Accuracy: 0.345800\n",
      "Epoch 180, CIFAR-10 Batch 1:  Loss:     1.6327 Validation Accuracy: 0.348400\n",
      "Epoch 181, CIFAR-10 Batch 1:  Loss:     1.6276 Validation Accuracy: 0.353400\n",
      "Epoch 182, CIFAR-10 Batch 1:  Loss:     1.6227 Validation Accuracy: 0.347800\n",
      "Epoch 183, CIFAR-10 Batch 1:  Loss:     1.6191 Validation Accuracy: 0.349200\n",
      "Epoch 184, CIFAR-10 Batch 1:  Loss:     1.6154 Validation Accuracy: 0.350800\n",
      "Epoch 185, CIFAR-10 Batch 1:  Loss:     1.6131 Validation Accuracy: 0.349600\n",
      "Epoch 186, CIFAR-10 Batch 1:  Loss:     1.6102 Validation Accuracy: 0.348000\n",
      "Epoch 187, CIFAR-10 Batch 1:  Loss:     1.6055 Validation Accuracy: 0.349800\n",
      "Epoch 188, CIFAR-10 Batch 1:  Loss:     1.6037 Validation Accuracy: 0.349800\n",
      "Epoch 189, CIFAR-10 Batch 1:  Loss:     1.6026 Validation Accuracy: 0.348600\n",
      "Epoch 190, CIFAR-10 Batch 1:  Loss:     1.5981 Validation Accuracy: 0.350400\n",
      "Epoch 191, CIFAR-10 Batch 1:  Loss:     1.5949 Validation Accuracy: 0.347000\n",
      "Epoch 192, CIFAR-10 Batch 1:  Loss:     1.5934 Validation Accuracy: 0.350600\n",
      "Epoch 193, CIFAR-10 Batch 1:  Loss:     1.5901 Validation Accuracy: 0.354400\n",
      "Epoch 194, CIFAR-10 Batch 1:  Loss:     1.5861 Validation Accuracy: 0.353400\n",
      "Epoch 195, CIFAR-10 Batch 1:  Loss:     1.5859 Validation Accuracy: 0.354800\n",
      "Epoch 196, CIFAR-10 Batch 1:  Loss:     1.5844 Validation Accuracy: 0.354400\n",
      "Epoch 197, CIFAR-10 Batch 1:  Loss:     1.5797 Validation Accuracy: 0.353400\n",
      "Epoch 198, CIFAR-10 Batch 1:  Loss:     1.5788 Validation Accuracy: 0.352800\n",
      "Epoch 199, CIFAR-10 Batch 1:  Loss:     1.5827 Validation Accuracy: 0.353000\n",
      "Epoch 200, CIFAR-10 Batch 1:  Loss:     1.5772 Validation Accuracy: 0.353000\n",
      "Epoch 201, CIFAR-10 Batch 1:  Loss:     1.5710 Validation Accuracy: 0.356400\n",
      "Epoch 202, CIFAR-10 Batch 1:  Loss:     1.5642 Validation Accuracy: 0.358000\n",
      "Epoch 203, CIFAR-10 Batch 1:  Loss:     1.5664 Validation Accuracy: 0.351800\n",
      "Epoch 204, CIFAR-10 Batch 1:  Loss:     1.5610 Validation Accuracy: 0.356000\n",
      "Epoch 205, CIFAR-10 Batch 1:  Loss:     1.5558 Validation Accuracy: 0.363400\n",
      "Epoch 206, CIFAR-10 Batch 1:  Loss:     1.5550 Validation Accuracy: 0.360400\n",
      "Epoch 207, CIFAR-10 Batch 1:  Loss:     1.5548 Validation Accuracy: 0.356600\n",
      "Epoch 208, CIFAR-10 Batch 1:  Loss:     1.5513 Validation Accuracy: 0.364800\n",
      "Epoch 209, CIFAR-10 Batch 1:  Loss:     1.5485 Validation Accuracy: 0.367200\n",
      "Epoch 210, CIFAR-10 Batch 1:  Loss:     1.5466 Validation Accuracy: 0.357600\n",
      "Epoch 211, CIFAR-10 Batch 1:  Loss:     1.5395 Validation Accuracy: 0.363800\n",
      "Epoch 212, CIFAR-10 Batch 1:  Loss:     1.5358 Validation Accuracy: 0.365200\n",
      "Epoch 213, CIFAR-10 Batch 1:  Loss:     1.5348 Validation Accuracy: 0.360000\n",
      "Epoch 214, CIFAR-10 Batch 1:  Loss:     1.5317 Validation Accuracy: 0.366800\n",
      "Epoch 215, CIFAR-10 Batch 1:  Loss:     1.5290 Validation Accuracy: 0.367200\n",
      "Epoch 216, CIFAR-10 Batch 1:  Loss:     1.5257 Validation Accuracy: 0.367800\n",
      "Epoch 217, CIFAR-10 Batch 1:  Loss:     1.5268 Validation Accuracy: 0.369200\n",
      "Epoch 218, CIFAR-10 Batch 1:  Loss:     1.5241 Validation Accuracy: 0.369400\n",
      "Epoch 219, CIFAR-10 Batch 1:  Loss:     1.5212 Validation Accuracy: 0.371000\n",
      "Epoch 220, CIFAR-10 Batch 1:  Loss:     1.5271 Validation Accuracy: 0.363800\n",
      "Epoch 221, CIFAR-10 Batch 1:  Loss:     1.5393 Validation Accuracy: 0.366000\n",
      "Epoch 222, CIFAR-10 Batch 1:  Loss:     1.5441 Validation Accuracy: 0.368400\n",
      "Epoch 223, CIFAR-10 Batch 1:  Loss:     1.5352 Validation Accuracy: 0.364200\n",
      "Epoch 224, CIFAR-10 Batch 1:  Loss:     1.5230 Validation Accuracy: 0.365400\n",
      "Epoch 225, CIFAR-10 Batch 1:  Loss:     1.5077 Validation Accuracy: 0.374400\n",
      "Epoch 226, CIFAR-10 Batch 1:  Loss:     1.5095 Validation Accuracy: 0.372200\n",
      "Epoch 227, CIFAR-10 Batch 1:  Loss:     1.5085 Validation Accuracy: 0.370800\n",
      "Epoch 228, CIFAR-10 Batch 1:  Loss:     1.5080 Validation Accuracy: 0.375800\n",
      "Epoch 229, CIFAR-10 Batch 1:  Loss:     1.4978 Validation Accuracy: 0.372400\n",
      "Epoch 230, CIFAR-10 Batch 1:  Loss:     1.4959 Validation Accuracy: 0.377400\n",
      "Epoch 231, CIFAR-10 Batch 1:  Loss:     1.5065 Validation Accuracy: 0.377000\n",
      "Epoch 232, CIFAR-10 Batch 1:  Loss:     1.5086 Validation Accuracy: 0.369600\n",
      "Epoch 233, CIFAR-10 Batch 1:  Loss:     1.4973 Validation Accuracy: 0.373600\n",
      "Epoch 234, CIFAR-10 Batch 1:  Loss:     1.4839 Validation Accuracy: 0.379800\n",
      "Epoch 235, CIFAR-10 Batch 1:  Loss:     1.4795 Validation Accuracy: 0.378200\n",
      "Epoch 236, CIFAR-10 Batch 1:  Loss:     1.4799 Validation Accuracy: 0.376800\n",
      "Epoch 237, CIFAR-10 Batch 1:  Loss:     1.4753 Validation Accuracy: 0.379800\n",
      "Epoch 238, CIFAR-10 Batch 1:  Loss:     1.4730 Validation Accuracy: 0.378000\n",
      "Epoch 239, CIFAR-10 Batch 1:  Loss:     1.4688 Validation Accuracy: 0.381000\n",
      "Epoch 240, CIFAR-10 Batch 1:  Loss:     1.4652 Validation Accuracy: 0.379400\n",
      "Epoch 241, CIFAR-10 Batch 1:  Loss:     1.4676 Validation Accuracy: 0.381800\n",
      "Epoch 242, CIFAR-10 Batch 1:  Loss:     1.4703 Validation Accuracy: 0.384000\n",
      "Epoch 243, CIFAR-10 Batch 1:  Loss:     1.4766 Validation Accuracy: 0.378000\n",
      "Epoch 244, CIFAR-10 Batch 1:  Loss:     1.4825 Validation Accuracy: 0.378200\n",
      "Epoch 245, CIFAR-10 Batch 1:  Loss:     1.4807 Validation Accuracy: 0.376000\n",
      "Epoch 246, CIFAR-10 Batch 1:  Loss:     1.4678 Validation Accuracy: 0.381800\n",
      "Epoch 247, CIFAR-10 Batch 1:  Loss:     1.4561 Validation Accuracy: 0.385600\n",
      "Epoch 248, CIFAR-10 Batch 1:  Loss:     1.4498 Validation Accuracy: 0.387200\n",
      "Epoch 249, CIFAR-10 Batch 1:  Loss:     1.4504 Validation Accuracy: 0.387000\n",
      "Epoch 250, CIFAR-10 Batch 1:  Loss:     1.4471 Validation Accuracy: 0.388600\n",
      "Epoch 251, CIFAR-10 Batch 1:  Loss:     1.4405 Validation Accuracy: 0.387200\n",
      "Epoch 252, CIFAR-10 Batch 1:  Loss:     1.4339 Validation Accuracy: 0.391400\n",
      "Epoch 253, CIFAR-10 Batch 1:  Loss:     1.4360 Validation Accuracy: 0.389400\n",
      "Epoch 254, CIFAR-10 Batch 1:  Loss:     1.4407 Validation Accuracy: 0.389800\n",
      "Epoch 255, CIFAR-10 Batch 1:  Loss:     1.4513 Validation Accuracy: 0.391600\n",
      "Epoch 256, CIFAR-10 Batch 1:  Loss:     1.4532 Validation Accuracy: 0.390000\n",
      "Epoch 257, CIFAR-10 Batch 1:  Loss:     1.4343 Validation Accuracy: 0.388600\n",
      "Epoch 258, CIFAR-10 Batch 1:  Loss:     1.4247 Validation Accuracy: 0.395600\n",
      "Epoch 259, CIFAR-10 Batch 1:  Loss:     1.4211 Validation Accuracy: 0.394200\n",
      "Epoch 260, CIFAR-10 Batch 1:  Loss:     1.4299 Validation Accuracy: 0.395000\n",
      "Epoch 261, CIFAR-10 Batch 1:  Loss:     1.4263 Validation Accuracy: 0.391800\n",
      "Epoch 262, CIFAR-10 Batch 1:  Loss:     1.4128 Validation Accuracy: 0.402200\n",
      "Epoch 263, CIFAR-10 Batch 1:  Loss:     1.4137 Validation Accuracy: 0.397400\n",
      "Epoch 264, CIFAR-10 Batch 1:  Loss:     1.4250 Validation Accuracy: 0.394600\n",
      "Epoch 265, CIFAR-10 Batch 1:  Loss:     1.4324 Validation Accuracy: 0.396600\n",
      "Epoch 266, CIFAR-10 Batch 1:  Loss:     1.4169 Validation Accuracy: 0.397000\n",
      "Epoch 267, CIFAR-10 Batch 1:  Loss:     1.4052 Validation Accuracy: 0.401200\n",
      "Epoch 268, CIFAR-10 Batch 1:  Loss:     1.3999 Validation Accuracy: 0.402400\n",
      "Epoch 269, CIFAR-10 Batch 1:  Loss:     1.3963 Validation Accuracy: 0.403800\n",
      "Epoch 270, CIFAR-10 Batch 1:  Loss:     1.3941 Validation Accuracy: 0.403400\n",
      "Epoch 271, CIFAR-10 Batch 1:  Loss:     1.3955 Validation Accuracy: 0.401800\n",
      "Epoch 272, CIFAR-10 Batch 1:  Loss:     1.3864 Validation Accuracy: 0.402200\n",
      "Epoch 273, CIFAR-10 Batch 1:  Loss:     1.3886 Validation Accuracy: 0.405000\n",
      "Epoch 274, CIFAR-10 Batch 1:  Loss:     1.3897 Validation Accuracy: 0.405600\n",
      "Epoch 275, CIFAR-10 Batch 1:  Loss:     1.3988 Validation Accuracy: 0.403800\n",
      "Epoch 276, CIFAR-10 Batch 1:  Loss:     1.4149 Validation Accuracy: 0.398000\n",
      "Epoch 277, CIFAR-10 Batch 1:  Loss:     1.4095 Validation Accuracy: 0.399200\n",
      "Epoch 278, CIFAR-10 Batch 1:  Loss:     1.3985 Validation Accuracy: 0.401600\n",
      "Epoch 279, CIFAR-10 Batch 1:  Loss:     1.3799 Validation Accuracy: 0.407400\n",
      "Epoch 280, CIFAR-10 Batch 1:  Loss:     1.3766 Validation Accuracy: 0.409200\n",
      "Epoch 281, CIFAR-10 Batch 1:  Loss:     1.3749 Validation Accuracy: 0.407800\n",
      "Epoch 282, CIFAR-10 Batch 1:  Loss:     1.3758 Validation Accuracy: 0.406000\n",
      "Epoch 283, CIFAR-10 Batch 1:  Loss:     1.3667 Validation Accuracy: 0.410000\n",
      "Epoch 284, CIFAR-10 Batch 1:  Loss:     1.3634 Validation Accuracy: 0.412200\n",
      "Epoch 285, CIFAR-10 Batch 1:  Loss:     1.3662 Validation Accuracy: 0.408800\n",
      "Epoch 286, CIFAR-10 Batch 1:  Loss:     1.3704 Validation Accuracy: 0.409200\n",
      "Epoch 287, CIFAR-10 Batch 1:  Loss:     1.3845 Validation Accuracy: 0.406200\n",
      "Epoch 288, CIFAR-10 Batch 1:  Loss:     1.3883 Validation Accuracy: 0.404400\n",
      "Epoch 289, CIFAR-10 Batch 1:  Loss:     1.3699 Validation Accuracy: 0.407200\n",
      "Epoch 290, CIFAR-10 Batch 1:  Loss:     1.3511 Validation Accuracy: 0.412600\n",
      "Epoch 291, CIFAR-10 Batch 1:  Loss:     1.3530 Validation Accuracy: 0.413400\n",
      "Epoch 292, CIFAR-10 Batch 1:  Loss:     1.3535 Validation Accuracy: 0.412600\n",
      "Epoch 293, CIFAR-10 Batch 1:  Loss:     1.3482 Validation Accuracy: 0.415000\n",
      "Epoch 294, CIFAR-10 Batch 1:  Loss:     1.3418 Validation Accuracy: 0.413600\n",
      "Epoch 295, CIFAR-10 Batch 1:  Loss:     1.3417 Validation Accuracy: 0.416200\n",
      "Epoch 296, CIFAR-10 Batch 1:  Loss:     1.3386 Validation Accuracy: 0.414000\n",
      "Epoch 297, CIFAR-10 Batch 1:  Loss:     1.3375 Validation Accuracy: 0.414200\n",
      "Epoch 298, CIFAR-10 Batch 1:  Loss:     1.3386 Validation Accuracy: 0.413800\n",
      "Epoch 299, CIFAR-10 Batch 1:  Loss:     1.3368 Validation Accuracy: 0.413200\n",
      "Epoch 300, CIFAR-10 Batch 1:  Loss:     1.3390 Validation Accuracy: 0.414000\n",
      "Epoch 301, CIFAR-10 Batch 1:  Loss:     1.3557 Validation Accuracy: 0.406600\n",
      "Epoch 302, CIFAR-10 Batch 1:  Loss:     1.3902 Validation Accuracy: 0.400800\n",
      "Epoch 303, CIFAR-10 Batch 1:  Loss:     1.3808 Validation Accuracy: 0.403000\n",
      "Epoch 304, CIFAR-10 Batch 1:  Loss:     1.3495 Validation Accuracy: 0.411000\n",
      "Epoch 305, CIFAR-10 Batch 1:  Loss:     1.3286 Validation Accuracy: 0.414400\n",
      "Epoch 306, CIFAR-10 Batch 1:  Loss:     1.3430 Validation Accuracy: 0.415200\n",
      "Epoch 307, CIFAR-10 Batch 1:  Loss:     1.3263 Validation Accuracy: 0.418800\n",
      "Epoch 308, CIFAR-10 Batch 1:  Loss:     1.3144 Validation Accuracy: 0.420200\n",
      "Epoch 309, CIFAR-10 Batch 1:  Loss:     1.3199 Validation Accuracy: 0.417000\n",
      "Epoch 310, CIFAR-10 Batch 1:  Loss:     1.3304 Validation Accuracy: 0.414200\n",
      "Epoch 311, CIFAR-10 Batch 1:  Loss:     1.3220 Validation Accuracy: 0.414800\n",
      "Epoch 312, CIFAR-10 Batch 1:  Loss:     1.3107 Validation Accuracy: 0.417400\n",
      "Epoch 313, CIFAR-10 Batch 1:  Loss:     1.3055 Validation Accuracy: 0.417800\n",
      "Epoch 314, CIFAR-10 Batch 1:  Loss:     1.3100 Validation Accuracy: 0.416600\n",
      "Epoch 315, CIFAR-10 Batch 1:  Loss:     1.3030 Validation Accuracy: 0.420600\n",
      "Epoch 316, CIFAR-10 Batch 1:  Loss:     1.3026 Validation Accuracy: 0.418200\n",
      "Epoch 317, CIFAR-10 Batch 1:  Loss:     1.2969 Validation Accuracy: 0.416000\n",
      "Epoch 318, CIFAR-10 Batch 1:  Loss:     1.2975 Validation Accuracy: 0.416800\n",
      "Epoch 319, CIFAR-10 Batch 1:  Loss:     1.2954 Validation Accuracy: 0.418800\n",
      "Epoch 320, CIFAR-10 Batch 1:  Loss:     1.2965 Validation Accuracy: 0.417400\n",
      "Epoch 321, CIFAR-10 Batch 1:  Loss:     1.2974 Validation Accuracy: 0.422800\n",
      "Epoch 322, CIFAR-10 Batch 1:  Loss:     1.2982 Validation Accuracy: 0.420000\n",
      "Epoch 323, CIFAR-10 Batch 1:  Loss:     1.3005 Validation Accuracy: 0.418000\n",
      "Epoch 324, CIFAR-10 Batch 1:  Loss:     1.3050 Validation Accuracy: 0.420200\n",
      "Epoch 325, CIFAR-10 Batch 1:  Loss:     1.3048 Validation Accuracy: 0.416200\n",
      "Epoch 326, CIFAR-10 Batch 1:  Loss:     1.2970 Validation Accuracy: 0.422800\n",
      "Epoch 327, CIFAR-10 Batch 1:  Loss:     1.2803 Validation Accuracy: 0.419200\n",
      "Epoch 328, CIFAR-10 Batch 1:  Loss:     1.2790 Validation Accuracy: 0.421000\n",
      "Epoch 329, CIFAR-10 Batch 1:  Loss:     1.2766 Validation Accuracy: 0.425200\n",
      "Epoch 330, CIFAR-10 Batch 1:  Loss:     1.2770 Validation Accuracy: 0.424400\n",
      "Epoch 331, CIFAR-10 Batch 1:  Loss:     1.2718 Validation Accuracy: 0.424400\n",
      "Epoch 332, CIFAR-10 Batch 1:  Loss:     1.2786 Validation Accuracy: 0.421400\n",
      "Epoch 333, CIFAR-10 Batch 1:  Loss:     1.2728 Validation Accuracy: 0.425400\n",
      "Epoch 334, CIFAR-10 Batch 1:  Loss:     1.2692 Validation Accuracy: 0.427400\n",
      "Epoch 335, CIFAR-10 Batch 1:  Loss:     1.2666 Validation Accuracy: 0.429600\n",
      "Epoch 336, CIFAR-10 Batch 1:  Loss:     1.2653 Validation Accuracy: 0.422400\n",
      "Epoch 337, CIFAR-10 Batch 1:  Loss:     1.2676 Validation Accuracy: 0.424800\n",
      "Epoch 338, CIFAR-10 Batch 1:  Loss:     1.2638 Validation Accuracy: 0.424400\n",
      "Epoch 339, CIFAR-10 Batch 1:  Loss:     1.2613 Validation Accuracy: 0.431000\n",
      "Epoch 340, CIFAR-10 Batch 1:  Loss:     1.2602 Validation Accuracy: 0.427200\n",
      "Epoch 341, CIFAR-10 Batch 1:  Loss:     1.2532 Validation Accuracy: 0.427200\n",
      "Epoch 342, CIFAR-10 Batch 1:  Loss:     1.2546 Validation Accuracy: 0.423200\n",
      "Epoch 343, CIFAR-10 Batch 1:  Loss:     1.2573 Validation Accuracy: 0.422200\n",
      "Epoch 344, CIFAR-10 Batch 1:  Loss:     1.2576 Validation Accuracy: 0.427800\n",
      "Epoch 345, CIFAR-10 Batch 1:  Loss:     1.2578 Validation Accuracy: 0.431600\n",
      "Epoch 346, CIFAR-10 Batch 1:  Loss:     1.2545 Validation Accuracy: 0.428400\n",
      "Epoch 347, CIFAR-10 Batch 1:  Loss:     1.2561 Validation Accuracy: 0.423400\n",
      "Epoch 348, CIFAR-10 Batch 1:  Loss:     1.2582 Validation Accuracy: 0.423600\n",
      "Epoch 349, CIFAR-10 Batch 1:  Loss:     1.2632 Validation Accuracy: 0.428000\n",
      "Epoch 350, CIFAR-10 Batch 1:  Loss:     1.2802 Validation Accuracy: 0.420400\n",
      "Epoch 351, CIFAR-10 Batch 1:  Loss:     1.2854 Validation Accuracy: 0.421800\n",
      "Epoch 352, CIFAR-10 Batch 1:  Loss:     1.2918 Validation Accuracy: 0.416800\n",
      "Epoch 353, CIFAR-10 Batch 1:  Loss:     1.2763 Validation Accuracy: 0.422200\n",
      "Epoch 354, CIFAR-10 Batch 1:  Loss:     1.2555 Validation Accuracy: 0.428600\n",
      "Epoch 355, CIFAR-10 Batch 1:  Loss:     1.2404 Validation Accuracy: 0.432600\n",
      "Epoch 356, CIFAR-10 Batch 1:  Loss:     1.2444 Validation Accuracy: 0.424800\n",
      "Epoch 357, CIFAR-10 Batch 1:  Loss:     1.2468 Validation Accuracy: 0.427800\n",
      "Epoch 358, CIFAR-10 Batch 1:  Loss:     1.2365 Validation Accuracy: 0.430400\n",
      "Epoch 359, CIFAR-10 Batch 1:  Loss:     1.2309 Validation Accuracy: 0.434400\n",
      "Epoch 360, CIFAR-10 Batch 1:  Loss:     1.2249 Validation Accuracy: 0.431400\n",
      "Epoch 361, CIFAR-10 Batch 1:  Loss:     1.2286 Validation Accuracy: 0.432400\n",
      "Epoch 362, CIFAR-10 Batch 1:  Loss:     1.2255 Validation Accuracy: 0.435800\n",
      "Epoch 363, CIFAR-10 Batch 1:  Loss:     1.2229 Validation Accuracy: 0.433400\n",
      "Epoch 364, CIFAR-10 Batch 1:  Loss:     1.2225 Validation Accuracy: 0.432400\n",
      "Epoch 365, CIFAR-10 Batch 1:  Loss:     1.2205 Validation Accuracy: 0.436600\n",
      "Epoch 366, CIFAR-10 Batch 1:  Loss:     1.2225 Validation Accuracy: 0.436400\n",
      "Epoch 367, CIFAR-10 Batch 1:  Loss:     1.2187 Validation Accuracy: 0.433400\n",
      "Epoch 368, CIFAR-10 Batch 1:  Loss:     1.2198 Validation Accuracy: 0.433200\n",
      "Epoch 369, CIFAR-10 Batch 1:  Loss:     1.2165 Validation Accuracy: 0.433400\n",
      "Epoch 370, CIFAR-10 Batch 1:  Loss:     1.2150 Validation Accuracy: 0.435600\n",
      "Epoch 371, CIFAR-10 Batch 1:  Loss:     1.2195 Validation Accuracy: 0.433800\n",
      "Epoch 372, CIFAR-10 Batch 1:  Loss:     1.2122 Validation Accuracy: 0.435600\n",
      "Epoch 373, CIFAR-10 Batch 1:  Loss:     1.2103 Validation Accuracy: 0.436800\n",
      "Epoch 374, CIFAR-10 Batch 1:  Loss:     1.2065 Validation Accuracy: 0.437000\n",
      "Epoch 375, CIFAR-10 Batch 1:  Loss:     1.2072 Validation Accuracy: 0.437600\n",
      "Epoch 376, CIFAR-10 Batch 1:  Loss:     1.2073 Validation Accuracy: 0.434000\n",
      "Epoch 377, CIFAR-10 Batch 1:  Loss:     1.2077 Validation Accuracy: 0.436400\n",
      "Epoch 378, CIFAR-10 Batch 1:  Loss:     1.2061 Validation Accuracy: 0.435200\n",
      "Epoch 379, CIFAR-10 Batch 1:  Loss:     1.2027 Validation Accuracy: 0.439400\n",
      "Epoch 380, CIFAR-10 Batch 1:  Loss:     1.2026 Validation Accuracy: 0.437200\n",
      "Epoch 381, CIFAR-10 Batch 1:  Loss:     1.2019 Validation Accuracy: 0.440000\n",
      "Epoch 382, CIFAR-10 Batch 1:  Loss:     1.2170 Validation Accuracy: 0.428800\n",
      "Epoch 383, CIFAR-10 Batch 1:  Loss:     1.2334 Validation Accuracy: 0.429600\n",
      "Epoch 384, CIFAR-10 Batch 1:  Loss:     1.2610 Validation Accuracy: 0.424000\n",
      "Epoch 385, CIFAR-10 Batch 1:  Loss:     1.2825 Validation Accuracy: 0.411600\n",
      "Epoch 386, CIFAR-10 Batch 1:  Loss:     1.2345 Validation Accuracy: 0.431000\n",
      "Epoch 387, CIFAR-10 Batch 1:  Loss:     1.2052 Validation Accuracy: 0.430800\n",
      "Epoch 388, CIFAR-10 Batch 1:  Loss:     1.2187 Validation Accuracy: 0.430200\n",
      "Epoch 389, CIFAR-10 Batch 1:  Loss:     1.2147 Validation Accuracy: 0.437200\n",
      "Epoch 390, CIFAR-10 Batch 1:  Loss:     1.1994 Validation Accuracy: 0.438200\n",
      "Epoch 391, CIFAR-10 Batch 1:  Loss:     1.1890 Validation Accuracy: 0.436200\n",
      "Epoch 392, CIFAR-10 Batch 1:  Loss:     1.1943 Validation Accuracy: 0.434200\n",
      "Epoch 393, CIFAR-10 Batch 1:  Loss:     1.1892 Validation Accuracy: 0.436600\n",
      "Epoch 394, CIFAR-10 Batch 1:  Loss:     1.1834 Validation Accuracy: 0.440800\n",
      "Epoch 395, CIFAR-10 Batch 1:  Loss:     1.1867 Validation Accuracy: 0.439000\n",
      "Epoch 396, CIFAR-10 Batch 1:  Loss:     1.1834 Validation Accuracy: 0.442600\n",
      "Epoch 397, CIFAR-10 Batch 1:  Loss:     1.1816 Validation Accuracy: 0.439400\n",
      "Epoch 398, CIFAR-10 Batch 1:  Loss:     1.1822 Validation Accuracy: 0.440200\n",
      "Epoch 399, CIFAR-10 Batch 1:  Loss:     1.1811 Validation Accuracy: 0.440600\n",
      "Epoch 400, CIFAR-10 Batch 1:  Loss:     1.1785 Validation Accuracy: 0.440000\n",
      "Epoch 401, CIFAR-10 Batch 1:  Loss:     1.1767 Validation Accuracy: 0.439800\n",
      "Epoch 402, CIFAR-10 Batch 1:  Loss:     1.1766 Validation Accuracy: 0.441000\n",
      "Epoch 403, CIFAR-10 Batch 1:  Loss:     1.1740 Validation Accuracy: 0.442800\n",
      "Epoch 404, CIFAR-10 Batch 1:  Loss:     1.1752 Validation Accuracy: 0.437600\n",
      "Epoch 405, CIFAR-10 Batch 1:  Loss:     1.1742 Validation Accuracy: 0.439800\n",
      "Epoch 406, CIFAR-10 Batch 1:  Loss:     1.1715 Validation Accuracy: 0.441400\n",
      "Epoch 407, CIFAR-10 Batch 1:  Loss:     1.1718 Validation Accuracy: 0.440200\n",
      "Epoch 408, CIFAR-10 Batch 1:  Loss:     1.1712 Validation Accuracy: 0.441800\n",
      "Epoch 409, CIFAR-10 Batch 1:  Loss:     1.1757 Validation Accuracy: 0.437800\n",
      "Epoch 410, CIFAR-10 Batch 1:  Loss:     1.1772 Validation Accuracy: 0.435600\n",
      "Epoch 411, CIFAR-10 Batch 1:  Loss:     1.1732 Validation Accuracy: 0.437200\n",
      "Epoch 412, CIFAR-10 Batch 1:  Loss:     1.1685 Validation Accuracy: 0.440000\n",
      "Epoch 413, CIFAR-10 Batch 1:  Loss:     1.1734 Validation Accuracy: 0.442600\n",
      "Epoch 414, CIFAR-10 Batch 1:  Loss:     1.1772 Validation Accuracy: 0.442600\n",
      "Epoch 415, CIFAR-10 Batch 1:  Loss:     1.1815 Validation Accuracy: 0.440600\n",
      "Epoch 416, CIFAR-10 Batch 1:  Loss:     1.1971 Validation Accuracy: 0.433200\n",
      "Epoch 417, CIFAR-10 Batch 1:  Loss:     1.1907 Validation Accuracy: 0.435000\n",
      "Epoch 418, CIFAR-10 Batch 1:  Loss:     1.1897 Validation Accuracy: 0.438400\n",
      "Epoch 419, CIFAR-10 Batch 1:  Loss:     1.1721 Validation Accuracy: 0.442200\n",
      "Epoch 420, CIFAR-10 Batch 1:  Loss:     1.1600 Validation Accuracy: 0.444000\n",
      "Epoch 421, CIFAR-10 Batch 1:  Loss:     1.1549 Validation Accuracy: 0.442800\n",
      "Epoch 422, CIFAR-10 Batch 1:  Loss:     1.1676 Validation Accuracy: 0.436400\n",
      "Epoch 423, CIFAR-10 Batch 1:  Loss:     1.1779 Validation Accuracy: 0.431800\n",
      "Epoch 424, CIFAR-10 Batch 1:  Loss:     1.1735 Validation Accuracy: 0.436400\n",
      "Epoch 425, CIFAR-10 Batch 1:  Loss:     1.1562 Validation Accuracy: 0.444000\n",
      "Epoch 426, CIFAR-10 Batch 1:  Loss:     1.1539 Validation Accuracy: 0.447000\n",
      "Epoch 427, CIFAR-10 Batch 1:  Loss:     1.1532 Validation Accuracy: 0.441800\n",
      "Epoch 428, CIFAR-10 Batch 1:  Loss:     1.1565 Validation Accuracy: 0.437600\n",
      "Epoch 429, CIFAR-10 Batch 1:  Loss:     1.1465 Validation Accuracy: 0.441600\n",
      "Epoch 430, CIFAR-10 Batch 1:  Loss:     1.1430 Validation Accuracy: 0.443600\n",
      "Epoch 431, CIFAR-10 Batch 1:  Loss:     1.1439 Validation Accuracy: 0.445400\n",
      "Epoch 432, CIFAR-10 Batch 1:  Loss:     1.1428 Validation Accuracy: 0.443600\n",
      "Epoch 433, CIFAR-10 Batch 1:  Loss:     1.1382 Validation Accuracy: 0.443200\n",
      "Epoch 434, CIFAR-10 Batch 1:  Loss:     1.1453 Validation Accuracy: 0.439800\n",
      "Epoch 435, CIFAR-10 Batch 1:  Loss:     1.1480 Validation Accuracy: 0.436800\n",
      "Epoch 436, CIFAR-10 Batch 1:  Loss:     1.1557 Validation Accuracy: 0.438600\n",
      "Epoch 437, CIFAR-10 Batch 1:  Loss:     1.1502 Validation Accuracy: 0.444800\n",
      "Epoch 438, CIFAR-10 Batch 1:  Loss:     1.1396 Validation Accuracy: 0.443800\n",
      "Epoch 439, CIFAR-10 Batch 1:  Loss:     1.1306 Validation Accuracy: 0.445200\n",
      "Epoch 440, CIFAR-10 Batch 1:  Loss:     1.1419 Validation Accuracy: 0.438600\n",
      "Epoch 441, CIFAR-10 Batch 1:  Loss:     1.1496 Validation Accuracy: 0.431000\n",
      "Epoch 442, CIFAR-10 Batch 1:  Loss:     1.1339 Validation Accuracy: 0.446000\n",
      "Epoch 443, CIFAR-10 Batch 1:  Loss:     1.1385 Validation Accuracy: 0.447600\n",
      "Epoch 444, CIFAR-10 Batch 1:  Loss:     1.1479 Validation Accuracy: 0.444000\n",
      "Epoch 445, CIFAR-10 Batch 1:  Loss:     1.1381 Validation Accuracy: 0.444400\n",
      "Epoch 446, CIFAR-10 Batch 1:  Loss:     1.1357 Validation Accuracy: 0.445000\n",
      "Epoch 447, CIFAR-10 Batch 1:  Loss:     1.1386 Validation Accuracy: 0.441200\n",
      "Epoch 448, CIFAR-10 Batch 1:  Loss:     1.1301 Validation Accuracy: 0.440600\n",
      "Epoch 449, CIFAR-10 Batch 1:  Loss:     1.1257 Validation Accuracy: 0.449000\n",
      "Epoch 450, CIFAR-10 Batch 1:  Loss:     1.1200 Validation Accuracy: 0.444400\n",
      "Epoch 451, CIFAR-10 Batch 1:  Loss:     1.1194 Validation Accuracy: 0.446200\n",
      "Epoch 452, CIFAR-10 Batch 1:  Loss:     1.1237 Validation Accuracy: 0.446400\n",
      "Epoch 453, CIFAR-10 Batch 1:  Loss:     1.1392 Validation Accuracy: 0.440800\n",
      "Epoch 454, CIFAR-10 Batch 1:  Loss:     1.1459 Validation Accuracy: 0.437400\n",
      "Epoch 455, CIFAR-10 Batch 1:  Loss:     1.1263 Validation Accuracy: 0.444000\n",
      "Epoch 456, CIFAR-10 Batch 1:  Loss:     1.1156 Validation Accuracy: 0.445200\n",
      "Epoch 457, CIFAR-10 Batch 1:  Loss:     1.1165 Validation Accuracy: 0.445400\n",
      "Epoch 458, CIFAR-10 Batch 1:  Loss:     1.1221 Validation Accuracy: 0.442200\n",
      "Epoch 459, CIFAR-10 Batch 1:  Loss:     1.1250 Validation Accuracy: 0.444200\n",
      "Epoch 460, CIFAR-10 Batch 1:  Loss:     1.1328 Validation Accuracy: 0.444000\n",
      "Epoch 461, CIFAR-10 Batch 1:  Loss:     1.1277 Validation Accuracy: 0.448200\n",
      "Epoch 462, CIFAR-10 Batch 1:  Loss:     1.1214 Validation Accuracy: 0.450800\n",
      "Epoch 463, CIFAR-10 Batch 1:  Loss:     1.1122 Validation Accuracy: 0.448400\n",
      "Epoch 464, CIFAR-10 Batch 1:  Loss:     1.1079 Validation Accuracy: 0.450000\n",
      "Epoch 465, CIFAR-10 Batch 1:  Loss:     1.1046 Validation Accuracy: 0.448200\n",
      "Epoch 466, CIFAR-10 Batch 1:  Loss:     1.1225 Validation Accuracy: 0.439400\n",
      "Epoch 467, CIFAR-10 Batch 1:  Loss:     1.1393 Validation Accuracy: 0.432600\n",
      "Epoch 468, CIFAR-10 Batch 1:  Loss:     1.1144 Validation Accuracy: 0.443000\n",
      "Epoch 469, CIFAR-10 Batch 1:  Loss:     1.1189 Validation Accuracy: 0.451400\n",
      "Epoch 470, CIFAR-10 Batch 1:  Loss:     1.1185 Validation Accuracy: 0.450800\n",
      "Epoch 471, CIFAR-10 Batch 1:  Loss:     1.1157 Validation Accuracy: 0.442400\n",
      "Epoch 472, CIFAR-10 Batch 1:  Loss:     1.1220 Validation Accuracy: 0.433600\n",
      "Epoch 473, CIFAR-10 Batch 1:  Loss:     1.1029 Validation Accuracy: 0.446400\n",
      "Epoch 474, CIFAR-10 Batch 1:  Loss:     1.1039 Validation Accuracy: 0.450600\n",
      "Epoch 475, CIFAR-10 Batch 1:  Loss:     1.1012 Validation Accuracy: 0.451200\n",
      "Epoch 476, CIFAR-10 Batch 1:  Loss:     1.0990 Validation Accuracy: 0.449000\n",
      "Epoch 477, CIFAR-10 Batch 1:  Loss:     1.1063 Validation Accuracy: 0.442600\n",
      "Epoch 478, CIFAR-10 Batch 1:  Loss:     1.1007 Validation Accuracy: 0.447200\n",
      "Epoch 479, CIFAR-10 Batch 1:  Loss:     1.0971 Validation Accuracy: 0.446800\n",
      "Epoch 480, CIFAR-10 Batch 1:  Loss:     1.0969 Validation Accuracy: 0.453200\n",
      "Epoch 481, CIFAR-10 Batch 1:  Loss:     1.0882 Validation Accuracy: 0.449200\n",
      "Epoch 482, CIFAR-10 Batch 1:  Loss:     1.0937 Validation Accuracy: 0.443800\n",
      "Epoch 483, CIFAR-10 Batch 1:  Loss:     1.1020 Validation Accuracy: 0.443200\n",
      "Epoch 484, CIFAR-10 Batch 1:  Loss:     1.1022 Validation Accuracy: 0.444400\n",
      "Epoch 485, CIFAR-10 Batch 1:  Loss:     1.1056 Validation Accuracy: 0.448200\n",
      "Epoch 486, CIFAR-10 Batch 1:  Loss:     1.1165 Validation Accuracy: 0.445800\n",
      "Epoch 487, CIFAR-10 Batch 1:  Loss:     1.1138 Validation Accuracy: 0.445800\n",
      "Epoch 488, CIFAR-10 Batch 1:  Loss:     1.1012 Validation Accuracy: 0.445000\n",
      "Epoch 489, CIFAR-10 Batch 1:  Loss:     1.0995 Validation Accuracy: 0.448400\n",
      "Epoch 490, CIFAR-10 Batch 1:  Loss:     1.0867 Validation Accuracy: 0.451200\n",
      "Epoch 491, CIFAR-10 Batch 1:  Loss:     1.0869 Validation Accuracy: 0.453400\n",
      "Epoch 492, CIFAR-10 Batch 1:  Loss:     1.0920 Validation Accuracy: 0.450000\n",
      "Epoch 493, CIFAR-10 Batch 1:  Loss:     1.0881 Validation Accuracy: 0.451400\n",
      "Epoch 494, CIFAR-10 Batch 1:  Loss:     1.0930 Validation Accuracy: 0.448200\n",
      "Epoch 495, CIFAR-10 Batch 1:  Loss:     1.0961 Validation Accuracy: 0.444800\n",
      "Epoch 496, CIFAR-10 Batch 1:  Loss:     1.0887 Validation Accuracy: 0.446800\n",
      "Epoch 497, CIFAR-10 Batch 1:  Loss:     1.0819 Validation Accuracy: 0.452800\n",
      "Epoch 498, CIFAR-10 Batch 1:  Loss:     1.0936 Validation Accuracy: 0.451400\n",
      "Epoch 499, CIFAR-10 Batch 1:  Loss:     1.0906 Validation Accuracy: 0.451600\n",
      "Epoch 500, CIFAR-10 Batch 1:  Loss:     1.0826 Validation Accuracy: 0.448800\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "print('Checking the Training on a Single Batch...')\n",
    "with tf.Session() as sess:\n",
    "    # Initializing the variables\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    # Training cycle\n",
    "    for epoch in range(epochs):\n",
    "        batch_i = 1\n",
    "        for batch_features, batch_labels in helper.load_preprocess_training_batch(batch_i, batch_size):\n",
    "            train_neural_network(sess, optimizer, keep_probability, batch_features, batch_labels)\n",
    "        print('Epoch {:>2}, CIFAR-10 Batch {}:  '.format(epoch + 1, batch_i), end='')\n",
    "        print_stats(sess, batch_features, batch_labels, cost, accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Fully Train the Model\n",
    "Now that you got a good accuracy with a single CIFAR-10 batch, try it with all five batches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n",
      "Epoch  1, CIFAR-10 Batch 1:  Loss:     2.3026 Validation Accuracy: 0.105000\n",
      "Epoch  1, CIFAR-10 Batch 2:  Loss:     2.3026 Validation Accuracy: 0.105000\n",
      "Epoch  1, CIFAR-10 Batch 3:  Loss:     2.3027 Validation Accuracy: 0.105000\n",
      "Epoch  1, CIFAR-10 Batch 4:  Loss:     2.3019 Validation Accuracy: 0.105000\n",
      "Epoch  1, CIFAR-10 Batch 5:  Loss:     2.3000 Validation Accuracy: 0.108600\n",
      "Epoch  2, CIFAR-10 Batch 1:  Loss:     2.2940 Validation Accuracy: 0.097600\n",
      "Epoch  2, CIFAR-10 Batch 2:  Loss:     2.2945 Validation Accuracy: 0.108000\n",
      "Epoch  2, CIFAR-10 Batch 3:  Loss:     2.2951 Validation Accuracy: 0.115000\n",
      "Epoch  2, CIFAR-10 Batch 4:  Loss:     2.2828 Validation Accuracy: 0.114800\n",
      "Epoch  2, CIFAR-10 Batch 5:  Loss:     2.2695 Validation Accuracy: 0.115200\n",
      "Epoch  3, CIFAR-10 Batch 1:  Loss:     2.2485 Validation Accuracy: 0.128200\n",
      "Epoch  3, CIFAR-10 Batch 2:  Loss:     2.2371 Validation Accuracy: 0.160800\n",
      "Epoch  3, CIFAR-10 Batch 3:  Loss:     2.2287 Validation Accuracy: 0.156800\n",
      "Epoch  3, CIFAR-10 Batch 4:  Loss:     2.2089 Validation Accuracy: 0.158200\n",
      "Epoch  3, CIFAR-10 Batch 5:  Loss:     2.2019 Validation Accuracy: 0.160000\n",
      "Epoch  4, CIFAR-10 Batch 1:  Loss:     2.1856 Validation Accuracy: 0.168600\n",
      "Epoch  4, CIFAR-10 Batch 2:  Loss:     2.1934 Validation Accuracy: 0.183600\n",
      "Epoch  4, CIFAR-10 Batch 3:  Loss:     2.1959 Validation Accuracy: 0.191600\n",
      "Epoch  4, CIFAR-10 Batch 4:  Loss:     2.1517 Validation Accuracy: 0.183800\n",
      "Epoch  4, CIFAR-10 Batch 5:  Loss:     2.1530 Validation Accuracy: 0.186800\n",
      "Epoch  5, CIFAR-10 Batch 1:  Loss:     2.1260 Validation Accuracy: 0.187200\n",
      "Epoch  5, CIFAR-10 Batch 2:  Loss:     2.1163 Validation Accuracy: 0.214400\n",
      "Epoch  5, CIFAR-10 Batch 3:  Loss:     2.1056 Validation Accuracy: 0.214800\n",
      "Epoch  5, CIFAR-10 Batch 4:  Loss:     2.0666 Validation Accuracy: 0.200800\n",
      "Epoch  5, CIFAR-10 Batch 5:  Loss:     2.0597 Validation Accuracy: 0.227800\n",
      "Epoch  6, CIFAR-10 Batch 1:  Loss:     2.0603 Validation Accuracy: 0.241800\n",
      "Epoch  6, CIFAR-10 Batch 2:  Loss:     2.0401 Validation Accuracy: 0.240400\n",
      "Epoch  6, CIFAR-10 Batch 3:  Loss:     2.0458 Validation Accuracy: 0.229600\n",
      "Epoch  6, CIFAR-10 Batch 4:  Loss:     2.0231 Validation Accuracy: 0.231800\n",
      "Epoch  6, CIFAR-10 Batch 5:  Loss:     2.0161 Validation Accuracy: 0.240800\n",
      "Epoch  7, CIFAR-10 Batch 1:  Loss:     2.0403 Validation Accuracy: 0.248600\n",
      "Epoch  7, CIFAR-10 Batch 2:  Loss:     2.0139 Validation Accuracy: 0.251000\n",
      "Epoch  7, CIFAR-10 Batch 3:  Loss:     2.0149 Validation Accuracy: 0.247200\n",
      "Epoch  7, CIFAR-10 Batch 4:  Loss:     2.0000 Validation Accuracy: 0.240400\n",
      "Epoch  7, CIFAR-10 Batch 5:  Loss:     2.0043 Validation Accuracy: 0.248400\n",
      "Epoch  8, CIFAR-10 Batch 1:  Loss:     2.0263 Validation Accuracy: 0.242600\n",
      "Epoch  8, CIFAR-10 Batch 2:  Loss:     2.0006 Validation Accuracy: 0.253400\n",
      "Epoch  8, CIFAR-10 Batch 3:  Loss:     1.9958 Validation Accuracy: 0.251800\n",
      "Epoch  8, CIFAR-10 Batch 4:  Loss:     1.9809 Validation Accuracy: 0.252400\n",
      "Epoch  8, CIFAR-10 Batch 5:  Loss:     1.9868 Validation Accuracy: 0.247600\n",
      "Epoch  9, CIFAR-10 Batch 1:  Loss:     2.0143 Validation Accuracy: 0.242600\n",
      "Epoch  9, CIFAR-10 Batch 2:  Loss:     1.9960 Validation Accuracy: 0.252600\n",
      "Epoch  9, CIFAR-10 Batch 3:  Loss:     1.9910 Validation Accuracy: 0.250800\n",
      "Epoch  9, CIFAR-10 Batch 4:  Loss:     1.9714 Validation Accuracy: 0.249200\n",
      "Epoch  9, CIFAR-10 Batch 5:  Loss:     1.9777 Validation Accuracy: 0.249000\n",
      "Epoch 10, CIFAR-10 Batch 1:  Loss:     1.9981 Validation Accuracy: 0.257600\n",
      "Epoch 10, CIFAR-10 Batch 2:  Loss:     1.9745 Validation Accuracy: 0.260400\n",
      "Epoch 10, CIFAR-10 Batch 3:  Loss:     1.9757 Validation Accuracy: 0.255600\n",
      "Epoch 10, CIFAR-10 Batch 4:  Loss:     1.9591 Validation Accuracy: 0.255800\n",
      "Epoch 10, CIFAR-10 Batch 5:  Loss:     1.9668 Validation Accuracy: 0.253000\n",
      "Epoch 11, CIFAR-10 Batch 1:  Loss:     1.9915 Validation Accuracy: 0.251800\n",
      "Epoch 11, CIFAR-10 Batch 2:  Loss:     1.9671 Validation Accuracy: 0.257600\n",
      "Epoch 11, CIFAR-10 Batch 3:  Loss:     1.9670 Validation Accuracy: 0.255800\n",
      "Epoch 11, CIFAR-10 Batch 4:  Loss:     1.9469 Validation Accuracy: 0.253000\n",
      "Epoch 11, CIFAR-10 Batch 5:  Loss:     1.9575 Validation Accuracy: 0.251200\n",
      "Epoch 12, CIFAR-10 Batch 1:  Loss:     1.9825 Validation Accuracy: 0.254400\n",
      "Epoch 12, CIFAR-10 Batch 2:  Loss:     1.9636 Validation Accuracy: 0.258000\n",
      "Epoch 12, CIFAR-10 Batch 3:  Loss:     1.9616 Validation Accuracy: 0.256000\n",
      "Epoch 12, CIFAR-10 Batch 4:  Loss:     1.9378 Validation Accuracy: 0.255600\n",
      "Epoch 12, CIFAR-10 Batch 5:  Loss:     1.9435 Validation Accuracy: 0.254200\n",
      "Epoch 13, CIFAR-10 Batch 1:  Loss:     1.9642 Validation Accuracy: 0.260600\n",
      "Epoch 13, CIFAR-10 Batch 2:  Loss:     1.9419 Validation Accuracy: 0.261400\n",
      "Epoch 13, CIFAR-10 Batch 3:  Loss:     1.9379 Validation Accuracy: 0.260800\n",
      "Epoch 13, CIFAR-10 Batch 4:  Loss:     1.9244 Validation Accuracy: 0.261800\n",
      "Epoch 13, CIFAR-10 Batch 5:  Loss:     1.9286 Validation Accuracy: 0.261800\n",
      "Epoch 14, CIFAR-10 Batch 1:  Loss:     1.9490 Validation Accuracy: 0.266200\n",
      "Epoch 14, CIFAR-10 Batch 2:  Loss:     1.9270 Validation Accuracy: 0.268800\n",
      "Epoch 14, CIFAR-10 Batch 3:  Loss:     1.9168 Validation Accuracy: 0.267600\n",
      "Epoch 14, CIFAR-10 Batch 4:  Loss:     1.9079 Validation Accuracy: 0.268400\n",
      "Epoch 14, CIFAR-10 Batch 5:  Loss:     1.9103 Validation Accuracy: 0.268000\n",
      "Epoch 15, CIFAR-10 Batch 1:  Loss:     1.9341 Validation Accuracy: 0.264600\n",
      "Epoch 15, CIFAR-10 Batch 2:  Loss:     1.9102 Validation Accuracy: 0.275200\n",
      "Epoch 15, CIFAR-10 Batch 3:  Loss:     1.8910 Validation Accuracy: 0.271400\n",
      "Epoch 15, CIFAR-10 Batch 4:  Loss:     1.8889 Validation Accuracy: 0.271800\n",
      "Epoch 15, CIFAR-10 Batch 5:  Loss:     1.8935 Validation Accuracy: 0.271600\n",
      "Epoch 16, CIFAR-10 Batch 1:  Loss:     1.9169 Validation Accuracy: 0.275200\n",
      "Epoch 16, CIFAR-10 Batch 2:  Loss:     1.8929 Validation Accuracy: 0.278800\n",
      "Epoch 16, CIFAR-10 Batch 3:  Loss:     1.8637 Validation Accuracy: 0.273200\n",
      "Epoch 16, CIFAR-10 Batch 4:  Loss:     1.8731 Validation Accuracy: 0.274200\n",
      "Epoch 16, CIFAR-10 Batch 5:  Loss:     1.8810 Validation Accuracy: 0.277800\n",
      "Epoch 17, CIFAR-10 Batch 1:  Loss:     1.8981 Validation Accuracy: 0.280800\n",
      "Epoch 17, CIFAR-10 Batch 2:  Loss:     1.8795 Validation Accuracy: 0.282000\n",
      "Epoch 17, CIFAR-10 Batch 3:  Loss:     1.8442 Validation Accuracy: 0.283400\n",
      "Epoch 17, CIFAR-10 Batch 4:  Loss:     1.8591 Validation Accuracy: 0.281400\n",
      "Epoch 17, CIFAR-10 Batch 5:  Loss:     1.8696 Validation Accuracy: 0.286600\n",
      "Epoch 18, CIFAR-10 Batch 1:  Loss:     1.8828 Validation Accuracy: 0.285400\n",
      "Epoch 18, CIFAR-10 Batch 2:  Loss:     1.8672 Validation Accuracy: 0.292200\n",
      "Epoch 18, CIFAR-10 Batch 3:  Loss:     1.8314 Validation Accuracy: 0.289600\n",
      "Epoch 18, CIFAR-10 Batch 4:  Loss:     1.8460 Validation Accuracy: 0.285600\n",
      "Epoch 18, CIFAR-10 Batch 5:  Loss:     1.8573 Validation Accuracy: 0.294400\n",
      "Epoch 19, CIFAR-10 Batch 1:  Loss:     1.8682 Validation Accuracy: 0.294800\n",
      "Epoch 19, CIFAR-10 Batch 2:  Loss:     1.8568 Validation Accuracy: 0.295800\n",
      "Epoch 19, CIFAR-10 Batch 3:  Loss:     1.8203 Validation Accuracy: 0.294400\n",
      "Epoch 19, CIFAR-10 Batch 4:  Loss:     1.8329 Validation Accuracy: 0.289000\n",
      "Epoch 19, CIFAR-10 Batch 5:  Loss:     1.8448 Validation Accuracy: 0.298000\n",
      "Epoch 20, CIFAR-10 Batch 1:  Loss:     1.8554 Validation Accuracy: 0.299000\n",
      "Epoch 20, CIFAR-10 Batch 2:  Loss:     1.8427 Validation Accuracy: 0.301800\n",
      "Epoch 20, CIFAR-10 Batch 3:  Loss:     1.8081 Validation Accuracy: 0.298800\n",
      "Epoch 20, CIFAR-10 Batch 4:  Loss:     1.8184 Validation Accuracy: 0.297800\n",
      "Epoch 20, CIFAR-10 Batch 5:  Loss:     1.8355 Validation Accuracy: 0.303600\n",
      "Epoch 21, CIFAR-10 Batch 1:  Loss:     1.8436 Validation Accuracy: 0.303200\n",
      "Epoch 21, CIFAR-10 Batch 2:  Loss:     1.8362 Validation Accuracy: 0.306600\n",
      "Epoch 21, CIFAR-10 Batch 3:  Loss:     1.7985 Validation Accuracy: 0.305200\n",
      "Epoch 21, CIFAR-10 Batch 4:  Loss:     1.8092 Validation Accuracy: 0.303400\n",
      "Epoch 21, CIFAR-10 Batch 5:  Loss:     1.8238 Validation Accuracy: 0.311000\n",
      "Epoch 22, CIFAR-10 Batch 1:  Loss:     1.8313 Validation Accuracy: 0.314000\n",
      "Epoch 22, CIFAR-10 Batch 2:  Loss:     1.8215 Validation Accuracy: 0.312800\n",
      "Epoch 22, CIFAR-10 Batch 3:  Loss:     1.7860 Validation Accuracy: 0.315600\n",
      "Epoch 22, CIFAR-10 Batch 4:  Loss:     1.7972 Validation Accuracy: 0.308200\n",
      "Epoch 22, CIFAR-10 Batch 5:  Loss:     1.8168 Validation Accuracy: 0.314200\n",
      "Epoch 23, CIFAR-10 Batch 1:  Loss:     1.8183 Validation Accuracy: 0.320800\n",
      "Epoch 23, CIFAR-10 Batch 2:  Loss:     1.8104 Validation Accuracy: 0.319400\n",
      "Epoch 23, CIFAR-10 Batch 3:  Loss:     1.7743 Validation Accuracy: 0.318000\n",
      "Epoch 23, CIFAR-10 Batch 4:  Loss:     1.7824 Validation Accuracy: 0.315200\n",
      "Epoch 23, CIFAR-10 Batch 5:  Loss:     1.8055 Validation Accuracy: 0.320800\n",
      "Epoch 24, CIFAR-10 Batch 1:  Loss:     1.8031 Validation Accuracy: 0.320400\n",
      "Epoch 24, CIFAR-10 Batch 2:  Loss:     1.7962 Validation Accuracy: 0.328800\n",
      "Epoch 24, CIFAR-10 Batch 3:  Loss:     1.7633 Validation Accuracy: 0.326600\n",
      "Epoch 24, CIFAR-10 Batch 4:  Loss:     1.7747 Validation Accuracy: 0.320000\n",
      "Epoch 24, CIFAR-10 Batch 5:  Loss:     1.7967 Validation Accuracy: 0.326600\n",
      "Epoch 25, CIFAR-10 Batch 1:  Loss:     1.7949 Validation Accuracy: 0.326000\n",
      "Epoch 25, CIFAR-10 Batch 2:  Loss:     1.7872 Validation Accuracy: 0.330000\n",
      "Epoch 25, CIFAR-10 Batch 3:  Loss:     1.7519 Validation Accuracy: 0.334600\n",
      "Epoch 25, CIFAR-10 Batch 4:  Loss:     1.7606 Validation Accuracy: 0.331800\n",
      "Epoch 25, CIFAR-10 Batch 5:  Loss:     1.7821 Validation Accuracy: 0.335200\n",
      "Epoch 26, CIFAR-10 Batch 1:  Loss:     1.7749 Validation Accuracy: 0.338200\n",
      "Epoch 26, CIFAR-10 Batch 2:  Loss:     1.7762 Validation Accuracy: 0.336000\n",
      "Epoch 26, CIFAR-10 Batch 3:  Loss:     1.7399 Validation Accuracy: 0.342600\n",
      "Epoch 26, CIFAR-10 Batch 4:  Loss:     1.7528 Validation Accuracy: 0.339800\n",
      "Epoch 26, CIFAR-10 Batch 5:  Loss:     1.7703 Validation Accuracy: 0.342200\n",
      "Epoch 27, CIFAR-10 Batch 1:  Loss:     1.7657 Validation Accuracy: 0.346000\n",
      "Epoch 27, CIFAR-10 Batch 2:  Loss:     1.7641 Validation Accuracy: 0.343600\n",
      "Epoch 27, CIFAR-10 Batch 3:  Loss:     1.7305 Validation Accuracy: 0.341600\n",
      "Epoch 27, CIFAR-10 Batch 4:  Loss:     1.7469 Validation Accuracy: 0.339000\n",
      "Epoch 27, CIFAR-10 Batch 5:  Loss:     1.7704 Validation Accuracy: 0.343000\n",
      "Epoch 28, CIFAR-10 Batch 1:  Loss:     1.7494 Validation Accuracy: 0.345600\n",
      "Epoch 28, CIFAR-10 Batch 2:  Loss:     1.7528 Validation Accuracy: 0.345600\n",
      "Epoch 28, CIFAR-10 Batch 3:  Loss:     1.7164 Validation Accuracy: 0.353800\n",
      "Epoch 28, CIFAR-10 Batch 4:  Loss:     1.7251 Validation Accuracy: 0.348400\n",
      "Epoch 28, CIFAR-10 Batch 5:  Loss:     1.7518 Validation Accuracy: 0.348800\n",
      "Epoch 29, CIFAR-10 Batch 1:  Loss:     1.7344 Validation Accuracy: 0.346800\n",
      "Epoch 29, CIFAR-10 Batch 2:  Loss:     1.7410 Validation Accuracy: 0.348200\n",
      "Epoch 29, CIFAR-10 Batch 3:  Loss:     1.7058 Validation Accuracy: 0.348800\n",
      "Epoch 29, CIFAR-10 Batch 4:  Loss:     1.7165 Validation Accuracy: 0.349400\n",
      "Epoch 29, CIFAR-10 Batch 5:  Loss:     1.7454 Validation Accuracy: 0.350200\n",
      "Epoch 30, CIFAR-10 Batch 1:  Loss:     1.7231 Validation Accuracy: 0.353400\n",
      "Epoch 30, CIFAR-10 Batch 2:  Loss:     1.7345 Validation Accuracy: 0.352000\n",
      "Epoch 30, CIFAR-10 Batch 3:  Loss:     1.6990 Validation Accuracy: 0.348800\n",
      "Epoch 30, CIFAR-10 Batch 4:  Loss:     1.7099 Validation Accuracy: 0.350000\n",
      "Epoch 30, CIFAR-10 Batch 5:  Loss:     1.7387 Validation Accuracy: 0.349400\n",
      "Epoch 31, CIFAR-10 Batch 1:  Loss:     1.7211 Validation Accuracy: 0.352400\n",
      "Epoch 31, CIFAR-10 Batch 2:  Loss:     1.7286 Validation Accuracy: 0.354000\n",
      "Epoch 31, CIFAR-10 Batch 3:  Loss:     1.6904 Validation Accuracy: 0.357000\n",
      "Epoch 31, CIFAR-10 Batch 4:  Loss:     1.7020 Validation Accuracy: 0.351000\n",
      "Epoch 31, CIFAR-10 Batch 5:  Loss:     1.7370 Validation Accuracy: 0.350800\n",
      "Epoch 32, CIFAR-10 Batch 1:  Loss:     1.7098 Validation Accuracy: 0.356200\n",
      "Epoch 32, CIFAR-10 Batch 2:  Loss:     1.7254 Validation Accuracy: 0.359400\n",
      "Epoch 32, CIFAR-10 Batch 3:  Loss:     1.6829 Validation Accuracy: 0.356800\n",
      "Epoch 32, CIFAR-10 Batch 4:  Loss:     1.6866 Validation Accuracy: 0.361600\n",
      "Epoch 32, CIFAR-10 Batch 5:  Loss:     1.7212 Validation Accuracy: 0.356200\n",
      "Epoch 33, CIFAR-10 Batch 1:  Loss:     1.6976 Validation Accuracy: 0.361000\n",
      "Epoch 33, CIFAR-10 Batch 2:  Loss:     1.7154 Validation Accuracy: 0.362600\n",
      "Epoch 33, CIFAR-10 Batch 3:  Loss:     1.6781 Validation Accuracy: 0.359800\n",
      "Epoch 33, CIFAR-10 Batch 4:  Loss:     1.6826 Validation Accuracy: 0.360600\n",
      "Epoch 33, CIFAR-10 Batch 5:  Loss:     1.7166 Validation Accuracy: 0.358200\n",
      "Epoch 34, CIFAR-10 Batch 1:  Loss:     1.6944 Validation Accuracy: 0.363000\n",
      "Epoch 34, CIFAR-10 Batch 2:  Loss:     1.7103 Validation Accuracy: 0.362000\n",
      "Epoch 34, CIFAR-10 Batch 3:  Loss:     1.6733 Validation Accuracy: 0.362000\n",
      "Epoch 34, CIFAR-10 Batch 4:  Loss:     1.6842 Validation Accuracy: 0.356200\n",
      "Epoch 34, CIFAR-10 Batch 5:  Loss:     1.7197 Validation Accuracy: 0.361600\n",
      "Epoch 35, CIFAR-10 Batch 1:  Loss:     1.6934 Validation Accuracy: 0.365400\n",
      "Epoch 35, CIFAR-10 Batch 2:  Loss:     1.7086 Validation Accuracy: 0.364400\n",
      "Epoch 35, CIFAR-10 Batch 3:  Loss:     1.6601 Validation Accuracy: 0.368600\n",
      "Epoch 35, CIFAR-10 Batch 4:  Loss:     1.6638 Validation Accuracy: 0.367000\n",
      "Epoch 35, CIFAR-10 Batch 5:  Loss:     1.7018 Validation Accuracy: 0.363600\n",
      "Epoch 36, CIFAR-10 Batch 1:  Loss:     1.6801 Validation Accuracy: 0.364800\n",
      "Epoch 36, CIFAR-10 Batch 2:  Loss:     1.6990 Validation Accuracy: 0.367000\n",
      "Epoch 36, CIFAR-10 Batch 3:  Loss:     1.6574 Validation Accuracy: 0.368600\n",
      "Epoch 36, CIFAR-10 Batch 4:  Loss:     1.6645 Validation Accuracy: 0.369800\n",
      "Epoch 36, CIFAR-10 Batch 5:  Loss:     1.6926 Validation Accuracy: 0.368400\n",
      "Epoch 37, CIFAR-10 Batch 1:  Loss:     1.6807 Validation Accuracy: 0.365000\n",
      "Epoch 37, CIFAR-10 Batch 2:  Loss:     1.6943 Validation Accuracy: 0.369400\n",
      "Epoch 37, CIFAR-10 Batch 3:  Loss:     1.6531 Validation Accuracy: 0.372800\n",
      "Epoch 37, CIFAR-10 Batch 4:  Loss:     1.6514 Validation Accuracy: 0.369200\n",
      "Epoch 37, CIFAR-10 Batch 5:  Loss:     1.6903 Validation Accuracy: 0.372000\n",
      "Epoch 38, CIFAR-10 Batch 1:  Loss:     1.6667 Validation Accuracy: 0.371400\n",
      "Epoch 38, CIFAR-10 Batch 2:  Loss:     1.6858 Validation Accuracy: 0.375000\n",
      "Epoch 38, CIFAR-10 Batch 3:  Loss:     1.6423 Validation Accuracy: 0.373600\n",
      "Epoch 38, CIFAR-10 Batch 4:  Loss:     1.6450 Validation Accuracy: 0.370000\n",
      "Epoch 38, CIFAR-10 Batch 5:  Loss:     1.6813 Validation Accuracy: 0.371600\n",
      "Epoch 39, CIFAR-10 Batch 1:  Loss:     1.6611 Validation Accuracy: 0.375200\n",
      "Epoch 39, CIFAR-10 Batch 2:  Loss:     1.6809 Validation Accuracy: 0.372200\n",
      "Epoch 39, CIFAR-10 Batch 3:  Loss:     1.6381 Validation Accuracy: 0.377600\n",
      "Epoch 39, CIFAR-10 Batch 4:  Loss:     1.6531 Validation Accuracy: 0.370600\n",
      "Epoch 39, CIFAR-10 Batch 5:  Loss:     1.6796 Validation Accuracy: 0.375000\n",
      "Epoch 40, CIFAR-10 Batch 1:  Loss:     1.6646 Validation Accuracy: 0.370600\n",
      "Epoch 40, CIFAR-10 Batch 2:  Loss:     1.6807 Validation Accuracy: 0.373400\n",
      "Epoch 40, CIFAR-10 Batch 3:  Loss:     1.6337 Validation Accuracy: 0.377600\n",
      "Epoch 40, CIFAR-10 Batch 4:  Loss:     1.6340 Validation Accuracy: 0.377400\n",
      "Epoch 40, CIFAR-10 Batch 5:  Loss:     1.6712 Validation Accuracy: 0.380200\n",
      "Epoch 41, CIFAR-10 Batch 1:  Loss:     1.6481 Validation Accuracy: 0.378400\n",
      "Epoch 41, CIFAR-10 Batch 2:  Loss:     1.6726 Validation Accuracy: 0.379400\n",
      "Epoch 41, CIFAR-10 Batch 3:  Loss:     1.6271 Validation Accuracy: 0.378000\n",
      "Epoch 41, CIFAR-10 Batch 4:  Loss:     1.6275 Validation Accuracy: 0.379400\n",
      "Epoch 41, CIFAR-10 Batch 5:  Loss:     1.6608 Validation Accuracy: 0.379400\n",
      "Epoch 42, CIFAR-10 Batch 1:  Loss:     1.6424 Validation Accuracy: 0.378000\n",
      "Epoch 42, CIFAR-10 Batch 2:  Loss:     1.6667 Validation Accuracy: 0.381000\n",
      "Epoch 42, CIFAR-10 Batch 3:  Loss:     1.6200 Validation Accuracy: 0.381200\n",
      "Epoch 42, CIFAR-10 Batch 4:  Loss:     1.6255 Validation Accuracy: 0.383200\n",
      "Epoch 42, CIFAR-10 Batch 5:  Loss:     1.6557 Validation Accuracy: 0.380600\n",
      "Epoch 43, CIFAR-10 Batch 1:  Loss:     1.6354 Validation Accuracy: 0.379800\n",
      "Epoch 43, CIFAR-10 Batch 2:  Loss:     1.6534 Validation Accuracy: 0.382400\n",
      "Epoch 43, CIFAR-10 Batch 3:  Loss:     1.6119 Validation Accuracy: 0.383200\n",
      "Epoch 43, CIFAR-10 Batch 4:  Loss:     1.6158 Validation Accuracy: 0.379000\n",
      "Epoch 43, CIFAR-10 Batch 5:  Loss:     1.6490 Validation Accuracy: 0.380800\n",
      "Epoch 44, CIFAR-10 Batch 1:  Loss:     1.6300 Validation Accuracy: 0.381800\n",
      "Epoch 44, CIFAR-10 Batch 2:  Loss:     1.6484 Validation Accuracy: 0.383400\n",
      "Epoch 44, CIFAR-10 Batch 3:  Loss:     1.6055 Validation Accuracy: 0.384600\n",
      "Epoch 44, CIFAR-10 Batch 4:  Loss:     1.6141 Validation Accuracy: 0.381800\n",
      "Epoch 44, CIFAR-10 Batch 5:  Loss:     1.6449 Validation Accuracy: 0.380200\n",
      "Epoch 45, CIFAR-10 Batch 1:  Loss:     1.6233 Validation Accuracy: 0.382400\n",
      "Epoch 45, CIFAR-10 Batch 2:  Loss:     1.6440 Validation Accuracy: 0.382400\n",
      "Epoch 45, CIFAR-10 Batch 3:  Loss:     1.6014 Validation Accuracy: 0.386800\n",
      "Epoch 45, CIFAR-10 Batch 4:  Loss:     1.6076 Validation Accuracy: 0.383000\n",
      "Epoch 45, CIFAR-10 Batch 5:  Loss:     1.6341 Validation Accuracy: 0.382800\n",
      "Epoch 46, CIFAR-10 Batch 1:  Loss:     1.6187 Validation Accuracy: 0.384400\n",
      "Epoch 46, CIFAR-10 Batch 2:  Loss:     1.6375 Validation Accuracy: 0.381800\n",
      "Epoch 46, CIFAR-10 Batch 3:  Loss:     1.5926 Validation Accuracy: 0.384200\n",
      "Epoch 46, CIFAR-10 Batch 4:  Loss:     1.6002 Validation Accuracy: 0.382600\n",
      "Epoch 46, CIFAR-10 Batch 5:  Loss:     1.6281 Validation Accuracy: 0.384800\n",
      "Epoch 47, CIFAR-10 Batch 1:  Loss:     1.6114 Validation Accuracy: 0.382400\n",
      "Epoch 47, CIFAR-10 Batch 2:  Loss:     1.6342 Validation Accuracy: 0.385200\n",
      "Epoch 47, CIFAR-10 Batch 3:  Loss:     1.5905 Validation Accuracy: 0.391800\n",
      "Epoch 47, CIFAR-10 Batch 4:  Loss:     1.5972 Validation Accuracy: 0.384400\n",
      "Epoch 47, CIFAR-10 Batch 5:  Loss:     1.6264 Validation Accuracy: 0.385200\n",
      "Epoch 48, CIFAR-10 Batch 1:  Loss:     1.6059 Validation Accuracy: 0.384000\n",
      "Epoch 48, CIFAR-10 Batch 2:  Loss:     1.6279 Validation Accuracy: 0.387200\n",
      "Epoch 48, CIFAR-10 Batch 3:  Loss:     1.5797 Validation Accuracy: 0.388800\n",
      "Epoch 48, CIFAR-10 Batch 4:  Loss:     1.5844 Validation Accuracy: 0.384200\n",
      "Epoch 48, CIFAR-10 Batch 5:  Loss:     1.6147 Validation Accuracy: 0.386200\n",
      "Epoch 49, CIFAR-10 Batch 1:  Loss:     1.5962 Validation Accuracy: 0.386800\n",
      "Epoch 49, CIFAR-10 Batch 2:  Loss:     1.6206 Validation Accuracy: 0.389400\n",
      "Epoch 49, CIFAR-10 Batch 3:  Loss:     1.5689 Validation Accuracy: 0.391200\n",
      "Epoch 49, CIFAR-10 Batch 4:  Loss:     1.5796 Validation Accuracy: 0.385800\n",
      "Epoch 49, CIFAR-10 Batch 5:  Loss:     1.6057 Validation Accuracy: 0.389200\n",
      "Epoch 50, CIFAR-10 Batch 1:  Loss:     1.5923 Validation Accuracy: 0.389800\n",
      "Epoch 50, CIFAR-10 Batch 2:  Loss:     1.6142 Validation Accuracy: 0.387400\n",
      "Epoch 50, CIFAR-10 Batch 3:  Loss:     1.5631 Validation Accuracy: 0.390400\n",
      "Epoch 50, CIFAR-10 Batch 4:  Loss:     1.5781 Validation Accuracy: 0.389600\n",
      "Epoch 50, CIFAR-10 Batch 5:  Loss:     1.6029 Validation Accuracy: 0.387600\n",
      "Epoch 51, CIFAR-10 Batch 1:  Loss:     1.5852 Validation Accuracy: 0.388600\n",
      "Epoch 51, CIFAR-10 Batch 2:  Loss:     1.6108 Validation Accuracy: 0.391800\n",
      "Epoch 51, CIFAR-10 Batch 3:  Loss:     1.5523 Validation Accuracy: 0.392000\n",
      "Epoch 51, CIFAR-10 Batch 4:  Loss:     1.5649 Validation Accuracy: 0.389800\n",
      "Epoch 51, CIFAR-10 Batch 5:  Loss:     1.5940 Validation Accuracy: 0.390200\n",
      "Epoch 52, CIFAR-10 Batch 1:  Loss:     1.5716 Validation Accuracy: 0.394400\n",
      "Epoch 52, CIFAR-10 Batch 2:  Loss:     1.6048 Validation Accuracy: 0.392000\n",
      "Epoch 52, CIFAR-10 Batch 3:  Loss:     1.5459 Validation Accuracy: 0.394400\n",
      "Epoch 52, CIFAR-10 Batch 4:  Loss:     1.5584 Validation Accuracy: 0.392800\n",
      "Epoch 52, CIFAR-10 Batch 5:  Loss:     1.5901 Validation Accuracy: 0.395200\n",
      "Epoch 53, CIFAR-10 Batch 1:  Loss:     1.5667 Validation Accuracy: 0.394000\n",
      "Epoch 53, CIFAR-10 Batch 2:  Loss:     1.5986 Validation Accuracy: 0.395800\n",
      "Epoch 53, CIFAR-10 Batch 3:  Loss:     1.5324 Validation Accuracy: 0.397800\n",
      "Epoch 53, CIFAR-10 Batch 4:  Loss:     1.5528 Validation Accuracy: 0.397800\n",
      "Epoch 53, CIFAR-10 Batch 5:  Loss:     1.5828 Validation Accuracy: 0.397800\n",
      "Epoch 54, CIFAR-10 Batch 1:  Loss:     1.5601 Validation Accuracy: 0.396400\n",
      "Epoch 54, CIFAR-10 Batch 2:  Loss:     1.5922 Validation Accuracy: 0.397600\n",
      "Epoch 54, CIFAR-10 Batch 3:  Loss:     1.5304 Validation Accuracy: 0.397000\n",
      "Epoch 54, CIFAR-10 Batch 4:  Loss:     1.5482 Validation Accuracy: 0.404200\n",
      "Epoch 54, CIFAR-10 Batch 5:  Loss:     1.5785 Validation Accuracy: 0.397600\n",
      "Epoch 55, CIFAR-10 Batch 1:  Loss:     1.5503 Validation Accuracy: 0.402600\n",
      "Epoch 55, CIFAR-10 Batch 2:  Loss:     1.5907 Validation Accuracy: 0.399600\n",
      "Epoch 55, CIFAR-10 Batch 3:  Loss:     1.5183 Validation Accuracy: 0.404400\n",
      "Epoch 55, CIFAR-10 Batch 4:  Loss:     1.5483 Validation Accuracy: 0.400800\n",
      "Epoch 55, CIFAR-10 Batch 5:  Loss:     1.5725 Validation Accuracy: 0.403000\n",
      "Epoch 56, CIFAR-10 Batch 1:  Loss:     1.5442 Validation Accuracy: 0.403800\n",
      "Epoch 56, CIFAR-10 Batch 2:  Loss:     1.5881 Validation Accuracy: 0.397800\n",
      "Epoch 56, CIFAR-10 Batch 3:  Loss:     1.5100 Validation Accuracy: 0.402600\n",
      "Epoch 56, CIFAR-10 Batch 4:  Loss:     1.5418 Validation Accuracy: 0.408600\n",
      "Epoch 56, CIFAR-10 Batch 5:  Loss:     1.5618 Validation Accuracy: 0.404800\n",
      "Epoch 57, CIFAR-10 Batch 1:  Loss:     1.5387 Validation Accuracy: 0.403200\n",
      "Epoch 57, CIFAR-10 Batch 2:  Loss:     1.5725 Validation Accuracy: 0.404800\n",
      "Epoch 57, CIFAR-10 Batch 3:  Loss:     1.5004 Validation Accuracy: 0.408800\n",
      "Epoch 57, CIFAR-10 Batch 4:  Loss:     1.5336 Validation Accuracy: 0.410200\n",
      "Epoch 57, CIFAR-10 Batch 5:  Loss:     1.5552 Validation Accuracy: 0.401800\n",
      "Epoch 58, CIFAR-10 Batch 1:  Loss:     1.5294 Validation Accuracy: 0.408200\n",
      "Epoch 58, CIFAR-10 Batch 2:  Loss:     1.5610 Validation Accuracy: 0.409200\n",
      "Epoch 58, CIFAR-10 Batch 3:  Loss:     1.4941 Validation Accuracy: 0.408800\n",
      "Epoch 58, CIFAR-10 Batch 4:  Loss:     1.5324 Validation Accuracy: 0.406200\n",
      "Epoch 58, CIFAR-10 Batch 5:  Loss:     1.5519 Validation Accuracy: 0.405200\n",
      "Epoch 59, CIFAR-10 Batch 1:  Loss:     1.5240 Validation Accuracy: 0.405000\n",
      "Epoch 59, CIFAR-10 Batch 2:  Loss:     1.5533 Validation Accuracy: 0.410200\n",
      "Epoch 59, CIFAR-10 Batch 3:  Loss:     1.4874 Validation Accuracy: 0.412000\n",
      "Epoch 59, CIFAR-10 Batch 4:  Loss:     1.5143 Validation Accuracy: 0.410400\n",
      "Epoch 59, CIFAR-10 Batch 5:  Loss:     1.5475 Validation Accuracy: 0.406600\n",
      "Epoch 60, CIFAR-10 Batch 1:  Loss:     1.5129 Validation Accuracy: 0.409800\n",
      "Epoch 60, CIFAR-10 Batch 2:  Loss:     1.5516 Validation Accuracy: 0.412600\n",
      "Epoch 60, CIFAR-10 Batch 3:  Loss:     1.4807 Validation Accuracy: 0.411400\n",
      "Epoch 60, CIFAR-10 Batch 4:  Loss:     1.5137 Validation Accuracy: 0.413600\n",
      "Epoch 60, CIFAR-10 Batch 5:  Loss:     1.5423 Validation Accuracy: 0.408000\n",
      "Epoch 61, CIFAR-10 Batch 1:  Loss:     1.5113 Validation Accuracy: 0.410000\n",
      "Epoch 61, CIFAR-10 Batch 2:  Loss:     1.5468 Validation Accuracy: 0.413200\n",
      "Epoch 61, CIFAR-10 Batch 3:  Loss:     1.4747 Validation Accuracy: 0.415800\n",
      "Epoch 61, CIFAR-10 Batch 4:  Loss:     1.5050 Validation Accuracy: 0.415200\n",
      "Epoch 61, CIFAR-10 Batch 5:  Loss:     1.5358 Validation Accuracy: 0.410400\n",
      "Epoch 62, CIFAR-10 Batch 1:  Loss:     1.5063 Validation Accuracy: 0.414200\n",
      "Epoch 62, CIFAR-10 Batch 2:  Loss:     1.5419 Validation Accuracy: 0.413000\n",
      "Epoch 62, CIFAR-10 Batch 3:  Loss:     1.4723 Validation Accuracy: 0.413800\n",
      "Epoch 62, CIFAR-10 Batch 4:  Loss:     1.4977 Validation Accuracy: 0.418400\n",
      "Epoch 62, CIFAR-10 Batch 5:  Loss:     1.5308 Validation Accuracy: 0.413800\n",
      "Epoch 63, CIFAR-10 Batch 1:  Loss:     1.4996 Validation Accuracy: 0.413800\n",
      "Epoch 63, CIFAR-10 Batch 2:  Loss:     1.5304 Validation Accuracy: 0.417000\n",
      "Epoch 63, CIFAR-10 Batch 3:  Loss:     1.4700 Validation Accuracy: 0.412800\n",
      "Epoch 63, CIFAR-10 Batch 4:  Loss:     1.4930 Validation Accuracy: 0.420400\n",
      "Epoch 63, CIFAR-10 Batch 5:  Loss:     1.5274 Validation Accuracy: 0.411600\n",
      "Epoch 64, CIFAR-10 Batch 1:  Loss:     1.4935 Validation Accuracy: 0.416400\n",
      "Epoch 64, CIFAR-10 Batch 2:  Loss:     1.5270 Validation Accuracy: 0.420400\n",
      "Epoch 64, CIFAR-10 Batch 3:  Loss:     1.4615 Validation Accuracy: 0.418000\n",
      "Epoch 64, CIFAR-10 Batch 4:  Loss:     1.4904 Validation Accuracy: 0.419000\n",
      "Epoch 64, CIFAR-10 Batch 5:  Loss:     1.5244 Validation Accuracy: 0.412000\n",
      "Epoch 65, CIFAR-10 Batch 1:  Loss:     1.4878 Validation Accuracy: 0.419400\n",
      "Epoch 65, CIFAR-10 Batch 2:  Loss:     1.5215 Validation Accuracy: 0.425000\n",
      "Epoch 65, CIFAR-10 Batch 3:  Loss:     1.4570 Validation Accuracy: 0.419600\n",
      "Epoch 65, CIFAR-10 Batch 4:  Loss:     1.4807 Validation Accuracy: 0.423600\n",
      "Epoch 65, CIFAR-10 Batch 5:  Loss:     1.5185 Validation Accuracy: 0.413200\n",
      "Epoch 66, CIFAR-10 Batch 1:  Loss:     1.4846 Validation Accuracy: 0.421600\n",
      "Epoch 66, CIFAR-10 Batch 2:  Loss:     1.5142 Validation Accuracy: 0.420000\n",
      "Epoch 66, CIFAR-10 Batch 3:  Loss:     1.4525 Validation Accuracy: 0.421200\n",
      "Epoch 66, CIFAR-10 Batch 4:  Loss:     1.4794 Validation Accuracy: 0.419800\n",
      "Epoch 66, CIFAR-10 Batch 5:  Loss:     1.5235 Validation Accuracy: 0.413600\n",
      "Epoch 67, CIFAR-10 Batch 1:  Loss:     1.4827 Validation Accuracy: 0.423000\n",
      "Epoch 67, CIFAR-10 Batch 2:  Loss:     1.5129 Validation Accuracy: 0.420600\n",
      "Epoch 67, CIFAR-10 Batch 3:  Loss:     1.4486 Validation Accuracy: 0.417400\n",
      "Epoch 67, CIFAR-10 Batch 4:  Loss:     1.4730 Validation Accuracy: 0.422200\n",
      "Epoch 67, CIFAR-10 Batch 5:  Loss:     1.5120 Validation Accuracy: 0.414000\n",
      "Epoch 68, CIFAR-10 Batch 1:  Loss:     1.4770 Validation Accuracy: 0.423000\n",
      "Epoch 68, CIFAR-10 Batch 2:  Loss:     1.5043 Validation Accuracy: 0.419200\n",
      "Epoch 68, CIFAR-10 Batch 3:  Loss:     1.4459 Validation Accuracy: 0.420400\n",
      "Epoch 68, CIFAR-10 Batch 4:  Loss:     1.4718 Validation Accuracy: 0.422800\n",
      "Epoch 68, CIFAR-10 Batch 5:  Loss:     1.5115 Validation Accuracy: 0.414800\n",
      "Epoch 69, CIFAR-10 Batch 1:  Loss:     1.4719 Validation Accuracy: 0.421600\n",
      "Epoch 69, CIFAR-10 Batch 2:  Loss:     1.4985 Validation Accuracy: 0.424000\n",
      "Epoch 69, CIFAR-10 Batch 3:  Loss:     1.4379 Validation Accuracy: 0.421000\n",
      "Epoch 69, CIFAR-10 Batch 4:  Loss:     1.4589 Validation Accuracy: 0.420600\n",
      "Epoch 69, CIFAR-10 Batch 5:  Loss:     1.5104 Validation Accuracy: 0.414000\n",
      "Epoch 70, CIFAR-10 Batch 1:  Loss:     1.4728 Validation Accuracy: 0.423600\n",
      "Epoch 70, CIFAR-10 Batch 2:  Loss:     1.4958 Validation Accuracy: 0.419600\n",
      "Epoch 70, CIFAR-10 Batch 3:  Loss:     1.4371 Validation Accuracy: 0.418600\n",
      "Epoch 70, CIFAR-10 Batch 4:  Loss:     1.4604 Validation Accuracy: 0.423800\n",
      "Epoch 70, CIFAR-10 Batch 5:  Loss:     1.5074 Validation Accuracy: 0.411400\n",
      "Epoch 71, CIFAR-10 Batch 1:  Loss:     1.4654 Validation Accuracy: 0.426600\n",
      "Epoch 71, CIFAR-10 Batch 2:  Loss:     1.4959 Validation Accuracy: 0.426800\n",
      "Epoch 71, CIFAR-10 Batch 3:  Loss:     1.4351 Validation Accuracy: 0.419800\n",
      "Epoch 71, CIFAR-10 Batch 4:  Loss:     1.4508 Validation Accuracy: 0.422400\n",
      "Epoch 71, CIFAR-10 Batch 5:  Loss:     1.4973 Validation Accuracy: 0.416800\n",
      "Epoch 72, CIFAR-10 Batch 1:  Loss:     1.4597 Validation Accuracy: 0.428000\n",
      "Epoch 72, CIFAR-10 Batch 2:  Loss:     1.4910 Validation Accuracy: 0.424000\n",
      "Epoch 72, CIFAR-10 Batch 3:  Loss:     1.4358 Validation Accuracy: 0.421800\n",
      "Epoch 72, CIFAR-10 Batch 4:  Loss:     1.4555 Validation Accuracy: 0.422000\n",
      "Epoch 72, CIFAR-10 Batch 5:  Loss:     1.5022 Validation Accuracy: 0.414200\n",
      "Epoch 73, CIFAR-10 Batch 1:  Loss:     1.4664 Validation Accuracy: 0.426800\n",
      "Epoch 73, CIFAR-10 Batch 2:  Loss:     1.4806 Validation Accuracy: 0.425400\n",
      "Epoch 73, CIFAR-10 Batch 3:  Loss:     1.4329 Validation Accuracy: 0.420600\n",
      "Epoch 73, CIFAR-10 Batch 4:  Loss:     1.4488 Validation Accuracy: 0.426400\n",
      "Epoch 73, CIFAR-10 Batch 5:  Loss:     1.5010 Validation Accuracy: 0.413000\n",
      "Epoch 74, CIFAR-10 Batch 1:  Loss:     1.4652 Validation Accuracy: 0.426600\n",
      "Epoch 74, CIFAR-10 Batch 2:  Loss:     1.4831 Validation Accuracy: 0.431000\n",
      "Epoch 74, CIFAR-10 Batch 3:  Loss:     1.4334 Validation Accuracy: 0.417000\n",
      "Epoch 74, CIFAR-10 Batch 4:  Loss:     1.4490 Validation Accuracy: 0.427000\n",
      "Epoch 74, CIFAR-10 Batch 5:  Loss:     1.4903 Validation Accuracy: 0.423000\n",
      "Epoch 75, CIFAR-10 Batch 1:  Loss:     1.4581 Validation Accuracy: 0.427600\n",
      "Epoch 75, CIFAR-10 Batch 2:  Loss:     1.4777 Validation Accuracy: 0.426200\n",
      "Epoch 75, CIFAR-10 Batch 3:  Loss:     1.4268 Validation Accuracy: 0.422600\n",
      "Epoch 75, CIFAR-10 Batch 4:  Loss:     1.4452 Validation Accuracy: 0.429000\n",
      "Epoch 75, CIFAR-10 Batch 5:  Loss:     1.4869 Validation Accuracy: 0.423000\n",
      "Epoch 76, CIFAR-10 Batch 1:  Loss:     1.4542 Validation Accuracy: 0.429600\n",
      "Epoch 76, CIFAR-10 Batch 2:  Loss:     1.4719 Validation Accuracy: 0.428800\n",
      "Epoch 76, CIFAR-10 Batch 3:  Loss:     1.4202 Validation Accuracy: 0.427000\n",
      "Epoch 76, CIFAR-10 Batch 4:  Loss:     1.4312 Validation Accuracy: 0.431000\n",
      "Epoch 76, CIFAR-10 Batch 5:  Loss:     1.4853 Validation Accuracy: 0.420600\n",
      "Epoch 77, CIFAR-10 Batch 1:  Loss:     1.4525 Validation Accuracy: 0.431400\n",
      "Epoch 77, CIFAR-10 Batch 2:  Loss:     1.4719 Validation Accuracy: 0.424600\n",
      "Epoch 77, CIFAR-10 Batch 3:  Loss:     1.4115 Validation Accuracy: 0.427400\n",
      "Epoch 77, CIFAR-10 Batch 4:  Loss:     1.4270 Validation Accuracy: 0.431000\n",
      "Epoch 77, CIFAR-10 Batch 5:  Loss:     1.4795 Validation Accuracy: 0.425400\n",
      "Epoch 78, CIFAR-10 Batch 1:  Loss:     1.4453 Validation Accuracy: 0.428000\n",
      "Epoch 78, CIFAR-10 Batch 2:  Loss:     1.4670 Validation Accuracy: 0.430400\n",
      "Epoch 78, CIFAR-10 Batch 3:  Loss:     1.4131 Validation Accuracy: 0.424600\n",
      "Epoch 78, CIFAR-10 Batch 4:  Loss:     1.4283 Validation Accuracy: 0.433000\n",
      "Epoch 78, CIFAR-10 Batch 5:  Loss:     1.4757 Validation Accuracy: 0.423800\n",
      "Epoch 79, CIFAR-10 Batch 1:  Loss:     1.4487 Validation Accuracy: 0.428600\n",
      "Epoch 79, CIFAR-10 Batch 2:  Loss:     1.4642 Validation Accuracy: 0.430400\n",
      "Epoch 79, CIFAR-10 Batch 3:  Loss:     1.4108 Validation Accuracy: 0.431400\n",
      "Epoch 79, CIFAR-10 Batch 4:  Loss:     1.4244 Validation Accuracy: 0.432200\n",
      "Epoch 79, CIFAR-10 Batch 5:  Loss:     1.4795 Validation Accuracy: 0.422000\n",
      "Epoch 80, CIFAR-10 Batch 1:  Loss:     1.4542 Validation Accuracy: 0.429400\n",
      "Epoch 80, CIFAR-10 Batch 2:  Loss:     1.4774 Validation Accuracy: 0.417800\n",
      "Epoch 80, CIFAR-10 Batch 3:  Loss:     1.4055 Validation Accuracy: 0.431400\n",
      "Epoch 80, CIFAR-10 Batch 4:  Loss:     1.4204 Validation Accuracy: 0.429800\n",
      "Epoch 80, CIFAR-10 Batch 5:  Loss:     1.4751 Validation Accuracy: 0.423200\n",
      "Epoch 81, CIFAR-10 Batch 1:  Loss:     1.4644 Validation Accuracy: 0.428400\n",
      "Epoch 81, CIFAR-10 Batch 2:  Loss:     1.4891 Validation Accuracy: 0.417200\n",
      "Epoch 81, CIFAR-10 Batch 3:  Loss:     1.4138 Validation Accuracy: 0.429800\n",
      "Epoch 81, CIFAR-10 Batch 4:  Loss:     1.4260 Validation Accuracy: 0.427200\n",
      "Epoch 81, CIFAR-10 Batch 5:  Loss:     1.4596 Validation Accuracy: 0.434200\n",
      "Epoch 82, CIFAR-10 Batch 1:  Loss:     1.4328 Validation Accuracy: 0.432400\n",
      "Epoch 82, CIFAR-10 Batch 2:  Loss:     1.4655 Validation Accuracy: 0.426200\n",
      "Epoch 82, CIFAR-10 Batch 3:  Loss:     1.4072 Validation Accuracy: 0.431200\n",
      "Epoch 82, CIFAR-10 Batch 4:  Loss:     1.4267 Validation Accuracy: 0.427000\n",
      "Epoch 82, CIFAR-10 Batch 5:  Loss:     1.4660 Validation Accuracy: 0.439400\n",
      "Epoch 83, CIFAR-10 Batch 1:  Loss:     1.4282 Validation Accuracy: 0.430200\n",
      "Epoch 83, CIFAR-10 Batch 2:  Loss:     1.4506 Validation Accuracy: 0.435800\n",
      "Epoch 83, CIFAR-10 Batch 3:  Loss:     1.3885 Validation Accuracy: 0.432600\n",
      "Epoch 83, CIFAR-10 Batch 4:  Loss:     1.4096 Validation Accuracy: 0.434000\n",
      "Epoch 83, CIFAR-10 Batch 5:  Loss:     1.4532 Validation Accuracy: 0.436400\n",
      "Epoch 84, CIFAR-10 Batch 1:  Loss:     1.4228 Validation Accuracy: 0.433600\n",
      "Epoch 84, CIFAR-10 Batch 2:  Loss:     1.4453 Validation Accuracy: 0.436400\n",
      "Epoch 84, CIFAR-10 Batch 3:  Loss:     1.3881 Validation Accuracy: 0.437600\n",
      "Epoch 84, CIFAR-10 Batch 4:  Loss:     1.4057 Validation Accuracy: 0.432400\n",
      "Epoch 84, CIFAR-10 Batch 5:  Loss:     1.4501 Validation Accuracy: 0.435400\n",
      "Epoch 85, CIFAR-10 Batch 1:  Loss:     1.4222 Validation Accuracy: 0.436800\n",
      "Epoch 85, CIFAR-10 Batch 2:  Loss:     1.4438 Validation Accuracy: 0.433200\n",
      "Epoch 85, CIFAR-10 Batch 3:  Loss:     1.3873 Validation Accuracy: 0.438400\n",
      "Epoch 85, CIFAR-10 Batch 4:  Loss:     1.4070 Validation Accuracy: 0.428400\n",
      "Epoch 85, CIFAR-10 Batch 5:  Loss:     1.4459 Validation Accuracy: 0.435400\n",
      "Epoch 86, CIFAR-10 Batch 1:  Loss:     1.4228 Validation Accuracy: 0.436800\n",
      "Epoch 86, CIFAR-10 Batch 2:  Loss:     1.4362 Validation Accuracy: 0.437000\n",
      "Epoch 86, CIFAR-10 Batch 3:  Loss:     1.3960 Validation Accuracy: 0.433600\n",
      "Epoch 86, CIFAR-10 Batch 4:  Loss:     1.4111 Validation Accuracy: 0.422800\n",
      "Epoch 86, CIFAR-10 Batch 5:  Loss:     1.4493 Validation Accuracy: 0.434600\n",
      "Epoch 87, CIFAR-10 Batch 1:  Loss:     1.4171 Validation Accuracy: 0.434600\n",
      "Epoch 87, CIFAR-10 Batch 2:  Loss:     1.4395 Validation Accuracy: 0.432800\n",
      "Epoch 87, CIFAR-10 Batch 3:  Loss:     1.3914 Validation Accuracy: 0.435400\n",
      "Epoch 87, CIFAR-10 Batch 4:  Loss:     1.3983 Validation Accuracy: 0.431800\n",
      "Epoch 87, CIFAR-10 Batch 5:  Loss:     1.4451 Validation Accuracy: 0.440400\n",
      "Epoch 88, CIFAR-10 Batch 1:  Loss:     1.4113 Validation Accuracy: 0.434400\n",
      "Epoch 88, CIFAR-10 Batch 2:  Loss:     1.4432 Validation Accuracy: 0.435800\n",
      "Epoch 88, CIFAR-10 Batch 3:  Loss:     1.3826 Validation Accuracy: 0.436400\n",
      "Epoch 88, CIFAR-10 Batch 4:  Loss:     1.3980 Validation Accuracy: 0.437400\n",
      "Epoch 88, CIFAR-10 Batch 5:  Loss:     1.4427 Validation Accuracy: 0.442600\n",
      "Epoch 89, CIFAR-10 Batch 1:  Loss:     1.4081 Validation Accuracy: 0.437200\n",
      "Epoch 89, CIFAR-10 Batch 2:  Loss:     1.4312 Validation Accuracy: 0.435200\n",
      "Epoch 89, CIFAR-10 Batch 3:  Loss:     1.3770 Validation Accuracy: 0.439000\n",
      "Epoch 89, CIFAR-10 Batch 4:  Loss:     1.3884 Validation Accuracy: 0.436400\n",
      "Epoch 89, CIFAR-10 Batch 5:  Loss:     1.4335 Validation Accuracy: 0.442200\n",
      "Epoch 90, CIFAR-10 Batch 1:  Loss:     1.4047 Validation Accuracy: 0.437200\n",
      "Epoch 90, CIFAR-10 Batch 2:  Loss:     1.4272 Validation Accuracy: 0.437400\n",
      "Epoch 90, CIFAR-10 Batch 3:  Loss:     1.3723 Validation Accuracy: 0.438800\n",
      "Epoch 90, CIFAR-10 Batch 4:  Loss:     1.3873 Validation Accuracy: 0.436200\n",
      "Epoch 90, CIFAR-10 Batch 5:  Loss:     1.4322 Validation Accuracy: 0.442600\n",
      "Epoch 91, CIFAR-10 Batch 1:  Loss:     1.4029 Validation Accuracy: 0.441600\n",
      "Epoch 91, CIFAR-10 Batch 2:  Loss:     1.4303 Validation Accuracy: 0.433200\n",
      "Epoch 91, CIFAR-10 Batch 3:  Loss:     1.3706 Validation Accuracy: 0.440800\n",
      "Epoch 91, CIFAR-10 Batch 4:  Loss:     1.3841 Validation Accuracy: 0.434200\n",
      "Epoch 91, CIFAR-10 Batch 5:  Loss:     1.4273 Validation Accuracy: 0.442400\n",
      "Epoch 92, CIFAR-10 Batch 1:  Loss:     1.3999 Validation Accuracy: 0.439200\n",
      "Epoch 92, CIFAR-10 Batch 2:  Loss:     1.4226 Validation Accuracy: 0.435600\n",
      "Epoch 92, CIFAR-10 Batch 3:  Loss:     1.3701 Validation Accuracy: 0.441400\n",
      "Epoch 92, CIFAR-10 Batch 4:  Loss:     1.3849 Validation Accuracy: 0.431600\n",
      "Epoch 92, CIFAR-10 Batch 5:  Loss:     1.4266 Validation Accuracy: 0.445000\n",
      "Epoch 93, CIFAR-10 Batch 1:  Loss:     1.3959 Validation Accuracy: 0.438400\n",
      "Epoch 93, CIFAR-10 Batch 2:  Loss:     1.4174 Validation Accuracy: 0.439800\n",
      "Epoch 93, CIFAR-10 Batch 3:  Loss:     1.3612 Validation Accuracy: 0.440800\n",
      "Epoch 93, CIFAR-10 Batch 4:  Loss:     1.3825 Validation Accuracy: 0.436200\n",
      "Epoch 93, CIFAR-10 Batch 5:  Loss:     1.4270 Validation Accuracy: 0.447200\n",
      "Epoch 94, CIFAR-10 Batch 1:  Loss:     1.3932 Validation Accuracy: 0.440400\n",
      "Epoch 94, CIFAR-10 Batch 2:  Loss:     1.4198 Validation Accuracy: 0.438000\n",
      "Epoch 94, CIFAR-10 Batch 3:  Loss:     1.3588 Validation Accuracy: 0.442200\n",
      "Epoch 94, CIFAR-10 Batch 4:  Loss:     1.3725 Validation Accuracy: 0.436400\n",
      "Epoch 94, CIFAR-10 Batch 5:  Loss:     1.4212 Validation Accuracy: 0.446600\n",
      "Epoch 95, CIFAR-10 Batch 1:  Loss:     1.3905 Validation Accuracy: 0.442000\n",
      "Epoch 95, CIFAR-10 Batch 2:  Loss:     1.4217 Validation Accuracy: 0.440800\n",
      "Epoch 95, CIFAR-10 Batch 3:  Loss:     1.3664 Validation Accuracy: 0.439400\n",
      "Epoch 95, CIFAR-10 Batch 4:  Loss:     1.3770 Validation Accuracy: 0.438200\n",
      "Epoch 95, CIFAR-10 Batch 5:  Loss:     1.4189 Validation Accuracy: 0.448600\n",
      "Epoch 96, CIFAR-10 Batch 1:  Loss:     1.3894 Validation Accuracy: 0.442000\n",
      "Epoch 96, CIFAR-10 Batch 2:  Loss:     1.4137 Validation Accuracy: 0.440200\n",
      "Epoch 96, CIFAR-10 Batch 3:  Loss:     1.3628 Validation Accuracy: 0.442000\n",
      "Epoch 96, CIFAR-10 Batch 4:  Loss:     1.3689 Validation Accuracy: 0.434400\n",
      "Epoch 96, CIFAR-10 Batch 5:  Loss:     1.4175 Validation Accuracy: 0.450600\n",
      "Epoch 97, CIFAR-10 Batch 1:  Loss:     1.3868 Validation Accuracy: 0.443600\n",
      "Epoch 97, CIFAR-10 Batch 2:  Loss:     1.4145 Validation Accuracy: 0.439200\n",
      "Epoch 97, CIFAR-10 Batch 3:  Loss:     1.3595 Validation Accuracy: 0.441800\n",
      "Epoch 97, CIFAR-10 Batch 4:  Loss:     1.3705 Validation Accuracy: 0.438000\n",
      "Epoch 97, CIFAR-10 Batch 5:  Loss:     1.4154 Validation Accuracy: 0.451200\n",
      "Epoch 98, CIFAR-10 Batch 1:  Loss:     1.3849 Validation Accuracy: 0.444200\n",
      "Epoch 98, CIFAR-10 Batch 2:  Loss:     1.4058 Validation Accuracy: 0.442600\n",
      "Epoch 98, CIFAR-10 Batch 3:  Loss:     1.3517 Validation Accuracy: 0.443800\n",
      "Epoch 98, CIFAR-10 Batch 4:  Loss:     1.3694 Validation Accuracy: 0.440800\n",
      "Epoch 98, CIFAR-10 Batch 5:  Loss:     1.4118 Validation Accuracy: 0.453200\n",
      "Epoch 99, CIFAR-10 Batch 1:  Loss:     1.3806 Validation Accuracy: 0.442000\n",
      "Epoch 99, CIFAR-10 Batch 2:  Loss:     1.4007 Validation Accuracy: 0.447600\n",
      "Epoch 99, CIFAR-10 Batch 3:  Loss:     1.3423 Validation Accuracy: 0.447200\n",
      "Epoch 99, CIFAR-10 Batch 4:  Loss:     1.3625 Validation Accuracy: 0.442400\n",
      "Epoch 99, CIFAR-10 Batch 5:  Loss:     1.4068 Validation Accuracy: 0.452000\n",
      "Epoch 100, CIFAR-10 Batch 1:  Loss:     1.3764 Validation Accuracy: 0.445600\n",
      "Epoch 100, CIFAR-10 Batch 2:  Loss:     1.3978 Validation Accuracy: 0.447800\n",
      "Epoch 100, CIFAR-10 Batch 3:  Loss:     1.3427 Validation Accuracy: 0.446400\n",
      "Epoch 100, CIFAR-10 Batch 4:  Loss:     1.3601 Validation Accuracy: 0.440400\n",
      "Epoch 100, CIFAR-10 Batch 5:  Loss:     1.4064 Validation Accuracy: 0.452000\n",
      "Epoch 101, CIFAR-10 Batch 1:  Loss:     1.3733 Validation Accuracy: 0.447200\n",
      "Epoch 101, CIFAR-10 Batch 2:  Loss:     1.3997 Validation Accuracy: 0.442600\n",
      "Epoch 101, CIFAR-10 Batch 3:  Loss:     1.3405 Validation Accuracy: 0.448400\n",
      "Epoch 101, CIFAR-10 Batch 4:  Loss:     1.3568 Validation Accuracy: 0.446400\n",
      "Epoch 101, CIFAR-10 Batch 5:  Loss:     1.4014 Validation Accuracy: 0.454200\n",
      "Epoch 102, CIFAR-10 Batch 1:  Loss:     1.3707 Validation Accuracy: 0.449800\n",
      "Epoch 102, CIFAR-10 Batch 2:  Loss:     1.3947 Validation Accuracy: 0.445200\n",
      "Epoch 102, CIFAR-10 Batch 3:  Loss:     1.3360 Validation Accuracy: 0.449600\n",
      "Epoch 102, CIFAR-10 Batch 4:  Loss:     1.3501 Validation Accuracy: 0.441400\n",
      "Epoch 102, CIFAR-10 Batch 5:  Loss:     1.3978 Validation Accuracy: 0.454200\n",
      "Epoch 103, CIFAR-10 Batch 1:  Loss:     1.3676 Validation Accuracy: 0.447800\n",
      "Epoch 103, CIFAR-10 Batch 2:  Loss:     1.3933 Validation Accuracy: 0.448200\n",
      "Epoch 103, CIFAR-10 Batch 3:  Loss:     1.3422 Validation Accuracy: 0.444600\n",
      "Epoch 103, CIFAR-10 Batch 4:  Loss:     1.3530 Validation Accuracy: 0.444600\n",
      "Epoch 103, CIFAR-10 Batch 5:  Loss:     1.4009 Validation Accuracy: 0.453600\n",
      "Epoch 104, CIFAR-10 Batch 1:  Loss:     1.3651 Validation Accuracy: 0.447400\n",
      "Epoch 104, CIFAR-10 Batch 2:  Loss:     1.3945 Validation Accuracy: 0.445200\n",
      "Epoch 104, CIFAR-10 Batch 3:  Loss:     1.3394 Validation Accuracy: 0.449800\n",
      "Epoch 104, CIFAR-10 Batch 4:  Loss:     1.3546 Validation Accuracy: 0.442000\n",
      "Epoch 104, CIFAR-10 Batch 5:  Loss:     1.3984 Validation Accuracy: 0.454400\n",
      "Epoch 105, CIFAR-10 Batch 1:  Loss:     1.3636 Validation Accuracy: 0.449200\n",
      "Epoch 105, CIFAR-10 Batch 2:  Loss:     1.3919 Validation Accuracy: 0.446600\n",
      "Epoch 105, CIFAR-10 Batch 3:  Loss:     1.3390 Validation Accuracy: 0.445600\n",
      "Epoch 105, CIFAR-10 Batch 4:  Loss:     1.3513 Validation Accuracy: 0.443400\n",
      "Epoch 105, CIFAR-10 Batch 5:  Loss:     1.3980 Validation Accuracy: 0.454200\n",
      "Epoch 106, CIFAR-10 Batch 1:  Loss:     1.3596 Validation Accuracy: 0.449800\n",
      "Epoch 106, CIFAR-10 Batch 2:  Loss:     1.3856 Validation Accuracy: 0.447000\n",
      "Epoch 106, CIFAR-10 Batch 3:  Loss:     1.3343 Validation Accuracy: 0.453000\n",
      "Epoch 106, CIFAR-10 Batch 4:  Loss:     1.3441 Validation Accuracy: 0.446400\n",
      "Epoch 106, CIFAR-10 Batch 5:  Loss:     1.3955 Validation Accuracy: 0.455800\n",
      "Epoch 107, CIFAR-10 Batch 1:  Loss:     1.3610 Validation Accuracy: 0.449400\n",
      "Epoch 107, CIFAR-10 Batch 2:  Loss:     1.3843 Validation Accuracy: 0.449600\n",
      "Epoch 107, CIFAR-10 Batch 3:  Loss:     1.3274 Validation Accuracy: 0.456000\n",
      "Epoch 107, CIFAR-10 Batch 4:  Loss:     1.3413 Validation Accuracy: 0.450600\n",
      "Epoch 107, CIFAR-10 Batch 5:  Loss:     1.3893 Validation Accuracy: 0.459800\n",
      "Epoch 108, CIFAR-10 Batch 1:  Loss:     1.3584 Validation Accuracy: 0.448800\n",
      "Epoch 108, CIFAR-10 Batch 2:  Loss:     1.3807 Validation Accuracy: 0.448400\n",
      "Epoch 108, CIFAR-10 Batch 3:  Loss:     1.3209 Validation Accuracy: 0.452400\n",
      "Epoch 108, CIFAR-10 Batch 4:  Loss:     1.3384 Validation Accuracy: 0.450000\n",
      "Epoch 108, CIFAR-10 Batch 5:  Loss:     1.3825 Validation Accuracy: 0.459000\n",
      "Epoch 109, CIFAR-10 Batch 1:  Loss:     1.3533 Validation Accuracy: 0.453400\n",
      "Epoch 109, CIFAR-10 Batch 2:  Loss:     1.3740 Validation Accuracy: 0.451200\n",
      "Epoch 109, CIFAR-10 Batch 3:  Loss:     1.3196 Validation Accuracy: 0.453800\n",
      "Epoch 109, CIFAR-10 Batch 4:  Loss:     1.3392 Validation Accuracy: 0.449600\n",
      "Epoch 109, CIFAR-10 Batch 5:  Loss:     1.3817 Validation Accuracy: 0.459400\n",
      "Epoch 110, CIFAR-10 Batch 1:  Loss:     1.3516 Validation Accuracy: 0.457200\n",
      "Epoch 110, CIFAR-10 Batch 2:  Loss:     1.3714 Validation Accuracy: 0.454000\n",
      "Epoch 110, CIFAR-10 Batch 3:  Loss:     1.3202 Validation Accuracy: 0.450400\n",
      "Epoch 110, CIFAR-10 Batch 4:  Loss:     1.3338 Validation Accuracy: 0.449600\n",
      "Epoch 110, CIFAR-10 Batch 5:  Loss:     1.3807 Validation Accuracy: 0.454600\n",
      "Epoch 111, CIFAR-10 Batch 1:  Loss:     1.3468 Validation Accuracy: 0.458000\n",
      "Epoch 111, CIFAR-10 Batch 2:  Loss:     1.3727 Validation Accuracy: 0.451400\n",
      "Epoch 111, CIFAR-10 Batch 3:  Loss:     1.3244 Validation Accuracy: 0.453200\n",
      "Epoch 111, CIFAR-10 Batch 4:  Loss:     1.3367 Validation Accuracy: 0.448000\n",
      "Epoch 111, CIFAR-10 Batch 5:  Loss:     1.3848 Validation Accuracy: 0.457000\n",
      "Epoch 112, CIFAR-10 Batch 1:  Loss:     1.3432 Validation Accuracy: 0.458200\n",
      "Epoch 112, CIFAR-10 Batch 2:  Loss:     1.3771 Validation Accuracy: 0.448800\n",
      "Epoch 112, CIFAR-10 Batch 3:  Loss:     1.3167 Validation Accuracy: 0.455800\n",
      "Epoch 112, CIFAR-10 Batch 4:  Loss:     1.3299 Validation Accuracy: 0.450600\n",
      "Epoch 112, CIFAR-10 Batch 5:  Loss:     1.3732 Validation Accuracy: 0.461600\n",
      "Epoch 113, CIFAR-10 Batch 1:  Loss:     1.3454 Validation Accuracy: 0.459000\n",
      "Epoch 113, CIFAR-10 Batch 2:  Loss:     1.3678 Validation Accuracy: 0.454200\n",
      "Epoch 113, CIFAR-10 Batch 3:  Loss:     1.3127 Validation Accuracy: 0.459600\n",
      "Epoch 113, CIFAR-10 Batch 4:  Loss:     1.3282 Validation Accuracy: 0.449800\n",
      "Epoch 113, CIFAR-10 Batch 5:  Loss:     1.3703 Validation Accuracy: 0.463200\n",
      "Epoch 114, CIFAR-10 Batch 1:  Loss:     1.3407 Validation Accuracy: 0.459000\n",
      "Epoch 114, CIFAR-10 Batch 2:  Loss:     1.3719 Validation Accuracy: 0.451400\n",
      "Epoch 114, CIFAR-10 Batch 3:  Loss:     1.3129 Validation Accuracy: 0.457200\n",
      "Epoch 114, CIFAR-10 Batch 4:  Loss:     1.3302 Validation Accuracy: 0.449400\n",
      "Epoch 114, CIFAR-10 Batch 5:  Loss:     1.3670 Validation Accuracy: 0.464000\n",
      "Epoch 115, CIFAR-10 Batch 1:  Loss:     1.3384 Validation Accuracy: 0.460200\n",
      "Epoch 115, CIFAR-10 Batch 2:  Loss:     1.3601 Validation Accuracy: 0.456000\n",
      "Epoch 115, CIFAR-10 Batch 3:  Loss:     1.3093 Validation Accuracy: 0.457400\n",
      "Epoch 115, CIFAR-10 Batch 4:  Loss:     1.3248 Validation Accuracy: 0.450800\n",
      "Epoch 115, CIFAR-10 Batch 5:  Loss:     1.3649 Validation Accuracy: 0.462200\n",
      "Epoch 116, CIFAR-10 Batch 1:  Loss:     1.3339 Validation Accuracy: 0.457600\n",
      "Epoch 116, CIFAR-10 Batch 2:  Loss:     1.3495 Validation Accuracy: 0.459200\n",
      "Epoch 116, CIFAR-10 Batch 3:  Loss:     1.3079 Validation Accuracy: 0.461200\n",
      "Epoch 116, CIFAR-10 Batch 4:  Loss:     1.3208 Validation Accuracy: 0.454400\n",
      "Epoch 116, CIFAR-10 Batch 5:  Loss:     1.3690 Validation Accuracy: 0.463000\n",
      "Epoch 117, CIFAR-10 Batch 1:  Loss:     1.3339 Validation Accuracy: 0.460800\n",
      "Epoch 117, CIFAR-10 Batch 2:  Loss:     1.3555 Validation Accuracy: 0.457000\n",
      "Epoch 117, CIFAR-10 Batch 3:  Loss:     1.3048 Validation Accuracy: 0.464200\n",
      "Epoch 117, CIFAR-10 Batch 4:  Loss:     1.3160 Validation Accuracy: 0.456000\n",
      "Epoch 117, CIFAR-10 Batch 5:  Loss:     1.3661 Validation Accuracy: 0.463400\n",
      "Epoch 118, CIFAR-10 Batch 1:  Loss:     1.3300 Validation Accuracy: 0.460000\n",
      "Epoch 118, CIFAR-10 Batch 2:  Loss:     1.3580 Validation Accuracy: 0.460800\n",
      "Epoch 118, CIFAR-10 Batch 3:  Loss:     1.3058 Validation Accuracy: 0.462400\n",
      "Epoch 118, CIFAR-10 Batch 4:  Loss:     1.3162 Validation Accuracy: 0.454800\n",
      "Epoch 118, CIFAR-10 Batch 5:  Loss:     1.3652 Validation Accuracy: 0.460600\n",
      "Epoch 119, CIFAR-10 Batch 1:  Loss:     1.3276 Validation Accuracy: 0.463400\n",
      "Epoch 119, CIFAR-10 Batch 2:  Loss:     1.3522 Validation Accuracy: 0.456200\n",
      "Epoch 119, CIFAR-10 Batch 3:  Loss:     1.2970 Validation Accuracy: 0.463800\n",
      "Epoch 119, CIFAR-10 Batch 4:  Loss:     1.3169 Validation Accuracy: 0.454000\n",
      "Epoch 119, CIFAR-10 Batch 5:  Loss:     1.3582 Validation Accuracy: 0.464400\n",
      "Epoch 120, CIFAR-10 Batch 1:  Loss:     1.3271 Validation Accuracy: 0.465800\n",
      "Epoch 120, CIFAR-10 Batch 2:  Loss:     1.3452 Validation Accuracy: 0.461400\n",
      "Epoch 120, CIFAR-10 Batch 3:  Loss:     1.2942 Validation Accuracy: 0.465400\n",
      "Epoch 120, CIFAR-10 Batch 4:  Loss:     1.3170 Validation Accuracy: 0.454200\n",
      "Epoch 120, CIFAR-10 Batch 5:  Loss:     1.3593 Validation Accuracy: 0.467600\n",
      "Epoch 121, CIFAR-10 Batch 1:  Loss:     1.3268 Validation Accuracy: 0.464000\n",
      "Epoch 121, CIFAR-10 Batch 2:  Loss:     1.3418 Validation Accuracy: 0.464400\n",
      "Epoch 121, CIFAR-10 Batch 3:  Loss:     1.2921 Validation Accuracy: 0.467200\n",
      "Epoch 121, CIFAR-10 Batch 4:  Loss:     1.3067 Validation Accuracy: 0.463000\n",
      "Epoch 121, CIFAR-10 Batch 5:  Loss:     1.3500 Validation Accuracy: 0.466400\n",
      "Epoch 122, CIFAR-10 Batch 1:  Loss:     1.3191 Validation Accuracy: 0.462600\n",
      "Epoch 122, CIFAR-10 Batch 2:  Loss:     1.3350 Validation Accuracy: 0.469600\n",
      "Epoch 122, CIFAR-10 Batch 3:  Loss:     1.2878 Validation Accuracy: 0.468400\n",
      "Epoch 122, CIFAR-10 Batch 4:  Loss:     1.3035 Validation Accuracy: 0.463800\n",
      "Epoch 122, CIFAR-10 Batch 5:  Loss:     1.3540 Validation Accuracy: 0.465400\n",
      "Epoch 123, CIFAR-10 Batch 1:  Loss:     1.3201 Validation Accuracy: 0.463800\n",
      "Epoch 123, CIFAR-10 Batch 2:  Loss:     1.3386 Validation Accuracy: 0.463400\n",
      "Epoch 123, CIFAR-10 Batch 3:  Loss:     1.2936 Validation Accuracy: 0.470600\n",
      "Epoch 123, CIFAR-10 Batch 4:  Loss:     1.3006 Validation Accuracy: 0.464200\n",
      "Epoch 123, CIFAR-10 Batch 5:  Loss:     1.3554 Validation Accuracy: 0.464000\n",
      "Epoch 124, CIFAR-10 Batch 1:  Loss:     1.3151 Validation Accuracy: 0.470400\n",
      "Epoch 124, CIFAR-10 Batch 2:  Loss:     1.3378 Validation Accuracy: 0.465800\n",
      "Epoch 124, CIFAR-10 Batch 3:  Loss:     1.2873 Validation Accuracy: 0.468200\n",
      "Epoch 124, CIFAR-10 Batch 4:  Loss:     1.3034 Validation Accuracy: 0.461200\n",
      "Epoch 124, CIFAR-10 Batch 5:  Loss:     1.3502 Validation Accuracy: 0.467400\n",
      "Epoch 125, CIFAR-10 Batch 1:  Loss:     1.3131 Validation Accuracy: 0.469200\n",
      "Epoch 125, CIFAR-10 Batch 2:  Loss:     1.3347 Validation Accuracy: 0.466600\n",
      "Epoch 125, CIFAR-10 Batch 3:  Loss:     1.2850 Validation Accuracy: 0.471400\n",
      "Epoch 125, CIFAR-10 Batch 4:  Loss:     1.3055 Validation Accuracy: 0.456400\n",
      "Epoch 125, CIFAR-10 Batch 5:  Loss:     1.3496 Validation Accuracy: 0.470600\n",
      "Epoch 126, CIFAR-10 Batch 1:  Loss:     1.3148 Validation Accuracy: 0.467800\n",
      "Epoch 126, CIFAR-10 Batch 2:  Loss:     1.3333 Validation Accuracy: 0.469800\n",
      "Epoch 126, CIFAR-10 Batch 3:  Loss:     1.2785 Validation Accuracy: 0.471200\n",
      "Epoch 126, CIFAR-10 Batch 4:  Loss:     1.2943 Validation Accuracy: 0.461400\n",
      "Epoch 126, CIFAR-10 Batch 5:  Loss:     1.3433 Validation Accuracy: 0.469600\n",
      "Epoch 127, CIFAR-10 Batch 1:  Loss:     1.3114 Validation Accuracy: 0.467600\n",
      "Epoch 127, CIFAR-10 Batch 2:  Loss:     1.3270 Validation Accuracy: 0.473000\n",
      "Epoch 127, CIFAR-10 Batch 3:  Loss:     1.2760 Validation Accuracy: 0.472600\n",
      "Epoch 127, CIFAR-10 Batch 4:  Loss:     1.2941 Validation Accuracy: 0.463200\n",
      "Epoch 127, CIFAR-10 Batch 5:  Loss:     1.3415 Validation Accuracy: 0.473000\n",
      "Epoch 128, CIFAR-10 Batch 1:  Loss:     1.3063 Validation Accuracy: 0.469200\n",
      "Epoch 128, CIFAR-10 Batch 2:  Loss:     1.3219 Validation Accuracy: 0.476600\n",
      "Epoch 128, CIFAR-10 Batch 3:  Loss:     1.2753 Validation Accuracy: 0.470800\n",
      "Epoch 128, CIFAR-10 Batch 4:  Loss:     1.2906 Validation Accuracy: 0.470600\n",
      "Epoch 128, CIFAR-10 Batch 5:  Loss:     1.3389 Validation Accuracy: 0.472600\n",
      "Epoch 129, CIFAR-10 Batch 1:  Loss:     1.3025 Validation Accuracy: 0.468800\n",
      "Epoch 129, CIFAR-10 Batch 2:  Loss:     1.3131 Validation Accuracy: 0.479000\n",
      "Epoch 129, CIFAR-10 Batch 3:  Loss:     1.2741 Validation Accuracy: 0.472000\n",
      "Epoch 129, CIFAR-10 Batch 4:  Loss:     1.2916 Validation Accuracy: 0.468200\n",
      "Epoch 129, CIFAR-10 Batch 5:  Loss:     1.3502 Validation Accuracy: 0.467600\n",
      "Epoch 130, CIFAR-10 Batch 1:  Loss:     1.3059 Validation Accuracy: 0.469000\n",
      "Epoch 130, CIFAR-10 Batch 2:  Loss:     1.3181 Validation Accuracy: 0.470000\n",
      "Epoch 130, CIFAR-10 Batch 3:  Loss:     1.2751 Validation Accuracy: 0.477200\n",
      "Epoch 130, CIFAR-10 Batch 4:  Loss:     1.2884 Validation Accuracy: 0.469800\n",
      "Epoch 130, CIFAR-10 Batch 5:  Loss:     1.3427 Validation Accuracy: 0.470400\n",
      "Epoch 131, CIFAR-10 Batch 1:  Loss:     1.2974 Validation Accuracy: 0.472000\n",
      "Epoch 131, CIFAR-10 Batch 2:  Loss:     1.3229 Validation Accuracy: 0.471800\n",
      "Epoch 131, CIFAR-10 Batch 3:  Loss:     1.2650 Validation Accuracy: 0.477000\n",
      "Epoch 131, CIFAR-10 Batch 4:  Loss:     1.2930 Validation Accuracy: 0.467200\n",
      "Epoch 131, CIFAR-10 Batch 5:  Loss:     1.3313 Validation Accuracy: 0.477800\n",
      "Epoch 132, CIFAR-10 Batch 1:  Loss:     1.2992 Validation Accuracy: 0.474200\n",
      "Epoch 132, CIFAR-10 Batch 2:  Loss:     1.3174 Validation Accuracy: 0.474800\n",
      "Epoch 132, CIFAR-10 Batch 3:  Loss:     1.2654 Validation Accuracy: 0.473800\n",
      "Epoch 132, CIFAR-10 Batch 4:  Loss:     1.2954 Validation Accuracy: 0.467200\n",
      "Epoch 132, CIFAR-10 Batch 5:  Loss:     1.3303 Validation Accuracy: 0.478000\n",
      "Epoch 133, CIFAR-10 Batch 1:  Loss:     1.2988 Validation Accuracy: 0.473000\n",
      "Epoch 133, CIFAR-10 Batch 2:  Loss:     1.3113 Validation Accuracy: 0.476200\n",
      "Epoch 133, CIFAR-10 Batch 3:  Loss:     1.2618 Validation Accuracy: 0.478000\n",
      "Epoch 133, CIFAR-10 Batch 4:  Loss:     1.2848 Validation Accuracy: 0.467200\n",
      "Epoch 133, CIFAR-10 Batch 5:  Loss:     1.3314 Validation Accuracy: 0.477600\n",
      "Epoch 134, CIFAR-10 Batch 1:  Loss:     1.2929 Validation Accuracy: 0.470400\n",
      "Epoch 134, CIFAR-10 Batch 2:  Loss:     1.3027 Validation Accuracy: 0.479000\n",
      "Epoch 134, CIFAR-10 Batch 3:  Loss:     1.2561 Validation Accuracy: 0.480400\n",
      "Epoch 134, CIFAR-10 Batch 4:  Loss:     1.2777 Validation Accuracy: 0.471600\n",
      "Epoch 134, CIFAR-10 Batch 5:  Loss:     1.3258 Validation Accuracy: 0.480200\n",
      "Epoch 135, CIFAR-10 Batch 1:  Loss:     1.2907 Validation Accuracy: 0.474000\n",
      "Epoch 135, CIFAR-10 Batch 2:  Loss:     1.3030 Validation Accuracy: 0.481800\n",
      "Epoch 135, CIFAR-10 Batch 3:  Loss:     1.2538 Validation Accuracy: 0.482600\n",
      "Epoch 135, CIFAR-10 Batch 4:  Loss:     1.2745 Validation Accuracy: 0.475400\n",
      "Epoch 135, CIFAR-10 Batch 5:  Loss:     1.3279 Validation Accuracy: 0.477200\n",
      "Epoch 136, CIFAR-10 Batch 1:  Loss:     1.2855 Validation Accuracy: 0.475600\n",
      "Epoch 136, CIFAR-10 Batch 2:  Loss:     1.3034 Validation Accuracy: 0.474800\n",
      "Epoch 136, CIFAR-10 Batch 3:  Loss:     1.2548 Validation Accuracy: 0.480200\n",
      "Epoch 136, CIFAR-10 Batch 4:  Loss:     1.2749 Validation Accuracy: 0.476600\n",
      "Epoch 136, CIFAR-10 Batch 5:  Loss:     1.3263 Validation Accuracy: 0.478600\n",
      "Epoch 137, CIFAR-10 Batch 1:  Loss:     1.2859 Validation Accuracy: 0.474400\n",
      "Epoch 137, CIFAR-10 Batch 2:  Loss:     1.2989 Validation Accuracy: 0.476000\n",
      "Epoch 137, CIFAR-10 Batch 3:  Loss:     1.2559 Validation Accuracy: 0.479800\n",
      "Epoch 137, CIFAR-10 Batch 4:  Loss:     1.2712 Validation Accuracy: 0.476200\n",
      "Epoch 137, CIFAR-10 Batch 5:  Loss:     1.3265 Validation Accuracy: 0.478000\n",
      "Epoch 138, CIFAR-10 Batch 1:  Loss:     1.2843 Validation Accuracy: 0.473800\n",
      "Epoch 138, CIFAR-10 Batch 2:  Loss:     1.3001 Validation Accuracy: 0.477800\n",
      "Epoch 138, CIFAR-10 Batch 3:  Loss:     1.2508 Validation Accuracy: 0.480600\n",
      "Epoch 138, CIFAR-10 Batch 4:  Loss:     1.2735 Validation Accuracy: 0.476600\n",
      "Epoch 138, CIFAR-10 Batch 5:  Loss:     1.3206 Validation Accuracy: 0.482800\n",
      "Epoch 139, CIFAR-10 Batch 1:  Loss:     1.2817 Validation Accuracy: 0.475000\n",
      "Epoch 139, CIFAR-10 Batch 2:  Loss:     1.2955 Validation Accuracy: 0.478400\n",
      "Epoch 139, CIFAR-10 Batch 3:  Loss:     1.2466 Validation Accuracy: 0.480800\n",
      "Epoch 139, CIFAR-10 Batch 4:  Loss:     1.2733 Validation Accuracy: 0.477000\n",
      "Epoch 139, CIFAR-10 Batch 5:  Loss:     1.3151 Validation Accuracy: 0.481400\n",
      "Epoch 140, CIFAR-10 Batch 1:  Loss:     1.2779 Validation Accuracy: 0.474200\n",
      "Epoch 140, CIFAR-10 Batch 2:  Loss:     1.2924 Validation Accuracy: 0.479000\n",
      "Epoch 140, CIFAR-10 Batch 3:  Loss:     1.2448 Validation Accuracy: 0.481000\n",
      "Epoch 140, CIFAR-10 Batch 4:  Loss:     1.2752 Validation Accuracy: 0.475600\n",
      "Epoch 140, CIFAR-10 Batch 5:  Loss:     1.3152 Validation Accuracy: 0.482800\n",
      "Epoch 141, CIFAR-10 Batch 1:  Loss:     1.2793 Validation Accuracy: 0.474200\n",
      "Epoch 141, CIFAR-10 Batch 2:  Loss:     1.2901 Validation Accuracy: 0.479200\n",
      "Epoch 141, CIFAR-10 Batch 3:  Loss:     1.2432 Validation Accuracy: 0.485200\n",
      "Epoch 141, CIFAR-10 Batch 4:  Loss:     1.2673 Validation Accuracy: 0.477200\n",
      "Epoch 141, CIFAR-10 Batch 5:  Loss:     1.3111 Validation Accuracy: 0.485000\n",
      "Epoch 142, CIFAR-10 Batch 1:  Loss:     1.2744 Validation Accuracy: 0.473600\n",
      "Epoch 142, CIFAR-10 Batch 2:  Loss:     1.2970 Validation Accuracy: 0.476000\n",
      "Epoch 142, CIFAR-10 Batch 3:  Loss:     1.2430 Validation Accuracy: 0.486000\n",
      "Epoch 142, CIFAR-10 Batch 4:  Loss:     1.2710 Validation Accuracy: 0.475600\n",
      "Epoch 142, CIFAR-10 Batch 5:  Loss:     1.3124 Validation Accuracy: 0.483600\n",
      "Epoch 143, CIFAR-10 Batch 1:  Loss:     1.2750 Validation Accuracy: 0.472200\n",
      "Epoch 143, CIFAR-10 Batch 2:  Loss:     1.2859 Validation Accuracy: 0.481400\n",
      "Epoch 143, CIFAR-10 Batch 3:  Loss:     1.2376 Validation Accuracy: 0.486200\n",
      "Epoch 143, CIFAR-10 Batch 4:  Loss:     1.2644 Validation Accuracy: 0.478600\n",
      "Epoch 143, CIFAR-10 Batch 5:  Loss:     1.3107 Validation Accuracy: 0.486400\n",
      "Epoch 144, CIFAR-10 Batch 1:  Loss:     1.2684 Validation Accuracy: 0.475600\n",
      "Epoch 144, CIFAR-10 Batch 2:  Loss:     1.2881 Validation Accuracy: 0.481200\n",
      "Epoch 144, CIFAR-10 Batch 3:  Loss:     1.2365 Validation Accuracy: 0.484600\n",
      "Epoch 144, CIFAR-10 Batch 4:  Loss:     1.2590 Validation Accuracy: 0.481000\n",
      "Epoch 144, CIFAR-10 Batch 5:  Loss:     1.3027 Validation Accuracy: 0.489000\n",
      "Epoch 145, CIFAR-10 Batch 1:  Loss:     1.2662 Validation Accuracy: 0.479600\n",
      "Epoch 145, CIFAR-10 Batch 2:  Loss:     1.2806 Validation Accuracy: 0.485000\n",
      "Epoch 145, CIFAR-10 Batch 3:  Loss:     1.2384 Validation Accuracy: 0.486400\n",
      "Epoch 145, CIFAR-10 Batch 4:  Loss:     1.2595 Validation Accuracy: 0.479600\n",
      "Epoch 145, CIFAR-10 Batch 5:  Loss:     1.2995 Validation Accuracy: 0.491400\n",
      "Epoch 146, CIFAR-10 Batch 1:  Loss:     1.2636 Validation Accuracy: 0.479600\n",
      "Epoch 146, CIFAR-10 Batch 2:  Loss:     1.2787 Validation Accuracy: 0.486800\n",
      "Epoch 146, CIFAR-10 Batch 3:  Loss:     1.2359 Validation Accuracy: 0.487600\n",
      "Epoch 146, CIFAR-10 Batch 4:  Loss:     1.2588 Validation Accuracy: 0.481000\n",
      "Epoch 146, CIFAR-10 Batch 5:  Loss:     1.2985 Validation Accuracy: 0.491000\n",
      "Epoch 147, CIFAR-10 Batch 1:  Loss:     1.2646 Validation Accuracy: 0.476800\n",
      "Epoch 147, CIFAR-10 Batch 2:  Loss:     1.2747 Validation Accuracy: 0.490400\n",
      "Epoch 147, CIFAR-10 Batch 3:  Loss:     1.2345 Validation Accuracy: 0.488600\n",
      "Epoch 147, CIFAR-10 Batch 4:  Loss:     1.2531 Validation Accuracy: 0.480600\n",
      "Epoch 147, CIFAR-10 Batch 5:  Loss:     1.3023 Validation Accuracy: 0.490600\n",
      "Epoch 148, CIFAR-10 Batch 1:  Loss:     1.2611 Validation Accuracy: 0.480400\n",
      "Epoch 148, CIFAR-10 Batch 2:  Loss:     1.2813 Validation Accuracy: 0.484000\n",
      "Epoch 148, CIFAR-10 Batch 3:  Loss:     1.2346 Validation Accuracy: 0.480400\n",
      "Epoch 148, CIFAR-10 Batch 4:  Loss:     1.2525 Validation Accuracy: 0.484600\n",
      "Epoch 148, CIFAR-10 Batch 5:  Loss:     1.3042 Validation Accuracy: 0.485800\n",
      "Epoch 149, CIFAR-10 Batch 1:  Loss:     1.2618 Validation Accuracy: 0.484400\n",
      "Epoch 149, CIFAR-10 Batch 2:  Loss:     1.2818 Validation Accuracy: 0.486800\n",
      "Epoch 149, CIFAR-10 Batch 3:  Loss:     1.2395 Validation Accuracy: 0.481400\n",
      "Epoch 149, CIFAR-10 Batch 4:  Loss:     1.2511 Validation Accuracy: 0.483200\n",
      "Epoch 149, CIFAR-10 Batch 5:  Loss:     1.3044 Validation Accuracy: 0.484200\n",
      "Epoch 150, CIFAR-10 Batch 1:  Loss:     1.2572 Validation Accuracy: 0.482200\n",
      "Epoch 150, CIFAR-10 Batch 2:  Loss:     1.2798 Validation Accuracy: 0.483600\n",
      "Epoch 150, CIFAR-10 Batch 3:  Loss:     1.2332 Validation Accuracy: 0.484200\n",
      "Epoch 150, CIFAR-10 Batch 4:  Loss:     1.2489 Validation Accuracy: 0.486800\n",
      "Epoch 150, CIFAR-10 Batch 5:  Loss:     1.2943 Validation Accuracy: 0.486600\n",
      "Epoch 151, CIFAR-10 Batch 1:  Loss:     1.2529 Validation Accuracy: 0.482200\n",
      "Epoch 151, CIFAR-10 Batch 2:  Loss:     1.2729 Validation Accuracy: 0.483200\n",
      "Epoch 151, CIFAR-10 Batch 3:  Loss:     1.2246 Validation Accuracy: 0.485800\n",
      "Epoch 151, CIFAR-10 Batch 4:  Loss:     1.2488 Validation Accuracy: 0.485800\n",
      "Epoch 151, CIFAR-10 Batch 5:  Loss:     1.2871 Validation Accuracy: 0.491200\n",
      "Epoch 152, CIFAR-10 Batch 1:  Loss:     1.2534 Validation Accuracy: 0.484400\n",
      "Epoch 152, CIFAR-10 Batch 2:  Loss:     1.2693 Validation Accuracy: 0.482600\n",
      "Epoch 152, CIFAR-10 Batch 3:  Loss:     1.2223 Validation Accuracy: 0.490200\n",
      "Epoch 152, CIFAR-10 Batch 4:  Loss:     1.2408 Validation Accuracy: 0.481800\n",
      "Epoch 152, CIFAR-10 Batch 5:  Loss:     1.2880 Validation Accuracy: 0.491600\n",
      "Epoch 153, CIFAR-10 Batch 1:  Loss:     1.2501 Validation Accuracy: 0.481400\n",
      "Epoch 153, CIFAR-10 Batch 2:  Loss:     1.2669 Validation Accuracy: 0.487200\n",
      "Epoch 153, CIFAR-10 Batch 3:  Loss:     1.2254 Validation Accuracy: 0.486600\n",
      "Epoch 153, CIFAR-10 Batch 4:  Loss:     1.2393 Validation Accuracy: 0.487600\n",
      "Epoch 153, CIFAR-10 Batch 5:  Loss:     1.2868 Validation Accuracy: 0.489800\n",
      "Epoch 154, CIFAR-10 Batch 1:  Loss:     1.2491 Validation Accuracy: 0.481200\n",
      "Epoch 154, CIFAR-10 Batch 2:  Loss:     1.2657 Validation Accuracy: 0.486400\n",
      "Epoch 154, CIFAR-10 Batch 3:  Loss:     1.2211 Validation Accuracy: 0.488600\n",
      "Epoch 154, CIFAR-10 Batch 4:  Loss:     1.2348 Validation Accuracy: 0.484400\n",
      "Epoch 154, CIFAR-10 Batch 5:  Loss:     1.2814 Validation Accuracy: 0.491000\n",
      "Epoch 155, CIFAR-10 Batch 1:  Loss:     1.2452 Validation Accuracy: 0.482000\n",
      "Epoch 155, CIFAR-10 Batch 2:  Loss:     1.2587 Validation Accuracy: 0.492000\n",
      "Epoch 155, CIFAR-10 Batch 3:  Loss:     1.2186 Validation Accuracy: 0.488000\n",
      "Epoch 155, CIFAR-10 Batch 4:  Loss:     1.2363 Validation Accuracy: 0.489600\n",
      "Epoch 155, CIFAR-10 Batch 5:  Loss:     1.2827 Validation Accuracy: 0.492800\n",
      "Epoch 156, CIFAR-10 Batch 1:  Loss:     1.2423 Validation Accuracy: 0.483200\n",
      "Epoch 156, CIFAR-10 Batch 2:  Loss:     1.2576 Validation Accuracy: 0.488200\n",
      "Epoch 156, CIFAR-10 Batch 3:  Loss:     1.2174 Validation Accuracy: 0.490000\n",
      "Epoch 156, CIFAR-10 Batch 4:  Loss:     1.2405 Validation Accuracy: 0.487400\n",
      "Epoch 156, CIFAR-10 Batch 5:  Loss:     1.2825 Validation Accuracy: 0.492800\n",
      "Epoch 157, CIFAR-10 Batch 1:  Loss:     1.2463 Validation Accuracy: 0.482800\n",
      "Epoch 157, CIFAR-10 Batch 2:  Loss:     1.2598 Validation Accuracy: 0.488800\n",
      "Epoch 157, CIFAR-10 Batch 3:  Loss:     1.2158 Validation Accuracy: 0.488400\n",
      "Epoch 157, CIFAR-10 Batch 4:  Loss:     1.2311 Validation Accuracy: 0.487800\n",
      "Epoch 157, CIFAR-10 Batch 5:  Loss:     1.2789 Validation Accuracy: 0.493800\n",
      "Epoch 158, CIFAR-10 Batch 1:  Loss:     1.2448 Validation Accuracy: 0.482200\n",
      "Epoch 158, CIFAR-10 Batch 2:  Loss:     1.2648 Validation Accuracy: 0.484200\n",
      "Epoch 158, CIFAR-10 Batch 3:  Loss:     1.2158 Validation Accuracy: 0.487000\n",
      "Epoch 158, CIFAR-10 Batch 4:  Loss:     1.2285 Validation Accuracy: 0.491000\n",
      "Epoch 158, CIFAR-10 Batch 5:  Loss:     1.2776 Validation Accuracy: 0.490400\n",
      "Epoch 159, CIFAR-10 Batch 1:  Loss:     1.2370 Validation Accuracy: 0.489400\n",
      "Epoch 159, CIFAR-10 Batch 2:  Loss:     1.2488 Validation Accuracy: 0.492400\n",
      "Epoch 159, CIFAR-10 Batch 3:  Loss:     1.2149 Validation Accuracy: 0.485600\n",
      "Epoch 159, CIFAR-10 Batch 4:  Loss:     1.2269 Validation Accuracy: 0.490200\n",
      "Epoch 159, CIFAR-10 Batch 5:  Loss:     1.2750 Validation Accuracy: 0.488800\n",
      "Epoch 160, CIFAR-10 Batch 1:  Loss:     1.2391 Validation Accuracy: 0.492200\n",
      "Epoch 160, CIFAR-10 Batch 2:  Loss:     1.2420 Validation Accuracy: 0.492400\n",
      "Epoch 160, CIFAR-10 Batch 3:  Loss:     1.2180 Validation Accuracy: 0.485800\n",
      "Epoch 160, CIFAR-10 Batch 4:  Loss:     1.2313 Validation Accuracy: 0.486800\n",
      "Epoch 160, CIFAR-10 Batch 5:  Loss:     1.2810 Validation Accuracy: 0.489200\n",
      "Epoch 161, CIFAR-10 Batch 1:  Loss:     1.2358 Validation Accuracy: 0.487600\n",
      "Epoch 161, CIFAR-10 Batch 2:  Loss:     1.2392 Validation Accuracy: 0.492400\n",
      "Epoch 161, CIFAR-10 Batch 3:  Loss:     1.2138 Validation Accuracy: 0.486800\n",
      "Epoch 161, CIFAR-10 Batch 4:  Loss:     1.2305 Validation Accuracy: 0.488000\n",
      "Epoch 161, CIFAR-10 Batch 5:  Loss:     1.2771 Validation Accuracy: 0.492200\n",
      "Epoch 162, CIFAR-10 Batch 1:  Loss:     1.2380 Validation Accuracy: 0.489800\n",
      "Epoch 162, CIFAR-10 Batch 2:  Loss:     1.2339 Validation Accuracy: 0.491000\n",
      "Epoch 162, CIFAR-10 Batch 3:  Loss:     1.2092 Validation Accuracy: 0.490000\n",
      "Epoch 162, CIFAR-10 Batch 4:  Loss:     1.2222 Validation Accuracy: 0.486600\n",
      "Epoch 162, CIFAR-10 Batch 5:  Loss:     1.2719 Validation Accuracy: 0.492800\n",
      "Epoch 163, CIFAR-10 Batch 1:  Loss:     1.2283 Validation Accuracy: 0.492200\n",
      "Epoch 163, CIFAR-10 Batch 2:  Loss:     1.2318 Validation Accuracy: 0.490400\n",
      "Epoch 163, CIFAR-10 Batch 3:  Loss:     1.2130 Validation Accuracy: 0.489600\n",
      "Epoch 163, CIFAR-10 Batch 4:  Loss:     1.2180 Validation Accuracy: 0.492200\n",
      "Epoch 163, CIFAR-10 Batch 5:  Loss:     1.2715 Validation Accuracy: 0.490800\n",
      "Epoch 164, CIFAR-10 Batch 1:  Loss:     1.2235 Validation Accuracy: 0.495400\n",
      "Epoch 164, CIFAR-10 Batch 2:  Loss:     1.2406 Validation Accuracy: 0.486800\n",
      "Epoch 164, CIFAR-10 Batch 3:  Loss:     1.2058 Validation Accuracy: 0.494000\n",
      "Epoch 164, CIFAR-10 Batch 4:  Loss:     1.2171 Validation Accuracy: 0.489800\n",
      "Epoch 164, CIFAR-10 Batch 5:  Loss:     1.2610 Validation Accuracy: 0.494800\n",
      "Epoch 165, CIFAR-10 Batch 1:  Loss:     1.2189 Validation Accuracy: 0.493800\n",
      "Epoch 165, CIFAR-10 Batch 2:  Loss:     1.2372 Validation Accuracy: 0.494400\n",
      "Epoch 165, CIFAR-10 Batch 3:  Loss:     1.2035 Validation Accuracy: 0.496600\n",
      "Epoch 165, CIFAR-10 Batch 4:  Loss:     1.2213 Validation Accuracy: 0.489200\n",
      "Epoch 165, CIFAR-10 Batch 5:  Loss:     1.2583 Validation Accuracy: 0.495400\n",
      "Epoch 166, CIFAR-10 Batch 1:  Loss:     1.2179 Validation Accuracy: 0.492800\n",
      "Epoch 166, CIFAR-10 Batch 2:  Loss:     1.2328 Validation Accuracy: 0.492000\n",
      "Epoch 166, CIFAR-10 Batch 3:  Loss:     1.2020 Validation Accuracy: 0.495800\n",
      "Epoch 166, CIFAR-10 Batch 4:  Loss:     1.2203 Validation Accuracy: 0.487600\n",
      "Epoch 166, CIFAR-10 Batch 5:  Loss:     1.2624 Validation Accuracy: 0.495200\n",
      "Epoch 167, CIFAR-10 Batch 1:  Loss:     1.2221 Validation Accuracy: 0.489600\n",
      "Epoch 167, CIFAR-10 Batch 2:  Loss:     1.2316 Validation Accuracy: 0.490800\n",
      "Epoch 167, CIFAR-10 Batch 3:  Loss:     1.1995 Validation Accuracy: 0.497400\n",
      "Epoch 167, CIFAR-10 Batch 4:  Loss:     1.2152 Validation Accuracy: 0.490000\n",
      "Epoch 167, CIFAR-10 Batch 5:  Loss:     1.2565 Validation Accuracy: 0.495400\n",
      "Epoch 168, CIFAR-10 Batch 1:  Loss:     1.2200 Validation Accuracy: 0.492800\n",
      "Epoch 168, CIFAR-10 Batch 2:  Loss:     1.2339 Validation Accuracy: 0.488200\n",
      "Epoch 168, CIFAR-10 Batch 3:  Loss:     1.1976 Validation Accuracy: 0.501200\n",
      "Epoch 168, CIFAR-10 Batch 4:  Loss:     1.2137 Validation Accuracy: 0.493200\n",
      "Epoch 168, CIFAR-10 Batch 5:  Loss:     1.2508 Validation Accuracy: 0.500000\n",
      "Epoch 169, CIFAR-10 Batch 1:  Loss:     1.2160 Validation Accuracy: 0.490800\n",
      "Epoch 169, CIFAR-10 Batch 2:  Loss:     1.2238 Validation Accuracy: 0.492200\n",
      "Epoch 169, CIFAR-10 Batch 3:  Loss:     1.1986 Validation Accuracy: 0.500400\n",
      "Epoch 169, CIFAR-10 Batch 4:  Loss:     1.2096 Validation Accuracy: 0.492000\n",
      "Epoch 169, CIFAR-10 Batch 5:  Loss:     1.2503 Validation Accuracy: 0.500800\n",
      "Epoch 170, CIFAR-10 Batch 1:  Loss:     1.2139 Validation Accuracy: 0.493600\n",
      "Epoch 170, CIFAR-10 Batch 2:  Loss:     1.2219 Validation Accuracy: 0.494000\n",
      "Epoch 170, CIFAR-10 Batch 3:  Loss:     1.1939 Validation Accuracy: 0.500800\n",
      "Epoch 170, CIFAR-10 Batch 4:  Loss:     1.2048 Validation Accuracy: 0.493200\n",
      "Epoch 170, CIFAR-10 Batch 5:  Loss:     1.2498 Validation Accuracy: 0.500000\n",
      "Epoch 171, CIFAR-10 Batch 1:  Loss:     1.2128 Validation Accuracy: 0.491000\n",
      "Epoch 171, CIFAR-10 Batch 2:  Loss:     1.2150 Validation Accuracy: 0.497000\n",
      "Epoch 171, CIFAR-10 Batch 3:  Loss:     1.1881 Validation Accuracy: 0.500400\n",
      "Epoch 171, CIFAR-10 Batch 4:  Loss:     1.1980 Validation Accuracy: 0.493000\n",
      "Epoch 171, CIFAR-10 Batch 5:  Loss:     1.2466 Validation Accuracy: 0.500600\n",
      "Epoch 172, CIFAR-10 Batch 1:  Loss:     1.2060 Validation Accuracy: 0.493400\n",
      "Epoch 172, CIFAR-10 Batch 2:  Loss:     1.2182 Validation Accuracy: 0.497000\n",
      "Epoch 172, CIFAR-10 Batch 3:  Loss:     1.1905 Validation Accuracy: 0.501600\n",
      "Epoch 172, CIFAR-10 Batch 4:  Loss:     1.2033 Validation Accuracy: 0.492400\n",
      "Epoch 172, CIFAR-10 Batch 5:  Loss:     1.2412 Validation Accuracy: 0.502400\n",
      "Epoch 173, CIFAR-10 Batch 1:  Loss:     1.2044 Validation Accuracy: 0.498800\n",
      "Epoch 173, CIFAR-10 Batch 2:  Loss:     1.2082 Validation Accuracy: 0.497000\n",
      "Epoch 173, CIFAR-10 Batch 3:  Loss:     1.1898 Validation Accuracy: 0.502600\n",
      "Epoch 173, CIFAR-10 Batch 4:  Loss:     1.2060 Validation Accuracy: 0.489800\n",
      "Epoch 173, CIFAR-10 Batch 5:  Loss:     1.2422 Validation Accuracy: 0.499000\n",
      "Epoch 174, CIFAR-10 Batch 1:  Loss:     1.2064 Validation Accuracy: 0.494400\n",
      "Epoch 174, CIFAR-10 Batch 2:  Loss:     1.2050 Validation Accuracy: 0.500600\n",
      "Epoch 174, CIFAR-10 Batch 3:  Loss:     1.1864 Validation Accuracy: 0.503000\n",
      "Epoch 174, CIFAR-10 Batch 4:  Loss:     1.1980 Validation Accuracy: 0.494200\n",
      "Epoch 174, CIFAR-10 Batch 5:  Loss:     1.2408 Validation Accuracy: 0.500000\n",
      "Epoch 175, CIFAR-10 Batch 1:  Loss:     1.2032 Validation Accuracy: 0.497800\n",
      "Epoch 175, CIFAR-10 Batch 2:  Loss:     1.2034 Validation Accuracy: 0.502800\n",
      "Epoch 175, CIFAR-10 Batch 3:  Loss:     1.1900 Validation Accuracy: 0.503200\n",
      "Epoch 175, CIFAR-10 Batch 4:  Loss:     1.1999 Validation Accuracy: 0.488200\n",
      "Epoch 175, CIFAR-10 Batch 5:  Loss:     1.2431 Validation Accuracy: 0.499800\n",
      "Epoch 176, CIFAR-10 Batch 1:  Loss:     1.2011 Validation Accuracy: 0.496200\n",
      "Epoch 176, CIFAR-10 Batch 2:  Loss:     1.2047 Validation Accuracy: 0.501000\n",
      "Epoch 176, CIFAR-10 Batch 3:  Loss:     1.1861 Validation Accuracy: 0.501600\n",
      "Epoch 176, CIFAR-10 Batch 4:  Loss:     1.1976 Validation Accuracy: 0.492000\n",
      "Epoch 176, CIFAR-10 Batch 5:  Loss:     1.2417 Validation Accuracy: 0.497000\n",
      "Epoch 177, CIFAR-10 Batch 1:  Loss:     1.2019 Validation Accuracy: 0.496000\n",
      "Epoch 177, CIFAR-10 Batch 2:  Loss:     1.2018 Validation Accuracy: 0.497400\n",
      "Epoch 177, CIFAR-10 Batch 3:  Loss:     1.1837 Validation Accuracy: 0.498600\n",
      "Epoch 177, CIFAR-10 Batch 4:  Loss:     1.1984 Validation Accuracy: 0.490400\n",
      "Epoch 177, CIFAR-10 Batch 5:  Loss:     1.2355 Validation Accuracy: 0.504400\n",
      "Epoch 178, CIFAR-10 Batch 1:  Loss:     1.2014 Validation Accuracy: 0.497200\n",
      "Epoch 178, CIFAR-10 Batch 2:  Loss:     1.1959 Validation Accuracy: 0.502600\n",
      "Epoch 178, CIFAR-10 Batch 3:  Loss:     1.1801 Validation Accuracy: 0.505800\n",
      "Epoch 178, CIFAR-10 Batch 4:  Loss:     1.1913 Validation Accuracy: 0.491600\n",
      "Epoch 178, CIFAR-10 Batch 5:  Loss:     1.2339 Validation Accuracy: 0.502200\n",
      "Epoch 179, CIFAR-10 Batch 1:  Loss:     1.1985 Validation Accuracy: 0.495800\n",
      "Epoch 179, CIFAR-10 Batch 2:  Loss:     1.1972 Validation Accuracy: 0.503800\n",
      "Epoch 179, CIFAR-10 Batch 3:  Loss:     1.1854 Validation Accuracy: 0.501400\n",
      "Epoch 179, CIFAR-10 Batch 4:  Loss:     1.1947 Validation Accuracy: 0.491000\n",
      "Epoch 179, CIFAR-10 Batch 5:  Loss:     1.2325 Validation Accuracy: 0.503000\n",
      "Epoch 180, CIFAR-10 Batch 1:  Loss:     1.1970 Validation Accuracy: 0.498800\n",
      "Epoch 180, CIFAR-10 Batch 2:  Loss:     1.1940 Validation Accuracy: 0.501000\n",
      "Epoch 180, CIFAR-10 Batch 3:  Loss:     1.1781 Validation Accuracy: 0.503000\n",
      "Epoch 180, CIFAR-10 Batch 4:  Loss:     1.1899 Validation Accuracy: 0.493000\n",
      "Epoch 180, CIFAR-10 Batch 5:  Loss:     1.2291 Validation Accuracy: 0.505000\n",
      "Epoch 181, CIFAR-10 Batch 1:  Loss:     1.1944 Validation Accuracy: 0.500000\n",
      "Epoch 181, CIFAR-10 Batch 2:  Loss:     1.1923 Validation Accuracy: 0.503800\n",
      "Epoch 181, CIFAR-10 Batch 3:  Loss:     1.1745 Validation Accuracy: 0.507200\n",
      "Epoch 181, CIFAR-10 Batch 4:  Loss:     1.1857 Validation Accuracy: 0.493800\n",
      "Epoch 181, CIFAR-10 Batch 5:  Loss:     1.2295 Validation Accuracy: 0.504400\n",
      "Epoch 182, CIFAR-10 Batch 1:  Loss:     1.1908 Validation Accuracy: 0.498000\n",
      "Epoch 182, CIFAR-10 Batch 2:  Loss:     1.1948 Validation Accuracy: 0.499400\n",
      "Epoch 182, CIFAR-10 Batch 3:  Loss:     1.1771 Validation Accuracy: 0.502400\n",
      "Epoch 182, CIFAR-10 Batch 4:  Loss:     1.1908 Validation Accuracy: 0.489400\n",
      "Epoch 182, CIFAR-10 Batch 5:  Loss:     1.2232 Validation Accuracy: 0.506400\n",
      "Epoch 183, CIFAR-10 Batch 1:  Loss:     1.1882 Validation Accuracy: 0.499600\n",
      "Epoch 183, CIFAR-10 Batch 2:  Loss:     1.1899 Validation Accuracy: 0.500000\n",
      "Epoch 183, CIFAR-10 Batch 3:  Loss:     1.1746 Validation Accuracy: 0.502400\n",
      "Epoch 183, CIFAR-10 Batch 4:  Loss:     1.1862 Validation Accuracy: 0.492400\n",
      "Epoch 183, CIFAR-10 Batch 5:  Loss:     1.2236 Validation Accuracy: 0.505000\n",
      "Epoch 184, CIFAR-10 Batch 1:  Loss:     1.1891 Validation Accuracy: 0.499200\n",
      "Epoch 184, CIFAR-10 Batch 2:  Loss:     1.1934 Validation Accuracy: 0.502200\n",
      "Epoch 184, CIFAR-10 Batch 3:  Loss:     1.1712 Validation Accuracy: 0.503400\n",
      "Epoch 184, CIFAR-10 Batch 4:  Loss:     1.1840 Validation Accuracy: 0.492400\n",
      "Epoch 184, CIFAR-10 Batch 5:  Loss:     1.2215 Validation Accuracy: 0.506000\n",
      "Epoch 185, CIFAR-10 Batch 1:  Loss:     1.1880 Validation Accuracy: 0.498600\n",
      "Epoch 185, CIFAR-10 Batch 2:  Loss:     1.1913 Validation Accuracy: 0.501000\n",
      "Epoch 185, CIFAR-10 Batch 3:  Loss:     1.1813 Validation Accuracy: 0.506200\n",
      "Epoch 185, CIFAR-10 Batch 4:  Loss:     1.1876 Validation Accuracy: 0.496400\n",
      "Epoch 185, CIFAR-10 Batch 5:  Loss:     1.2293 Validation Accuracy: 0.500800\n",
      "Epoch 186, CIFAR-10 Batch 1:  Loss:     1.1869 Validation Accuracy: 0.496000\n",
      "Epoch 186, CIFAR-10 Batch 2:  Loss:     1.1853 Validation Accuracy: 0.503200\n",
      "Epoch 186, CIFAR-10 Batch 3:  Loss:     1.1706 Validation Accuracy: 0.504800\n",
      "Epoch 186, CIFAR-10 Batch 4:  Loss:     1.1804 Validation Accuracy: 0.495000\n",
      "Epoch 186, CIFAR-10 Batch 5:  Loss:     1.2167 Validation Accuracy: 0.504800\n",
      "Epoch 187, CIFAR-10 Batch 1:  Loss:     1.1841 Validation Accuracy: 0.501400\n",
      "Epoch 187, CIFAR-10 Batch 2:  Loss:     1.1814 Validation Accuracy: 0.503400\n",
      "Epoch 187, CIFAR-10 Batch 3:  Loss:     1.1717 Validation Accuracy: 0.502800\n",
      "Epoch 187, CIFAR-10 Batch 4:  Loss:     1.1809 Validation Accuracy: 0.492800\n",
      "Epoch 187, CIFAR-10 Batch 5:  Loss:     1.2156 Validation Accuracy: 0.505400\n",
      "Epoch 188, CIFAR-10 Batch 1:  Loss:     1.1804 Validation Accuracy: 0.505000\n",
      "Epoch 188, CIFAR-10 Batch 2:  Loss:     1.1830 Validation Accuracy: 0.504000\n",
      "Epoch 188, CIFAR-10 Batch 3:  Loss:     1.1765 Validation Accuracy: 0.500800\n",
      "Epoch 188, CIFAR-10 Batch 4:  Loss:     1.1928 Validation Accuracy: 0.488800\n",
      "Epoch 188, CIFAR-10 Batch 5:  Loss:     1.2151 Validation Accuracy: 0.506800\n",
      "Epoch 189, CIFAR-10 Batch 1:  Loss:     1.1829 Validation Accuracy: 0.496600\n",
      "Epoch 189, CIFAR-10 Batch 2:  Loss:     1.1839 Validation Accuracy: 0.504400\n",
      "Epoch 189, CIFAR-10 Batch 3:  Loss:     1.1708 Validation Accuracy: 0.508800\n",
      "Epoch 189, CIFAR-10 Batch 4:  Loss:     1.1756 Validation Accuracy: 0.495800\n",
      "Epoch 189, CIFAR-10 Batch 5:  Loss:     1.2213 Validation Accuracy: 0.502800\n",
      "Epoch 190, CIFAR-10 Batch 1:  Loss:     1.1814 Validation Accuracy: 0.497200\n",
      "Epoch 190, CIFAR-10 Batch 2:  Loss:     1.1822 Validation Accuracy: 0.502600\n",
      "Epoch 190, CIFAR-10 Batch 3:  Loss:     1.1692 Validation Accuracy: 0.503200\n",
      "Epoch 190, CIFAR-10 Batch 4:  Loss:     1.1731 Validation Accuracy: 0.497400\n",
      "Epoch 190, CIFAR-10 Batch 5:  Loss:     1.2105 Validation Accuracy: 0.509400\n",
      "Epoch 191, CIFAR-10 Batch 1:  Loss:     1.1802 Validation Accuracy: 0.496000\n",
      "Epoch 191, CIFAR-10 Batch 2:  Loss:     1.1836 Validation Accuracy: 0.504000\n",
      "Epoch 191, CIFAR-10 Batch 3:  Loss:     1.1660 Validation Accuracy: 0.507800\n",
      "Epoch 191, CIFAR-10 Batch 4:  Loss:     1.1670 Validation Accuracy: 0.501800\n",
      "Epoch 191, CIFAR-10 Batch 5:  Loss:     1.2124 Validation Accuracy: 0.507200\n",
      "Epoch 192, CIFAR-10 Batch 1:  Loss:     1.1758 Validation Accuracy: 0.495400\n",
      "Epoch 192, CIFAR-10 Batch 2:  Loss:     1.1745 Validation Accuracy: 0.505600\n",
      "Epoch 192, CIFAR-10 Batch 3:  Loss:     1.1606 Validation Accuracy: 0.505400\n",
      "Epoch 192, CIFAR-10 Batch 4:  Loss:     1.1649 Validation Accuracy: 0.500800\n",
      "Epoch 192, CIFAR-10 Batch 5:  Loss:     1.2054 Validation Accuracy: 0.507600\n",
      "Epoch 193, CIFAR-10 Batch 1:  Loss:     1.1744 Validation Accuracy: 0.499600\n",
      "Epoch 193, CIFAR-10 Batch 2:  Loss:     1.1810 Validation Accuracy: 0.507800\n",
      "Epoch 193, CIFAR-10 Batch 3:  Loss:     1.1690 Validation Accuracy: 0.505400\n",
      "Epoch 193, CIFAR-10 Batch 4:  Loss:     1.1713 Validation Accuracy: 0.494400\n",
      "Epoch 193, CIFAR-10 Batch 5:  Loss:     1.2146 Validation Accuracy: 0.504200\n",
      "Epoch 194, CIFAR-10 Batch 1:  Loss:     1.1775 Validation Accuracy: 0.502200\n",
      "Epoch 194, CIFAR-10 Batch 2:  Loss:     1.1786 Validation Accuracy: 0.504600\n",
      "Epoch 194, CIFAR-10 Batch 3:  Loss:     1.1615 Validation Accuracy: 0.504200\n",
      "Epoch 194, CIFAR-10 Batch 4:  Loss:     1.1645 Validation Accuracy: 0.496800\n",
      "Epoch 194, CIFAR-10 Batch 5:  Loss:     1.2129 Validation Accuracy: 0.504600\n",
      "Epoch 195, CIFAR-10 Batch 1:  Loss:     1.1705 Validation Accuracy: 0.501400\n",
      "Epoch 195, CIFAR-10 Batch 2:  Loss:     1.1746 Validation Accuracy: 0.504000\n",
      "Epoch 195, CIFAR-10 Batch 3:  Loss:     1.1652 Validation Accuracy: 0.506400\n",
      "Epoch 195, CIFAR-10 Batch 4:  Loss:     1.1698 Validation Accuracy: 0.494600\n",
      "Epoch 195, CIFAR-10 Batch 5:  Loss:     1.2048 Validation Accuracy: 0.506800\n",
      "Epoch 196, CIFAR-10 Batch 1:  Loss:     1.1664 Validation Accuracy: 0.502200\n",
      "Epoch 196, CIFAR-10 Batch 2:  Loss:     1.1876 Validation Accuracy: 0.500200\n",
      "Epoch 196, CIFAR-10 Batch 3:  Loss:     1.1602 Validation Accuracy: 0.508400\n",
      "Epoch 196, CIFAR-10 Batch 4:  Loss:     1.1741 Validation Accuracy: 0.496000\n",
      "Epoch 196, CIFAR-10 Batch 5:  Loss:     1.2026 Validation Accuracy: 0.510400\n",
      "Epoch 197, CIFAR-10 Batch 1:  Loss:     1.1730 Validation Accuracy: 0.500200\n",
      "Epoch 197, CIFAR-10 Batch 2:  Loss:     1.1970 Validation Accuracy: 0.496600\n",
      "Epoch 197, CIFAR-10 Batch 3:  Loss:     1.1562 Validation Accuracy: 0.511400\n",
      "Epoch 197, CIFAR-10 Batch 4:  Loss:     1.1770 Validation Accuracy: 0.502200\n",
      "Epoch 197, CIFAR-10 Batch 5:  Loss:     1.1958 Validation Accuracy: 0.513000\n",
      "Epoch 198, CIFAR-10 Batch 1:  Loss:     1.1851 Validation Accuracy: 0.498200\n",
      "Epoch 198, CIFAR-10 Batch 2:  Loss:     1.1641 Validation Accuracy: 0.505200\n",
      "Epoch 198, CIFAR-10 Batch 3:  Loss:     1.1636 Validation Accuracy: 0.501400\n",
      "Epoch 198, CIFAR-10 Batch 4:  Loss:     1.1650 Validation Accuracy: 0.503200\n",
      "Epoch 198, CIFAR-10 Batch 5:  Loss:     1.2008 Validation Accuracy: 0.510800\n",
      "Epoch 199, CIFAR-10 Batch 1:  Loss:     1.1762 Validation Accuracy: 0.501000\n",
      "Epoch 199, CIFAR-10 Batch 2:  Loss:     1.1608 Validation Accuracy: 0.507400\n",
      "Epoch 199, CIFAR-10 Batch 3:  Loss:     1.1603 Validation Accuracy: 0.508400\n",
      "Epoch 199, CIFAR-10 Batch 4:  Loss:     1.1557 Validation Accuracy: 0.504800\n",
      "Epoch 199, CIFAR-10 Batch 5:  Loss:     1.1922 Validation Accuracy: 0.510200\n",
      "Epoch 200, CIFAR-10 Batch 1:  Loss:     1.1623 Validation Accuracy: 0.503200\n",
      "Epoch 200, CIFAR-10 Batch 2:  Loss:     1.1612 Validation Accuracy: 0.509200\n",
      "Epoch 200, CIFAR-10 Batch 3:  Loss:     1.1464 Validation Accuracy: 0.513800\n",
      "Epoch 200, CIFAR-10 Batch 4:  Loss:     1.1580 Validation Accuracy: 0.498600\n",
      "Epoch 200, CIFAR-10 Batch 5:  Loss:     1.1892 Validation Accuracy: 0.514800\n",
      "Epoch 201, CIFAR-10 Batch 1:  Loss:     1.1592 Validation Accuracy: 0.505400\n",
      "Epoch 201, CIFAR-10 Batch 2:  Loss:     1.1634 Validation Accuracy: 0.505800\n",
      "Epoch 201, CIFAR-10 Batch 3:  Loss:     1.1549 Validation Accuracy: 0.515000\n",
      "Epoch 201, CIFAR-10 Batch 4:  Loss:     1.1547 Validation Accuracy: 0.502200\n",
      "Epoch 201, CIFAR-10 Batch 5:  Loss:     1.1913 Validation Accuracy: 0.511600\n",
      "Epoch 202, CIFAR-10 Batch 1:  Loss:     1.1600 Validation Accuracy: 0.508200\n",
      "Epoch 202, CIFAR-10 Batch 2:  Loss:     1.1642 Validation Accuracy: 0.510000\n",
      "Epoch 202, CIFAR-10 Batch 3:  Loss:     1.1452 Validation Accuracy: 0.512600\n",
      "Epoch 202, CIFAR-10 Batch 4:  Loss:     1.1500 Validation Accuracy: 0.504200\n",
      "Epoch 202, CIFAR-10 Batch 5:  Loss:     1.1871 Validation Accuracy: 0.514400\n",
      "Epoch 203, CIFAR-10 Batch 1:  Loss:     1.1608 Validation Accuracy: 0.503000\n",
      "Epoch 203, CIFAR-10 Batch 2:  Loss:     1.1630 Validation Accuracy: 0.513000\n",
      "Epoch 203, CIFAR-10 Batch 3:  Loss:     1.1468 Validation Accuracy: 0.514200\n",
      "Epoch 203, CIFAR-10 Batch 4:  Loss:     1.1526 Validation Accuracy: 0.504200\n",
      "Epoch 203, CIFAR-10 Batch 5:  Loss:     1.1885 Validation Accuracy: 0.513400\n",
      "Epoch 204, CIFAR-10 Batch 1:  Loss:     1.1608 Validation Accuracy: 0.503200\n",
      "Epoch 204, CIFAR-10 Batch 2:  Loss:     1.1636 Validation Accuracy: 0.506000\n",
      "Epoch 204, CIFAR-10 Batch 3:  Loss:     1.1460 Validation Accuracy: 0.514000\n",
      "Epoch 204, CIFAR-10 Batch 4:  Loss:     1.1489 Validation Accuracy: 0.504200\n",
      "Epoch 204, CIFAR-10 Batch 5:  Loss:     1.1857 Validation Accuracy: 0.513800\n",
      "Epoch 205, CIFAR-10 Batch 1:  Loss:     1.1677 Validation Accuracy: 0.504400\n",
      "Epoch 205, CIFAR-10 Batch 2:  Loss:     1.1650 Validation Accuracy: 0.510600\n",
      "Epoch 205, CIFAR-10 Batch 3:  Loss:     1.1451 Validation Accuracy: 0.515000\n",
      "Epoch 205, CIFAR-10 Batch 4:  Loss:     1.1570 Validation Accuracy: 0.504400\n",
      "Epoch 205, CIFAR-10 Batch 5:  Loss:     1.1799 Validation Accuracy: 0.516200\n",
      "Epoch 206, CIFAR-10 Batch 1:  Loss:     1.1767 Validation Accuracy: 0.500600\n",
      "Epoch 206, CIFAR-10 Batch 2:  Loss:     1.1596 Validation Accuracy: 0.511200\n",
      "Epoch 206, CIFAR-10 Batch 3:  Loss:     1.1497 Validation Accuracy: 0.505600\n",
      "Epoch 206, CIFAR-10 Batch 4:  Loss:     1.1465 Validation Accuracy: 0.507200\n",
      "Epoch 206, CIFAR-10 Batch 5:  Loss:     1.1831 Validation Accuracy: 0.514000\n",
      "Epoch 207, CIFAR-10 Batch 1:  Loss:     1.1608 Validation Accuracy: 0.505400\n",
      "Epoch 207, CIFAR-10 Batch 2:  Loss:     1.1514 Validation Accuracy: 0.514400\n",
      "Epoch 207, CIFAR-10 Batch 3:  Loss:     1.1450 Validation Accuracy: 0.513800\n",
      "Epoch 207, CIFAR-10 Batch 4:  Loss:     1.1408 Validation Accuracy: 0.509200\n",
      "Epoch 207, CIFAR-10 Batch 5:  Loss:     1.1777 Validation Accuracy: 0.512600\n",
      "Epoch 208, CIFAR-10 Batch 1:  Loss:     1.1573 Validation Accuracy: 0.508600\n",
      "Epoch 208, CIFAR-10 Batch 2:  Loss:     1.1506 Validation Accuracy: 0.514000\n",
      "Epoch 208, CIFAR-10 Batch 3:  Loss:     1.1397 Validation Accuracy: 0.513400\n",
      "Epoch 208, CIFAR-10 Batch 4:  Loss:     1.1385 Validation Accuracy: 0.509600\n",
      "Epoch 208, CIFAR-10 Batch 5:  Loss:     1.1791 Validation Accuracy: 0.515800\n",
      "Epoch 209, CIFAR-10 Batch 1:  Loss:     1.1596 Validation Accuracy: 0.505600\n",
      "Epoch 209, CIFAR-10 Batch 2:  Loss:     1.1501 Validation Accuracy: 0.517000\n",
      "Epoch 209, CIFAR-10 Batch 3:  Loss:     1.1437 Validation Accuracy: 0.514000\n",
      "Epoch 209, CIFAR-10 Batch 4:  Loss:     1.1421 Validation Accuracy: 0.508600\n",
      "Epoch 209, CIFAR-10 Batch 5:  Loss:     1.1764 Validation Accuracy: 0.514400\n",
      "Epoch 210, CIFAR-10 Batch 1:  Loss:     1.1544 Validation Accuracy: 0.509000\n",
      "Epoch 210, CIFAR-10 Batch 2:  Loss:     1.1455 Validation Accuracy: 0.516400\n",
      "Epoch 210, CIFAR-10 Batch 3:  Loss:     1.1383 Validation Accuracy: 0.515800\n",
      "Epoch 210, CIFAR-10 Batch 4:  Loss:     1.1392 Validation Accuracy: 0.507800\n",
      "Epoch 210, CIFAR-10 Batch 5:  Loss:     1.1746 Validation Accuracy: 0.516800\n",
      "Epoch 211, CIFAR-10 Batch 1:  Loss:     1.1496 Validation Accuracy: 0.512200\n",
      "Epoch 211, CIFAR-10 Batch 2:  Loss:     1.1492 Validation Accuracy: 0.510600\n",
      "Epoch 211, CIFAR-10 Batch 3:  Loss:     1.1452 Validation Accuracy: 0.515000\n",
      "Epoch 211, CIFAR-10 Batch 4:  Loss:     1.1373 Validation Accuracy: 0.511800\n",
      "Epoch 211, CIFAR-10 Batch 5:  Loss:     1.1775 Validation Accuracy: 0.514200\n",
      "Epoch 212, CIFAR-10 Batch 1:  Loss:     1.1518 Validation Accuracy: 0.508600\n",
      "Epoch 212, CIFAR-10 Batch 2:  Loss:     1.1488 Validation Accuracy: 0.513800\n",
      "Epoch 212, CIFAR-10 Batch 3:  Loss:     1.1359 Validation Accuracy: 0.517000\n",
      "Epoch 212, CIFAR-10 Batch 4:  Loss:     1.1386 Validation Accuracy: 0.508000\n",
      "Epoch 212, CIFAR-10 Batch 5:  Loss:     1.1712 Validation Accuracy: 0.515000\n",
      "Epoch 213, CIFAR-10 Batch 1:  Loss:     1.1557 Validation Accuracy: 0.507000\n",
      "Epoch 213, CIFAR-10 Batch 2:  Loss:     1.1487 Validation Accuracy: 0.512800\n",
      "Epoch 213, CIFAR-10 Batch 3:  Loss:     1.1436 Validation Accuracy: 0.511400\n",
      "Epoch 213, CIFAR-10 Batch 4:  Loss:     1.1324 Validation Accuracy: 0.511200\n",
      "Epoch 213, CIFAR-10 Batch 5:  Loss:     1.1705 Validation Accuracy: 0.515400\n",
      "Epoch 214, CIFAR-10 Batch 1:  Loss:     1.1539 Validation Accuracy: 0.508400\n",
      "Epoch 214, CIFAR-10 Batch 2:  Loss:     1.1475 Validation Accuracy: 0.514400\n",
      "Epoch 214, CIFAR-10 Batch 3:  Loss:     1.1309 Validation Accuracy: 0.516400\n",
      "Epoch 214, CIFAR-10 Batch 4:  Loss:     1.1288 Validation Accuracy: 0.514600\n",
      "Epoch 214, CIFAR-10 Batch 5:  Loss:     1.1674 Validation Accuracy: 0.517600\n",
      "Epoch 215, CIFAR-10 Batch 1:  Loss:     1.1488 Validation Accuracy: 0.511200\n",
      "Epoch 215, CIFAR-10 Batch 2:  Loss:     1.1446 Validation Accuracy: 0.515000\n",
      "Epoch 215, CIFAR-10 Batch 3:  Loss:     1.1349 Validation Accuracy: 0.517400\n",
      "Epoch 215, CIFAR-10 Batch 4:  Loss:     1.1278 Validation Accuracy: 0.513600\n",
      "Epoch 215, CIFAR-10 Batch 5:  Loss:     1.1614 Validation Accuracy: 0.519000\n",
      "Epoch 216, CIFAR-10 Batch 1:  Loss:     1.1439 Validation Accuracy: 0.510200\n",
      "Epoch 216, CIFAR-10 Batch 2:  Loss:     1.1395 Validation Accuracy: 0.514600\n",
      "Epoch 216, CIFAR-10 Batch 3:  Loss:     1.1332 Validation Accuracy: 0.517200\n",
      "Epoch 216, CIFAR-10 Batch 4:  Loss:     1.1281 Validation Accuracy: 0.515400\n",
      "Epoch 216, CIFAR-10 Batch 5:  Loss:     1.1665 Validation Accuracy: 0.519400\n",
      "Epoch 217, CIFAR-10 Batch 1:  Loss:     1.1395 Validation Accuracy: 0.515800\n",
      "Epoch 217, CIFAR-10 Batch 2:  Loss:     1.1469 Validation Accuracy: 0.512400\n",
      "Epoch 217, CIFAR-10 Batch 3:  Loss:     1.1287 Validation Accuracy: 0.519800\n",
      "Epoch 217, CIFAR-10 Batch 4:  Loss:     1.1336 Validation Accuracy: 0.512400\n",
      "Epoch 217, CIFAR-10 Batch 5:  Loss:     1.1597 Validation Accuracy: 0.521200\n",
      "Epoch 218, CIFAR-10 Batch 1:  Loss:     1.1456 Validation Accuracy: 0.513400\n",
      "Epoch 218, CIFAR-10 Batch 2:  Loss:     1.1427 Validation Accuracy: 0.513800\n",
      "Epoch 218, CIFAR-10 Batch 3:  Loss:     1.1306 Validation Accuracy: 0.523600\n",
      "Epoch 218, CIFAR-10 Batch 4:  Loss:     1.1324 Validation Accuracy: 0.510200\n",
      "Epoch 218, CIFAR-10 Batch 5:  Loss:     1.1621 Validation Accuracy: 0.519000\n",
      "Epoch 219, CIFAR-10 Batch 1:  Loss:     1.1428 Validation Accuracy: 0.513400\n",
      "Epoch 219, CIFAR-10 Batch 2:  Loss:     1.1413 Validation Accuracy: 0.516400\n",
      "Epoch 219, CIFAR-10 Batch 3:  Loss:     1.1324 Validation Accuracy: 0.519000\n",
      "Epoch 219, CIFAR-10 Batch 4:  Loss:     1.1274 Validation Accuracy: 0.511000\n",
      "Epoch 219, CIFAR-10 Batch 5:  Loss:     1.1631 Validation Accuracy: 0.518800\n",
      "Epoch 220, CIFAR-10 Batch 1:  Loss:     1.1559 Validation Accuracy: 0.509400\n",
      "Epoch 220, CIFAR-10 Batch 2:  Loss:     1.1408 Validation Accuracy: 0.514200\n",
      "Epoch 220, CIFAR-10 Batch 3:  Loss:     1.1337 Validation Accuracy: 0.517400\n",
      "Epoch 220, CIFAR-10 Batch 4:  Loss:     1.1300 Validation Accuracy: 0.512800\n",
      "Epoch 220, CIFAR-10 Batch 5:  Loss:     1.1625 Validation Accuracy: 0.517000\n",
      "Epoch 221, CIFAR-10 Batch 1:  Loss:     1.1411 Validation Accuracy: 0.511400\n",
      "Epoch 221, CIFAR-10 Batch 2:  Loss:     1.1290 Validation Accuracy: 0.518600\n",
      "Epoch 221, CIFAR-10 Batch 3:  Loss:     1.1272 Validation Accuracy: 0.523400\n",
      "Epoch 221, CIFAR-10 Batch 4:  Loss:     1.1272 Validation Accuracy: 0.512800\n",
      "Epoch 221, CIFAR-10 Batch 5:  Loss:     1.1624 Validation Accuracy: 0.521000\n",
      "Epoch 222, CIFAR-10 Batch 1:  Loss:     1.1421 Validation Accuracy: 0.515200\n",
      "Epoch 222, CIFAR-10 Batch 2:  Loss:     1.1345 Validation Accuracy: 0.520400\n",
      "Epoch 222, CIFAR-10 Batch 3:  Loss:     1.1207 Validation Accuracy: 0.523600\n",
      "Epoch 222, CIFAR-10 Batch 4:  Loss:     1.1186 Validation Accuracy: 0.517600\n",
      "Epoch 222, CIFAR-10 Batch 5:  Loss:     1.1553 Validation Accuracy: 0.520600\n",
      "Epoch 223, CIFAR-10 Batch 1:  Loss:     1.1362 Validation Accuracy: 0.515600\n",
      "Epoch 223, CIFAR-10 Batch 2:  Loss:     1.1321 Validation Accuracy: 0.517600\n",
      "Epoch 223, CIFAR-10 Batch 3:  Loss:     1.1229 Validation Accuracy: 0.521000\n",
      "Epoch 223, CIFAR-10 Batch 4:  Loss:     1.1133 Validation Accuracy: 0.521600\n",
      "Epoch 223, CIFAR-10 Batch 5:  Loss:     1.1541 Validation Accuracy: 0.521800\n",
      "Epoch 224, CIFAR-10 Batch 1:  Loss:     1.1325 Validation Accuracy: 0.515400\n",
      "Epoch 224, CIFAR-10 Batch 2:  Loss:     1.1271 Validation Accuracy: 0.521800\n",
      "Epoch 224, CIFAR-10 Batch 3:  Loss:     1.1332 Validation Accuracy: 0.520600\n",
      "Epoch 224, CIFAR-10 Batch 4:  Loss:     1.1164 Validation Accuracy: 0.516200\n",
      "Epoch 224, CIFAR-10 Batch 5:  Loss:     1.1574 Validation Accuracy: 0.520600\n",
      "Epoch 225, CIFAR-10 Batch 1:  Loss:     1.1318 Validation Accuracy: 0.515800\n",
      "Epoch 225, CIFAR-10 Batch 2:  Loss:     1.1323 Validation Accuracy: 0.519800\n",
      "Epoch 225, CIFAR-10 Batch 3:  Loss:     1.1154 Validation Accuracy: 0.522600\n",
      "Epoch 225, CIFAR-10 Batch 4:  Loss:     1.1083 Validation Accuracy: 0.521200\n",
      "Epoch 225, CIFAR-10 Batch 5:  Loss:     1.1459 Validation Accuracy: 0.525000\n",
      "Epoch 226, CIFAR-10 Batch 1:  Loss:     1.1266 Validation Accuracy: 0.518200\n",
      "Epoch 226, CIFAR-10 Batch 2:  Loss:     1.1277 Validation Accuracy: 0.517800\n",
      "Epoch 226, CIFAR-10 Batch 3:  Loss:     1.1271 Validation Accuracy: 0.522000\n",
      "Epoch 226, CIFAR-10 Batch 4:  Loss:     1.1184 Validation Accuracy: 0.515000\n",
      "Epoch 226, CIFAR-10 Batch 5:  Loss:     1.1530 Validation Accuracy: 0.519600\n",
      "Epoch 227, CIFAR-10 Batch 1:  Loss:     1.1287 Validation Accuracy: 0.517600\n",
      "Epoch 227, CIFAR-10 Batch 2:  Loss:     1.1258 Validation Accuracy: 0.520400\n",
      "Epoch 227, CIFAR-10 Batch 3:  Loss:     1.1211 Validation Accuracy: 0.524600\n",
      "Epoch 227, CIFAR-10 Batch 4:  Loss:     1.1173 Validation Accuracy: 0.516000\n",
      "Epoch 227, CIFAR-10 Batch 5:  Loss:     1.1502 Validation Accuracy: 0.523000\n",
      "Epoch 228, CIFAR-10 Batch 1:  Loss:     1.1249 Validation Accuracy: 0.517600\n",
      "Epoch 228, CIFAR-10 Batch 2:  Loss:     1.1281 Validation Accuracy: 0.519400\n",
      "Epoch 228, CIFAR-10 Batch 3:  Loss:     1.1180 Validation Accuracy: 0.525200\n",
      "Epoch 228, CIFAR-10 Batch 4:  Loss:     1.1141 Validation Accuracy: 0.515800\n",
      "Epoch 228, CIFAR-10 Batch 5:  Loss:     1.1481 Validation Accuracy: 0.526000\n",
      "Epoch 229, CIFAR-10 Batch 1:  Loss:     1.1226 Validation Accuracy: 0.518600\n",
      "Epoch 229, CIFAR-10 Batch 2:  Loss:     1.1251 Validation Accuracy: 0.518600\n",
      "Epoch 229, CIFAR-10 Batch 3:  Loss:     1.1138 Validation Accuracy: 0.523800\n",
      "Epoch 229, CIFAR-10 Batch 4:  Loss:     1.1073 Validation Accuracy: 0.518800\n",
      "Epoch 229, CIFAR-10 Batch 5:  Loss:     1.1467 Validation Accuracy: 0.525600\n",
      "Epoch 230, CIFAR-10 Batch 1:  Loss:     1.1242 Validation Accuracy: 0.517200\n",
      "Epoch 230, CIFAR-10 Batch 2:  Loss:     1.1232 Validation Accuracy: 0.523400\n",
      "Epoch 230, CIFAR-10 Batch 3:  Loss:     1.1184 Validation Accuracy: 0.523800\n",
      "Epoch 230, CIFAR-10 Batch 4:  Loss:     1.1102 Validation Accuracy: 0.518200\n",
      "Epoch 230, CIFAR-10 Batch 5:  Loss:     1.1457 Validation Accuracy: 0.524600\n",
      "Epoch 231, CIFAR-10 Batch 1:  Loss:     1.1288 Validation Accuracy: 0.517200\n",
      "Epoch 231, CIFAR-10 Batch 2:  Loss:     1.1265 Validation Accuracy: 0.517600\n",
      "Epoch 231, CIFAR-10 Batch 3:  Loss:     1.1107 Validation Accuracy: 0.525000\n",
      "Epoch 231, CIFAR-10 Batch 4:  Loss:     1.1062 Validation Accuracy: 0.519200\n",
      "Epoch 231, CIFAR-10 Batch 5:  Loss:     1.1441 Validation Accuracy: 0.525200\n",
      "Epoch 232, CIFAR-10 Batch 1:  Loss:     1.1261 Validation Accuracy: 0.514400\n",
      "Epoch 232, CIFAR-10 Batch 2:  Loss:     1.1326 Validation Accuracy: 0.515200\n",
      "Epoch 232, CIFAR-10 Batch 3:  Loss:     1.1134 Validation Accuracy: 0.525000\n",
      "Epoch 232, CIFAR-10 Batch 4:  Loss:     1.1075 Validation Accuracy: 0.519800\n",
      "Epoch 232, CIFAR-10 Batch 5:  Loss:     1.1443 Validation Accuracy: 0.524800\n",
      "Epoch 233, CIFAR-10 Batch 1:  Loss:     1.1206 Validation Accuracy: 0.518000\n",
      "Epoch 233, CIFAR-10 Batch 2:  Loss:     1.1308 Validation Accuracy: 0.514800\n",
      "Epoch 233, CIFAR-10 Batch 3:  Loss:     1.1191 Validation Accuracy: 0.525400\n",
      "Epoch 233, CIFAR-10 Batch 4:  Loss:     1.1114 Validation Accuracy: 0.518600\n",
      "Epoch 233, CIFAR-10 Batch 5:  Loss:     1.1395 Validation Accuracy: 0.526600\n",
      "Epoch 234, CIFAR-10 Batch 1:  Loss:     1.1227 Validation Accuracy: 0.518400\n",
      "Epoch 234, CIFAR-10 Batch 2:  Loss:     1.1328 Validation Accuracy: 0.518800\n",
      "Epoch 234, CIFAR-10 Batch 3:  Loss:     1.1098 Validation Accuracy: 0.526000\n",
      "Epoch 234, CIFAR-10 Batch 4:  Loss:     1.1108 Validation Accuracy: 0.515800\n",
      "Epoch 234, CIFAR-10 Batch 5:  Loss:     1.1327 Validation Accuracy: 0.528800\n",
      "Epoch 235, CIFAR-10 Batch 1:  Loss:     1.1457 Validation Accuracy: 0.511400\n",
      "Epoch 235, CIFAR-10 Batch 2:  Loss:     1.1227 Validation Accuracy: 0.522000\n",
      "Epoch 235, CIFAR-10 Batch 3:  Loss:     1.1317 Validation Accuracy: 0.516400\n",
      "Epoch 235, CIFAR-10 Batch 4:  Loss:     1.0979 Validation Accuracy: 0.520800\n",
      "Epoch 235, CIFAR-10 Batch 5:  Loss:     1.1466 Validation Accuracy: 0.519800\n",
      "Epoch 236, CIFAR-10 Batch 1:  Loss:     1.1198 Validation Accuracy: 0.522200\n",
      "Epoch 236, CIFAR-10 Batch 2:  Loss:     1.1160 Validation Accuracy: 0.525200\n",
      "Epoch 236, CIFAR-10 Batch 3:  Loss:     1.1108 Validation Accuracy: 0.526400\n",
      "Epoch 236, CIFAR-10 Batch 4:  Loss:     1.1022 Validation Accuracy: 0.522600\n",
      "Epoch 236, CIFAR-10 Batch 5:  Loss:     1.1332 Validation Accuracy: 0.526200\n",
      "Epoch 237, CIFAR-10 Batch 1:  Loss:     1.1124 Validation Accuracy: 0.521000\n",
      "Epoch 237, CIFAR-10 Batch 2:  Loss:     1.1109 Validation Accuracy: 0.529200\n",
      "Epoch 237, CIFAR-10 Batch 3:  Loss:     1.1109 Validation Accuracy: 0.525200\n",
      "Epoch 237, CIFAR-10 Batch 4:  Loss:     1.0971 Validation Accuracy: 0.523600\n",
      "Epoch 237, CIFAR-10 Batch 5:  Loss:     1.1360 Validation Accuracy: 0.527000\n",
      "Epoch 238, CIFAR-10 Batch 1:  Loss:     1.1141 Validation Accuracy: 0.521200\n",
      "Epoch 238, CIFAR-10 Batch 2:  Loss:     1.1109 Validation Accuracy: 0.524400\n",
      "Epoch 238, CIFAR-10 Batch 3:  Loss:     1.1111 Validation Accuracy: 0.524200\n",
      "Epoch 238, CIFAR-10 Batch 4:  Loss:     1.0973 Validation Accuracy: 0.522000\n",
      "Epoch 238, CIFAR-10 Batch 5:  Loss:     1.1354 Validation Accuracy: 0.526400\n",
      "Epoch 239, CIFAR-10 Batch 1:  Loss:     1.1147 Validation Accuracy: 0.522200\n",
      "Epoch 239, CIFAR-10 Batch 2:  Loss:     1.1099 Validation Accuracy: 0.524000\n",
      "Epoch 239, CIFAR-10 Batch 3:  Loss:     1.1078 Validation Accuracy: 0.526800\n",
      "Epoch 239, CIFAR-10 Batch 4:  Loss:     1.0962 Validation Accuracy: 0.522800\n",
      "Epoch 239, CIFAR-10 Batch 5:  Loss:     1.1282 Validation Accuracy: 0.529600\n",
      "Epoch 240, CIFAR-10 Batch 1:  Loss:     1.1228 Validation Accuracy: 0.519000\n",
      "Epoch 240, CIFAR-10 Batch 2:  Loss:     1.1143 Validation Accuracy: 0.523400\n",
      "Epoch 240, CIFAR-10 Batch 3:  Loss:     1.1075 Validation Accuracy: 0.528200\n",
      "Epoch 240, CIFAR-10 Batch 4:  Loss:     1.0981 Validation Accuracy: 0.521200\n",
      "Epoch 240, CIFAR-10 Batch 5:  Loss:     1.1280 Validation Accuracy: 0.527800\n",
      "Epoch 241, CIFAR-10 Batch 1:  Loss:     1.1215 Validation Accuracy: 0.520600\n",
      "Epoch 241, CIFAR-10 Batch 2:  Loss:     1.1118 Validation Accuracy: 0.522200\n",
      "Epoch 241, CIFAR-10 Batch 3:  Loss:     1.1099 Validation Accuracy: 0.527600\n",
      "Epoch 241, CIFAR-10 Batch 4:  Loss:     1.0884 Validation Accuracy: 0.525400\n",
      "Epoch 241, CIFAR-10 Batch 5:  Loss:     1.1282 Validation Accuracy: 0.526200\n",
      "Epoch 242, CIFAR-10 Batch 1:  Loss:     1.1129 Validation Accuracy: 0.519600\n",
      "Epoch 242, CIFAR-10 Batch 2:  Loss:     1.1079 Validation Accuracy: 0.529600\n",
      "Epoch 242, CIFAR-10 Batch 3:  Loss:     1.1108 Validation Accuracy: 0.527400\n",
      "Epoch 242, CIFAR-10 Batch 4:  Loss:     1.0872 Validation Accuracy: 0.527400\n",
      "Epoch 242, CIFAR-10 Batch 5:  Loss:     1.1234 Validation Accuracy: 0.528000\n",
      "Epoch 243, CIFAR-10 Batch 1:  Loss:     1.1086 Validation Accuracy: 0.526000\n",
      "Epoch 243, CIFAR-10 Batch 2:  Loss:     1.1032 Validation Accuracy: 0.526000\n",
      "Epoch 243, CIFAR-10 Batch 3:  Loss:     1.1010 Validation Accuracy: 0.528800\n",
      "Epoch 243, CIFAR-10 Batch 4:  Loss:     1.0876 Validation Accuracy: 0.526000\n",
      "Epoch 243, CIFAR-10 Batch 5:  Loss:     1.1264 Validation Accuracy: 0.526200\n",
      "Epoch 244, CIFAR-10 Batch 1:  Loss:     1.1067 Validation Accuracy: 0.524800\n",
      "Epoch 244, CIFAR-10 Batch 2:  Loss:     1.1040 Validation Accuracy: 0.529800\n",
      "Epoch 244, CIFAR-10 Batch 3:  Loss:     1.1023 Validation Accuracy: 0.531800\n",
      "Epoch 244, CIFAR-10 Batch 4:  Loss:     1.0918 Validation Accuracy: 0.523800\n",
      "Epoch 244, CIFAR-10 Batch 5:  Loss:     1.1289 Validation Accuracy: 0.524000\n",
      "Epoch 245, CIFAR-10 Batch 1:  Loss:     1.1007 Validation Accuracy: 0.524400\n",
      "Epoch 245, CIFAR-10 Batch 2:  Loss:     1.1030 Validation Accuracy: 0.529200\n",
      "Epoch 245, CIFAR-10 Batch 3:  Loss:     1.0990 Validation Accuracy: 0.526600\n",
      "Epoch 245, CIFAR-10 Batch 4:  Loss:     1.0897 Validation Accuracy: 0.522400\n",
      "Epoch 245, CIFAR-10 Batch 5:  Loss:     1.1232 Validation Accuracy: 0.531800\n",
      "Epoch 246, CIFAR-10 Batch 1:  Loss:     1.1037 Validation Accuracy: 0.524600\n",
      "Epoch 246, CIFAR-10 Batch 2:  Loss:     1.1062 Validation Accuracy: 0.527000\n",
      "Epoch 246, CIFAR-10 Batch 3:  Loss:     1.1033 Validation Accuracy: 0.528400\n",
      "Epoch 246, CIFAR-10 Batch 4:  Loss:     1.0874 Validation Accuracy: 0.522800\n",
      "Epoch 246, CIFAR-10 Batch 5:  Loss:     1.1288 Validation Accuracy: 0.524800\n",
      "Epoch 247, CIFAR-10 Batch 1:  Loss:     1.1018 Validation Accuracy: 0.523600\n",
      "Epoch 247, CIFAR-10 Batch 2:  Loss:     1.1075 Validation Accuracy: 0.526400\n",
      "Epoch 247, CIFAR-10 Batch 3:  Loss:     1.1031 Validation Accuracy: 0.528800\n",
      "Epoch 247, CIFAR-10 Batch 4:  Loss:     1.0984 Validation Accuracy: 0.525200\n",
      "Epoch 247, CIFAR-10 Batch 5:  Loss:     1.1267 Validation Accuracy: 0.530400\n",
      "Epoch 248, CIFAR-10 Batch 1:  Loss:     1.1177 Validation Accuracy: 0.520800\n",
      "Epoch 248, CIFAR-10 Batch 2:  Loss:     1.1130 Validation Accuracy: 0.526000\n",
      "Epoch 248, CIFAR-10 Batch 3:  Loss:     1.1004 Validation Accuracy: 0.529400\n",
      "Epoch 248, CIFAR-10 Batch 4:  Loss:     1.0860 Validation Accuracy: 0.526000\n",
      "Epoch 248, CIFAR-10 Batch 5:  Loss:     1.1208 Validation Accuracy: 0.533600\n",
      "Epoch 249, CIFAR-10 Batch 1:  Loss:     1.1268 Validation Accuracy: 0.520000\n",
      "Epoch 249, CIFAR-10 Batch 2:  Loss:     1.1077 Validation Accuracy: 0.530600\n",
      "Epoch 249, CIFAR-10 Batch 3:  Loss:     1.1068 Validation Accuracy: 0.527800\n",
      "Epoch 249, CIFAR-10 Batch 4:  Loss:     1.0733 Validation Accuracy: 0.529400\n",
      "Epoch 249, CIFAR-10 Batch 5:  Loss:     1.1172 Validation Accuracy: 0.527000\n",
      "Epoch 250, CIFAR-10 Batch 1:  Loss:     1.1105 Validation Accuracy: 0.523600\n",
      "Epoch 250, CIFAR-10 Batch 2:  Loss:     1.1066 Validation Accuracy: 0.527000\n",
      "Epoch 250, CIFAR-10 Batch 3:  Loss:     1.1046 Validation Accuracy: 0.527400\n",
      "Epoch 250, CIFAR-10 Batch 4:  Loss:     1.0793 Validation Accuracy: 0.527800\n",
      "Epoch 250, CIFAR-10 Batch 5:  Loss:     1.1274 Validation Accuracy: 0.524000\n",
      "Epoch 251, CIFAR-10 Batch 1:  Loss:     1.1057 Validation Accuracy: 0.522200\n",
      "Epoch 251, CIFAR-10 Batch 2:  Loss:     1.1007 Validation Accuracy: 0.531400\n",
      "Epoch 251, CIFAR-10 Batch 3:  Loss:     1.1008 Validation Accuracy: 0.528400\n",
      "Epoch 251, CIFAR-10 Batch 4:  Loss:     1.0800 Validation Accuracy: 0.527800\n",
      "Epoch 251, CIFAR-10 Batch 5:  Loss:     1.1143 Validation Accuracy: 0.528400\n",
      "Epoch 252, CIFAR-10 Batch 1:  Loss:     1.1017 Validation Accuracy: 0.525600\n",
      "Epoch 252, CIFAR-10 Batch 2:  Loss:     1.0975 Validation Accuracy: 0.532800\n",
      "Epoch 252, CIFAR-10 Batch 3:  Loss:     1.0927 Validation Accuracy: 0.529000\n",
      "Epoch 252, CIFAR-10 Batch 4:  Loss:     1.0733 Validation Accuracy: 0.527800\n",
      "Epoch 252, CIFAR-10 Batch 5:  Loss:     1.1086 Validation Accuracy: 0.532800\n",
      "Epoch 253, CIFAR-10 Batch 1:  Loss:     1.0909 Validation Accuracy: 0.524200\n",
      "Epoch 253, CIFAR-10 Batch 2:  Loss:     1.0968 Validation Accuracy: 0.532400\n",
      "Epoch 253, CIFAR-10 Batch 3:  Loss:     1.0965 Validation Accuracy: 0.526800\n",
      "Epoch 253, CIFAR-10 Batch 4:  Loss:     1.0750 Validation Accuracy: 0.528200\n",
      "Epoch 253, CIFAR-10 Batch 5:  Loss:     1.1125 Validation Accuracy: 0.529200\n",
      "Epoch 254, CIFAR-10 Batch 1:  Loss:     1.0910 Validation Accuracy: 0.526000\n",
      "Epoch 254, CIFAR-10 Batch 2:  Loss:     1.0965 Validation Accuracy: 0.530800\n",
      "Epoch 254, CIFAR-10 Batch 3:  Loss:     1.0909 Validation Accuracy: 0.533400\n",
      "Epoch 254, CIFAR-10 Batch 4:  Loss:     1.0761 Validation Accuracy: 0.524200\n",
      "Epoch 254, CIFAR-10 Batch 5:  Loss:     1.1076 Validation Accuracy: 0.533000\n",
      "Epoch 255, CIFAR-10 Batch 1:  Loss:     1.0960 Validation Accuracy: 0.524400\n",
      "Epoch 255, CIFAR-10 Batch 2:  Loss:     1.0928 Validation Accuracy: 0.532000\n",
      "Epoch 255, CIFAR-10 Batch 3:  Loss:     1.0936 Validation Accuracy: 0.532600\n",
      "Epoch 255, CIFAR-10 Batch 4:  Loss:     1.0787 Validation Accuracy: 0.528600\n",
      "Epoch 255, CIFAR-10 Batch 5:  Loss:     1.1083 Validation Accuracy: 0.534600\n",
      "Epoch 256, CIFAR-10 Batch 1:  Loss:     1.0959 Validation Accuracy: 0.524600\n",
      "Epoch 256, CIFAR-10 Batch 2:  Loss:     1.0971 Validation Accuracy: 0.532600\n",
      "Epoch 256, CIFAR-10 Batch 3:  Loss:     1.0943 Validation Accuracy: 0.533200\n",
      "Epoch 256, CIFAR-10 Batch 4:  Loss:     1.0752 Validation Accuracy: 0.527600\n",
      "Epoch 256, CIFAR-10 Batch 5:  Loss:     1.1090 Validation Accuracy: 0.534400\n",
      "Epoch 257, CIFAR-10 Batch 1:  Loss:     1.1004 Validation Accuracy: 0.526200\n",
      "Epoch 257, CIFAR-10 Batch 2:  Loss:     1.0951 Validation Accuracy: 0.530400\n",
      "Epoch 257, CIFAR-10 Batch 3:  Loss:     1.0910 Validation Accuracy: 0.532600\n",
      "Epoch 257, CIFAR-10 Batch 4:  Loss:     1.0753 Validation Accuracy: 0.529400\n",
      "Epoch 257, CIFAR-10 Batch 5:  Loss:     1.1083 Validation Accuracy: 0.533200\n",
      "Epoch 258, CIFAR-10 Batch 1:  Loss:     1.1021 Validation Accuracy: 0.526400\n",
      "Epoch 258, CIFAR-10 Batch 2:  Loss:     1.0941 Validation Accuracy: 0.534000\n",
      "Epoch 258, CIFAR-10 Batch 3:  Loss:     1.0916 Validation Accuracy: 0.533600\n",
      "Epoch 258, CIFAR-10 Batch 4:  Loss:     1.0640 Validation Accuracy: 0.531400\n",
      "Epoch 258, CIFAR-10 Batch 5:  Loss:     1.1016 Validation Accuracy: 0.534000\n",
      "Epoch 259, CIFAR-10 Batch 1:  Loss:     1.0995 Validation Accuracy: 0.527000\n",
      "Epoch 259, CIFAR-10 Batch 2:  Loss:     1.0929 Validation Accuracy: 0.534400\n",
      "Epoch 259, CIFAR-10 Batch 3:  Loss:     1.0839 Validation Accuracy: 0.535800\n",
      "Epoch 259, CIFAR-10 Batch 4:  Loss:     1.0667 Validation Accuracy: 0.529600\n",
      "Epoch 259, CIFAR-10 Batch 5:  Loss:     1.0970 Validation Accuracy: 0.536000\n",
      "Epoch 260, CIFAR-10 Batch 1:  Loss:     1.0973 Validation Accuracy: 0.529600\n",
      "Epoch 260, CIFAR-10 Batch 2:  Loss:     1.0939 Validation Accuracy: 0.533800\n",
      "Epoch 260, CIFAR-10 Batch 3:  Loss:     1.0932 Validation Accuracy: 0.531000\n",
      "Epoch 260, CIFAR-10 Batch 4:  Loss:     1.0646 Validation Accuracy: 0.532800\n",
      "Epoch 260, CIFAR-10 Batch 5:  Loss:     1.1039 Validation Accuracy: 0.535800\n",
      "Epoch 261, CIFAR-10 Batch 1:  Loss:     1.1073 Validation Accuracy: 0.522600\n",
      "Epoch 261, CIFAR-10 Batch 2:  Loss:     1.0902 Validation Accuracy: 0.538800\n",
      "Epoch 261, CIFAR-10 Batch 3:  Loss:     1.0989 Validation Accuracy: 0.527200\n",
      "Epoch 261, CIFAR-10 Batch 4:  Loss:     1.0635 Validation Accuracy: 0.529800\n",
      "Epoch 261, CIFAR-10 Batch 5:  Loss:     1.1056 Validation Accuracy: 0.528200\n",
      "Epoch 262, CIFAR-10 Batch 1:  Loss:     1.0842 Validation Accuracy: 0.527600\n",
      "Epoch 262, CIFAR-10 Batch 2:  Loss:     1.0894 Validation Accuracy: 0.534000\n",
      "Epoch 262, CIFAR-10 Batch 3:  Loss:     1.0844 Validation Accuracy: 0.534600\n",
      "Epoch 262, CIFAR-10 Batch 4:  Loss:     1.0654 Validation Accuracy: 0.532600\n",
      "Epoch 262, CIFAR-10 Batch 5:  Loss:     1.0993 Validation Accuracy: 0.532200\n",
      "Epoch 263, CIFAR-10 Batch 1:  Loss:     1.0872 Validation Accuracy: 0.526000\n",
      "Epoch 263, CIFAR-10 Batch 2:  Loss:     1.0885 Validation Accuracy: 0.536600\n",
      "Epoch 263, CIFAR-10 Batch 3:  Loss:     1.0781 Validation Accuracy: 0.533000\n",
      "Epoch 263, CIFAR-10 Batch 4:  Loss:     1.0629 Validation Accuracy: 0.532200\n",
      "Epoch 263, CIFAR-10 Batch 5:  Loss:     1.0969 Validation Accuracy: 0.533200\n",
      "Epoch 264, CIFAR-10 Batch 1:  Loss:     1.0824 Validation Accuracy: 0.525600\n",
      "Epoch 264, CIFAR-10 Batch 2:  Loss:     1.0906 Validation Accuracy: 0.535400\n",
      "Epoch 264, CIFAR-10 Batch 3:  Loss:     1.0799 Validation Accuracy: 0.535400\n",
      "Epoch 264, CIFAR-10 Batch 4:  Loss:     1.0647 Validation Accuracy: 0.530400\n",
      "Epoch 264, CIFAR-10 Batch 5:  Loss:     1.0940 Validation Accuracy: 0.533200\n",
      "Epoch 265, CIFAR-10 Batch 1:  Loss:     1.0833 Validation Accuracy: 0.528000\n",
      "Epoch 265, CIFAR-10 Batch 2:  Loss:     1.0856 Validation Accuracy: 0.532600\n",
      "Epoch 265, CIFAR-10 Batch 3:  Loss:     1.0788 Validation Accuracy: 0.537400\n",
      "Epoch 265, CIFAR-10 Batch 4:  Loss:     1.0613 Validation Accuracy: 0.529600\n",
      "Epoch 265, CIFAR-10 Batch 5:  Loss:     1.0971 Validation Accuracy: 0.533200\n",
      "Epoch 266, CIFAR-10 Batch 1:  Loss:     1.0834 Validation Accuracy: 0.529400\n",
      "Epoch 266, CIFAR-10 Batch 2:  Loss:     1.0854 Validation Accuracy: 0.533600\n",
      "Epoch 266, CIFAR-10 Batch 3:  Loss:     1.0806 Validation Accuracy: 0.534000\n",
      "Epoch 266, CIFAR-10 Batch 4:  Loss:     1.0635 Validation Accuracy: 0.531800\n",
      "Epoch 266, CIFAR-10 Batch 5:  Loss:     1.0955 Validation Accuracy: 0.535200\n",
      "Epoch 267, CIFAR-10 Batch 1:  Loss:     1.0821 Validation Accuracy: 0.528400\n",
      "Epoch 267, CIFAR-10 Batch 2:  Loss:     1.0836 Validation Accuracy: 0.537600\n",
      "Epoch 267, CIFAR-10 Batch 3:  Loss:     1.0760 Validation Accuracy: 0.536600\n",
      "Epoch 267, CIFAR-10 Batch 4:  Loss:     1.0563 Validation Accuracy: 0.532200\n",
      "Epoch 267, CIFAR-10 Batch 5:  Loss:     1.0978 Validation Accuracy: 0.532200\n",
      "Epoch 268, CIFAR-10 Batch 1:  Loss:     1.0733 Validation Accuracy: 0.529600\n",
      "Epoch 268, CIFAR-10 Batch 2:  Loss:     1.0814 Validation Accuracy: 0.537400\n",
      "Epoch 268, CIFAR-10 Batch 3:  Loss:     1.0801 Validation Accuracy: 0.532800\n",
      "Epoch 268, CIFAR-10 Batch 4:  Loss:     1.0590 Validation Accuracy: 0.531800\n",
      "Epoch 268, CIFAR-10 Batch 5:  Loss:     1.0924 Validation Accuracy: 0.531800\n",
      "Epoch 269, CIFAR-10 Batch 1:  Loss:     1.0706 Validation Accuracy: 0.531400\n",
      "Epoch 269, CIFAR-10 Batch 2:  Loss:     1.0830 Validation Accuracy: 0.538000\n",
      "Epoch 269, CIFAR-10 Batch 3:  Loss:     1.0735 Validation Accuracy: 0.538200\n",
      "Epoch 269, CIFAR-10 Batch 4:  Loss:     1.0555 Validation Accuracy: 0.532800\n",
      "Epoch 269, CIFAR-10 Batch 5:  Loss:     1.0918 Validation Accuracy: 0.532400\n",
      "Epoch 270, CIFAR-10 Batch 1:  Loss:     1.0782 Validation Accuracy: 0.527800\n",
      "Epoch 270, CIFAR-10 Batch 2:  Loss:     1.0867 Validation Accuracy: 0.535600\n",
      "Epoch 270, CIFAR-10 Batch 3:  Loss:     1.0728 Validation Accuracy: 0.535600\n",
      "Epoch 270, CIFAR-10 Batch 4:  Loss:     1.0568 Validation Accuracy: 0.532200\n",
      "Epoch 270, CIFAR-10 Batch 5:  Loss:     1.0825 Validation Accuracy: 0.538800\n",
      "Epoch 271, CIFAR-10 Batch 1:  Loss:     1.0812 Validation Accuracy: 0.533600\n",
      "Epoch 271, CIFAR-10 Batch 2:  Loss:     1.0831 Validation Accuracy: 0.539000\n",
      "Epoch 271, CIFAR-10 Batch 3:  Loss:     1.0735 Validation Accuracy: 0.537000\n",
      "Epoch 271, CIFAR-10 Batch 4:  Loss:     1.0557 Validation Accuracy: 0.530000\n",
      "Epoch 271, CIFAR-10 Batch 5:  Loss:     1.0844 Validation Accuracy: 0.538000\n",
      "Epoch 272, CIFAR-10 Batch 1:  Loss:     1.0741 Validation Accuracy: 0.535200\n",
      "Epoch 272, CIFAR-10 Batch 2:  Loss:     1.0872 Validation Accuracy: 0.534400\n",
      "Epoch 272, CIFAR-10 Batch 3:  Loss:     1.0722 Validation Accuracy: 0.536400\n",
      "Epoch 272, CIFAR-10 Batch 4:  Loss:     1.0586 Validation Accuracy: 0.531000\n",
      "Epoch 272, CIFAR-10 Batch 5:  Loss:     1.0841 Validation Accuracy: 0.538800\n",
      "Epoch 273, CIFAR-10 Batch 1:  Loss:     1.0790 Validation Accuracy: 0.532000\n",
      "Epoch 273, CIFAR-10 Batch 2:  Loss:     1.0887 Validation Accuracy: 0.537800\n",
      "Epoch 273, CIFAR-10 Batch 3:  Loss:     1.0726 Validation Accuracy: 0.540000\n",
      "Epoch 273, CIFAR-10 Batch 4:  Loss:     1.0552 Validation Accuracy: 0.533200\n",
      "Epoch 273, CIFAR-10 Batch 5:  Loss:     1.0894 Validation Accuracy: 0.533400\n",
      "Epoch 274, CIFAR-10 Batch 1:  Loss:     1.0821 Validation Accuracy: 0.531200\n",
      "Epoch 274, CIFAR-10 Batch 2:  Loss:     1.0818 Validation Accuracy: 0.540800\n",
      "Epoch 274, CIFAR-10 Batch 3:  Loss:     1.0700 Validation Accuracy: 0.537800\n",
      "Epoch 274, CIFAR-10 Batch 4:  Loss:     1.0507 Validation Accuracy: 0.533400\n",
      "Epoch 274, CIFAR-10 Batch 5:  Loss:     1.0806 Validation Accuracy: 0.538800\n",
      "Epoch 275, CIFAR-10 Batch 1:  Loss:     1.0833 Validation Accuracy: 0.526800\n",
      "Epoch 275, CIFAR-10 Batch 2:  Loss:     1.0830 Validation Accuracy: 0.541200\n",
      "Epoch 275, CIFAR-10 Batch 3:  Loss:     1.0682 Validation Accuracy: 0.538600\n",
      "Epoch 275, CIFAR-10 Batch 4:  Loss:     1.0514 Validation Accuracy: 0.533600\n",
      "Epoch 275, CIFAR-10 Batch 5:  Loss:     1.0856 Validation Accuracy: 0.537800\n",
      "Epoch 276, CIFAR-10 Batch 1:  Loss:     1.0773 Validation Accuracy: 0.529000\n",
      "Epoch 276, CIFAR-10 Batch 2:  Loss:     1.0812 Validation Accuracy: 0.544400\n",
      "Epoch 276, CIFAR-10 Batch 3:  Loss:     1.0765 Validation Accuracy: 0.533600\n",
      "Epoch 276, CIFAR-10 Batch 4:  Loss:     1.0463 Validation Accuracy: 0.538600\n",
      "Epoch 276, CIFAR-10 Batch 5:  Loss:     1.0821 Validation Accuracy: 0.530000\n",
      "Epoch 277, CIFAR-10 Batch 1:  Loss:     1.0796 Validation Accuracy: 0.533000\n",
      "Epoch 277, CIFAR-10 Batch 2:  Loss:     1.0770 Validation Accuracy: 0.543400\n",
      "Epoch 277, CIFAR-10 Batch 3:  Loss:     1.0713 Validation Accuracy: 0.538600\n",
      "Epoch 277, CIFAR-10 Batch 4:  Loss:     1.0419 Validation Accuracy: 0.538600\n",
      "Epoch 277, CIFAR-10 Batch 5:  Loss:     1.0866 Validation Accuracy: 0.531600\n",
      "Epoch 278, CIFAR-10 Batch 1:  Loss:     1.0767 Validation Accuracy: 0.534600\n",
      "Epoch 278, CIFAR-10 Batch 2:  Loss:     1.0765 Validation Accuracy: 0.543400\n",
      "Epoch 278, CIFAR-10 Batch 3:  Loss:     1.0733 Validation Accuracy: 0.535600\n",
      "Epoch 278, CIFAR-10 Batch 4:  Loss:     1.0394 Validation Accuracy: 0.536200\n",
      "Epoch 278, CIFAR-10 Batch 5:  Loss:     1.0751 Validation Accuracy: 0.539200\n",
      "Epoch 279, CIFAR-10 Batch 1:  Loss:     1.0776 Validation Accuracy: 0.532000\n",
      "Epoch 279, CIFAR-10 Batch 2:  Loss:     1.0777 Validation Accuracy: 0.545000\n",
      "Epoch 279, CIFAR-10 Batch 3:  Loss:     1.0712 Validation Accuracy: 0.536000\n",
      "Epoch 279, CIFAR-10 Batch 4:  Loss:     1.0434 Validation Accuracy: 0.537000\n",
      "Epoch 279, CIFAR-10 Batch 5:  Loss:     1.0797 Validation Accuracy: 0.531400\n",
      "Epoch 280, CIFAR-10 Batch 1:  Loss:     1.0655 Validation Accuracy: 0.533600\n",
      "Epoch 280, CIFAR-10 Batch 2:  Loss:     1.0743 Validation Accuracy: 0.542000\n",
      "Epoch 280, CIFAR-10 Batch 3:  Loss:     1.0648 Validation Accuracy: 0.537800\n",
      "Epoch 280, CIFAR-10 Batch 4:  Loss:     1.0431 Validation Accuracy: 0.536000\n",
      "Epoch 280, CIFAR-10 Batch 5:  Loss:     1.0769 Validation Accuracy: 0.533200\n",
      "Epoch 281, CIFAR-10 Batch 1:  Loss:     1.0601 Validation Accuracy: 0.534800\n",
      "Epoch 281, CIFAR-10 Batch 2:  Loss:     1.0711 Validation Accuracy: 0.541000\n",
      "Epoch 281, CIFAR-10 Batch 3:  Loss:     1.0598 Validation Accuracy: 0.538800\n",
      "Epoch 281, CIFAR-10 Batch 4:  Loss:     1.0396 Validation Accuracy: 0.536000\n",
      "Epoch 281, CIFAR-10 Batch 5:  Loss:     1.0684 Validation Accuracy: 0.538000\n",
      "Epoch 282, CIFAR-10 Batch 1:  Loss:     1.0626 Validation Accuracy: 0.537600\n",
      "Epoch 282, CIFAR-10 Batch 2:  Loss:     1.0691 Validation Accuracy: 0.540800\n",
      "Epoch 282, CIFAR-10 Batch 3:  Loss:     1.0579 Validation Accuracy: 0.539200\n",
      "Epoch 282, CIFAR-10 Batch 4:  Loss:     1.0464 Validation Accuracy: 0.534800\n",
      "Epoch 282, CIFAR-10 Batch 5:  Loss:     1.0711 Validation Accuracy: 0.537800\n",
      "Epoch 283, CIFAR-10 Batch 1:  Loss:     1.0538 Validation Accuracy: 0.535600\n",
      "Epoch 283, CIFAR-10 Batch 2:  Loss:     1.0691 Validation Accuracy: 0.543800\n",
      "Epoch 283, CIFAR-10 Batch 3:  Loss:     1.0581 Validation Accuracy: 0.541600\n",
      "Epoch 283, CIFAR-10 Batch 4:  Loss:     1.0471 Validation Accuracy: 0.535000\n",
      "Epoch 283, CIFAR-10 Batch 5:  Loss:     1.0759 Validation Accuracy: 0.532800\n",
      "Epoch 284, CIFAR-10 Batch 1:  Loss:     1.0521 Validation Accuracy: 0.537000\n",
      "Epoch 284, CIFAR-10 Batch 2:  Loss:     1.0709 Validation Accuracy: 0.542000\n",
      "Epoch 284, CIFAR-10 Batch 3:  Loss:     1.0638 Validation Accuracy: 0.540200\n",
      "Epoch 284, CIFAR-10 Batch 4:  Loss:     1.0554 Validation Accuracy: 0.534000\n",
      "Epoch 284, CIFAR-10 Batch 5:  Loss:     1.0717 Validation Accuracy: 0.535200\n",
      "Epoch 285, CIFAR-10 Batch 1:  Loss:     1.0550 Validation Accuracy: 0.536000\n",
      "Epoch 285, CIFAR-10 Batch 2:  Loss:     1.0741 Validation Accuracy: 0.543000\n",
      "Epoch 285, CIFAR-10 Batch 3:  Loss:     1.0655 Validation Accuracy: 0.538600\n",
      "Epoch 285, CIFAR-10 Batch 4:  Loss:     1.0519 Validation Accuracy: 0.535600\n",
      "Epoch 285, CIFAR-10 Batch 5:  Loss:     1.0820 Validation Accuracy: 0.531400\n",
      "Epoch 286, CIFAR-10 Batch 1:  Loss:     1.0594 Validation Accuracy: 0.534800\n",
      "Epoch 286, CIFAR-10 Batch 2:  Loss:     1.0690 Validation Accuracy: 0.542400\n",
      "Epoch 286, CIFAR-10 Batch 3:  Loss:     1.0564 Validation Accuracy: 0.540800\n",
      "Epoch 286, CIFAR-10 Batch 4:  Loss:     1.0507 Validation Accuracy: 0.533200\n",
      "Epoch 286, CIFAR-10 Batch 5:  Loss:     1.0697 Validation Accuracy: 0.542400\n",
      "Epoch 287, CIFAR-10 Batch 1:  Loss:     1.0650 Validation Accuracy: 0.537000\n",
      "Epoch 287, CIFAR-10 Batch 2:  Loss:     1.0676 Validation Accuracy: 0.544000\n",
      "Epoch 287, CIFAR-10 Batch 3:  Loss:     1.0601 Validation Accuracy: 0.542200\n",
      "Epoch 287, CIFAR-10 Batch 4:  Loss:     1.0333 Validation Accuracy: 0.537800\n",
      "Epoch 287, CIFAR-10 Batch 5:  Loss:     1.0654 Validation Accuracy: 0.543600\n",
      "Epoch 288, CIFAR-10 Batch 1:  Loss:     1.0668 Validation Accuracy: 0.532000\n",
      "Epoch 288, CIFAR-10 Batch 2:  Loss:     1.0729 Validation Accuracy: 0.547000\n",
      "Epoch 288, CIFAR-10 Batch 3:  Loss:     1.0594 Validation Accuracy: 0.543200\n",
      "Epoch 288, CIFAR-10 Batch 4:  Loss:     1.0294 Validation Accuracy: 0.540800\n",
      "Epoch 288, CIFAR-10 Batch 5:  Loss:     1.0599 Validation Accuracy: 0.544800\n",
      "Epoch 289, CIFAR-10 Batch 1:  Loss:     1.0560 Validation Accuracy: 0.531800\n",
      "Epoch 289, CIFAR-10 Batch 2:  Loss:     1.0647 Validation Accuracy: 0.546800\n",
      "Epoch 289, CIFAR-10 Batch 3:  Loss:     1.0547 Validation Accuracy: 0.541400\n",
      "Epoch 289, CIFAR-10 Batch 4:  Loss:     1.0271 Validation Accuracy: 0.537400\n",
      "Epoch 289, CIFAR-10 Batch 5:  Loss:     1.0650 Validation Accuracy: 0.538400\n",
      "Epoch 290, CIFAR-10 Batch 1:  Loss:     1.0507 Validation Accuracy: 0.535400\n",
      "Epoch 290, CIFAR-10 Batch 2:  Loss:     1.0639 Validation Accuracy: 0.543800\n",
      "Epoch 290, CIFAR-10 Batch 3:  Loss:     1.0535 Validation Accuracy: 0.541600\n",
      "Epoch 290, CIFAR-10 Batch 4:  Loss:     1.0296 Validation Accuracy: 0.538400\n",
      "Epoch 290, CIFAR-10 Batch 5:  Loss:     1.0646 Validation Accuracy: 0.534600\n",
      "Epoch 291, CIFAR-10 Batch 1:  Loss:     1.0452 Validation Accuracy: 0.537000\n",
      "Epoch 291, CIFAR-10 Batch 2:  Loss:     1.0645 Validation Accuracy: 0.549200\n",
      "Epoch 291, CIFAR-10 Batch 3:  Loss:     1.0507 Validation Accuracy: 0.542400\n",
      "Epoch 291, CIFAR-10 Batch 4:  Loss:     1.0298 Validation Accuracy: 0.540800\n",
      "Epoch 291, CIFAR-10 Batch 5:  Loss:     1.0585 Validation Accuracy: 0.536800\n",
      "Epoch 292, CIFAR-10 Batch 1:  Loss:     1.0492 Validation Accuracy: 0.538000\n",
      "Epoch 292, CIFAR-10 Batch 2:  Loss:     1.0634 Validation Accuracy: 0.547000\n",
      "Epoch 292, CIFAR-10 Batch 3:  Loss:     1.0514 Validation Accuracy: 0.543000\n",
      "Epoch 292, CIFAR-10 Batch 4:  Loss:     1.0364 Validation Accuracy: 0.535200\n",
      "Epoch 292, CIFAR-10 Batch 5:  Loss:     1.0637 Validation Accuracy: 0.530400\n",
      "Epoch 293, CIFAR-10 Batch 1:  Loss:     1.0435 Validation Accuracy: 0.540800\n",
      "Epoch 293, CIFAR-10 Batch 2:  Loss:     1.0650 Validation Accuracy: 0.545400\n",
      "Epoch 293, CIFAR-10 Batch 3:  Loss:     1.0510 Validation Accuracy: 0.543800\n",
      "Epoch 293, CIFAR-10 Batch 4:  Loss:     1.0362 Validation Accuracy: 0.538800\n",
      "Epoch 293, CIFAR-10 Batch 5:  Loss:     1.0663 Validation Accuracy: 0.535400\n",
      "Epoch 294, CIFAR-10 Batch 1:  Loss:     1.0403 Validation Accuracy: 0.541200\n",
      "Epoch 294, CIFAR-10 Batch 2:  Loss:     1.0627 Validation Accuracy: 0.544200\n",
      "Epoch 294, CIFAR-10 Batch 3:  Loss:     1.0494 Validation Accuracy: 0.544600\n",
      "Epoch 294, CIFAR-10 Batch 4:  Loss:     1.0297 Validation Accuracy: 0.541200\n",
      "Epoch 294, CIFAR-10 Batch 5:  Loss:     1.0586 Validation Accuracy: 0.535200\n",
      "Epoch 295, CIFAR-10 Batch 1:  Loss:     1.0405 Validation Accuracy: 0.540000\n",
      "Epoch 295, CIFAR-10 Batch 2:  Loss:     1.0611 Validation Accuracy: 0.545600\n",
      "Epoch 295, CIFAR-10 Batch 3:  Loss:     1.0502 Validation Accuracy: 0.543000\n",
      "Epoch 295, CIFAR-10 Batch 4:  Loss:     1.0301 Validation Accuracy: 0.540600\n",
      "Epoch 295, CIFAR-10 Batch 5:  Loss:     1.0626 Validation Accuracy: 0.531200\n",
      "Epoch 296, CIFAR-10 Batch 1:  Loss:     1.0398 Validation Accuracy: 0.535000\n",
      "Epoch 296, CIFAR-10 Batch 2:  Loss:     1.0635 Validation Accuracy: 0.547600\n",
      "Epoch 296, CIFAR-10 Batch 3:  Loss:     1.0479 Validation Accuracy: 0.543000\n",
      "Epoch 296, CIFAR-10 Batch 4:  Loss:     1.0320 Validation Accuracy: 0.540600\n",
      "Epoch 296, CIFAR-10 Batch 5:  Loss:     1.0635 Validation Accuracy: 0.536000\n",
      "Epoch 297, CIFAR-10 Batch 1:  Loss:     1.0451 Validation Accuracy: 0.540600\n",
      "Epoch 297, CIFAR-10 Batch 2:  Loss:     1.0581 Validation Accuracy: 0.547000\n",
      "Epoch 297, CIFAR-10 Batch 3:  Loss:     1.0480 Validation Accuracy: 0.542400\n",
      "Epoch 297, CIFAR-10 Batch 4:  Loss:     1.0293 Validation Accuracy: 0.540600\n",
      "Epoch 297, CIFAR-10 Batch 5:  Loss:     1.0580 Validation Accuracy: 0.535800\n",
      "Epoch 298, CIFAR-10 Batch 1:  Loss:     1.0431 Validation Accuracy: 0.536800\n",
      "Epoch 298, CIFAR-10 Batch 2:  Loss:     1.0590 Validation Accuracy: 0.547400\n",
      "Epoch 298, CIFAR-10 Batch 3:  Loss:     1.0425 Validation Accuracy: 0.545000\n",
      "Epoch 298, CIFAR-10 Batch 4:  Loss:     1.0244 Validation Accuracy: 0.541200\n",
      "Epoch 298, CIFAR-10 Batch 5:  Loss:     1.0530 Validation Accuracy: 0.541400\n",
      "Epoch 299, CIFAR-10 Batch 1:  Loss:     1.0423 Validation Accuracy: 0.538600\n",
      "Epoch 299, CIFAR-10 Batch 2:  Loss:     1.0575 Validation Accuracy: 0.548000\n",
      "Epoch 299, CIFAR-10 Batch 3:  Loss:     1.0415 Validation Accuracy: 0.550000\n",
      "Epoch 299, CIFAR-10 Batch 4:  Loss:     1.0319 Validation Accuracy: 0.538000\n",
      "Epoch 299, CIFAR-10 Batch 5:  Loss:     1.0493 Validation Accuracy: 0.540800\n",
      "Epoch 300, CIFAR-10 Batch 1:  Loss:     1.0391 Validation Accuracy: 0.539800\n",
      "Epoch 300, CIFAR-10 Batch 2:  Loss:     1.0557 Validation Accuracy: 0.548600\n",
      "Epoch 300, CIFAR-10 Batch 3:  Loss:     1.0413 Validation Accuracy: 0.545000\n",
      "Epoch 300, CIFAR-10 Batch 4:  Loss:     1.0215 Validation Accuracy: 0.542600\n",
      "Epoch 300, CIFAR-10 Batch 5:  Loss:     1.0474 Validation Accuracy: 0.540800\n",
      "Epoch 301, CIFAR-10 Batch 1:  Loss:     1.0411 Validation Accuracy: 0.537600\n",
      "Epoch 301, CIFAR-10 Batch 2:  Loss:     1.0554 Validation Accuracy: 0.547000\n",
      "Epoch 301, CIFAR-10 Batch 3:  Loss:     1.0399 Validation Accuracy: 0.545600\n",
      "Epoch 301, CIFAR-10 Batch 4:  Loss:     1.0270 Validation Accuracy: 0.542000\n",
      "Epoch 301, CIFAR-10 Batch 5:  Loss:     1.0509 Validation Accuracy: 0.536200\n",
      "Epoch 302, CIFAR-10 Batch 1:  Loss:     1.0317 Validation Accuracy: 0.543000\n",
      "Epoch 302, CIFAR-10 Batch 2:  Loss:     1.0523 Validation Accuracy: 0.549400\n",
      "Epoch 302, CIFAR-10 Batch 3:  Loss:     1.0403 Validation Accuracy: 0.545200\n",
      "Epoch 302, CIFAR-10 Batch 4:  Loss:     1.0310 Validation Accuracy: 0.541000\n",
      "Epoch 302, CIFAR-10 Batch 5:  Loss:     1.0536 Validation Accuracy: 0.535200\n",
      "Epoch 303, CIFAR-10 Batch 1:  Loss:     1.0296 Validation Accuracy: 0.541200\n",
      "Epoch 303, CIFAR-10 Batch 2:  Loss:     1.0588 Validation Accuracy: 0.545600\n",
      "Epoch 303, CIFAR-10 Batch 3:  Loss:     1.0463 Validation Accuracy: 0.542800\n",
      "Epoch 303, CIFAR-10 Batch 4:  Loss:     1.0248 Validation Accuracy: 0.541800\n",
      "Epoch 303, CIFAR-10 Batch 5:  Loss:     1.0553 Validation Accuracy: 0.533800\n",
      "Epoch 304, CIFAR-10 Batch 1:  Loss:     1.0341 Validation Accuracy: 0.539200\n",
      "Epoch 304, CIFAR-10 Batch 2:  Loss:     1.0573 Validation Accuracy: 0.549600\n",
      "Epoch 304, CIFAR-10 Batch 3:  Loss:     1.0378 Validation Accuracy: 0.545400\n",
      "Epoch 304, CIFAR-10 Batch 4:  Loss:     1.0282 Validation Accuracy: 0.540600\n",
      "Epoch 304, CIFAR-10 Batch 5:  Loss:     1.0477 Validation Accuracy: 0.538800\n",
      "Epoch 305, CIFAR-10 Batch 1:  Loss:     1.0359 Validation Accuracy: 0.538600\n",
      "Epoch 305, CIFAR-10 Batch 2:  Loss:     1.0543 Validation Accuracy: 0.550200\n",
      "Epoch 305, CIFAR-10 Batch 3:  Loss:     1.0347 Validation Accuracy: 0.546200\n",
      "Epoch 305, CIFAR-10 Batch 4:  Loss:     1.0373 Validation Accuracy: 0.540600\n",
      "Epoch 305, CIFAR-10 Batch 5:  Loss:     1.0481 Validation Accuracy: 0.538800\n",
      "Epoch 306, CIFAR-10 Batch 1:  Loss:     1.0357 Validation Accuracy: 0.541800\n",
      "Epoch 306, CIFAR-10 Batch 2:  Loss:     1.0515 Validation Accuracy: 0.546600\n",
      "Epoch 306, CIFAR-10 Batch 3:  Loss:     1.0373 Validation Accuracy: 0.547200\n",
      "Epoch 306, CIFAR-10 Batch 4:  Loss:     1.0259 Validation Accuracy: 0.539400\n",
      "Epoch 306, CIFAR-10 Batch 5:  Loss:     1.0494 Validation Accuracy: 0.537400\n",
      "Epoch 307, CIFAR-10 Batch 1:  Loss:     1.0384 Validation Accuracy: 0.538000\n",
      "Epoch 307, CIFAR-10 Batch 2:  Loss:     1.0549 Validation Accuracy: 0.549200\n",
      "Epoch 307, CIFAR-10 Batch 3:  Loss:     1.0362 Validation Accuracy: 0.544400\n",
      "Epoch 307, CIFAR-10 Batch 4:  Loss:     1.0198 Validation Accuracy: 0.545400\n",
      "Epoch 307, CIFAR-10 Batch 5:  Loss:     1.0412 Validation Accuracy: 0.544600\n",
      "Epoch 308, CIFAR-10 Batch 1:  Loss:     1.0396 Validation Accuracy: 0.539600\n",
      "Epoch 308, CIFAR-10 Batch 2:  Loss:     1.0476 Validation Accuracy: 0.549800\n",
      "Epoch 308, CIFAR-10 Batch 3:  Loss:     1.0344 Validation Accuracy: 0.545800\n",
      "Epoch 308, CIFAR-10 Batch 4:  Loss:     1.0181 Validation Accuracy: 0.540400\n",
      "Epoch 308, CIFAR-10 Batch 5:  Loss:     1.0470 Validation Accuracy: 0.540800\n",
      "Epoch 309, CIFAR-10 Batch 1:  Loss:     1.0372 Validation Accuracy: 0.538800\n",
      "Epoch 309, CIFAR-10 Batch 2:  Loss:     1.0523 Validation Accuracy: 0.551000\n",
      "Epoch 309, CIFAR-10 Batch 3:  Loss:     1.0335 Validation Accuracy: 0.547400\n",
      "Epoch 309, CIFAR-10 Batch 4:  Loss:     1.0210 Validation Accuracy: 0.542400\n",
      "Epoch 309, CIFAR-10 Batch 5:  Loss:     1.0379 Validation Accuracy: 0.544400\n",
      "Epoch 310, CIFAR-10 Batch 1:  Loss:     1.0255 Validation Accuracy: 0.541600\n",
      "Epoch 310, CIFAR-10 Batch 2:  Loss:     1.0457 Validation Accuracy: 0.550000\n",
      "Epoch 310, CIFAR-10 Batch 3:  Loss:     1.0385 Validation Accuracy: 0.549000\n",
      "Epoch 310, CIFAR-10 Batch 4:  Loss:     1.0169 Validation Accuracy: 0.544600\n",
      "Epoch 310, CIFAR-10 Batch 5:  Loss:     1.0527 Validation Accuracy: 0.529600\n",
      "Epoch 311, CIFAR-10 Batch 1:  Loss:     1.0266 Validation Accuracy: 0.542400\n",
      "Epoch 311, CIFAR-10 Batch 2:  Loss:     1.0479 Validation Accuracy: 0.550400\n",
      "Epoch 311, CIFAR-10 Batch 3:  Loss:     1.0351 Validation Accuracy: 0.549600\n",
      "Epoch 311, CIFAR-10 Batch 4:  Loss:     1.0185 Validation Accuracy: 0.545800\n",
      "Epoch 311, CIFAR-10 Batch 5:  Loss:     1.0449 Validation Accuracy: 0.534600\n",
      "Epoch 312, CIFAR-10 Batch 1:  Loss:     1.0286 Validation Accuracy: 0.542800\n",
      "Epoch 312, CIFAR-10 Batch 2:  Loss:     1.0481 Validation Accuracy: 0.554000\n",
      "Epoch 312, CIFAR-10 Batch 3:  Loss:     1.0279 Validation Accuracy: 0.550600\n",
      "Epoch 312, CIFAR-10 Batch 4:  Loss:     1.0186 Validation Accuracy: 0.545800\n",
      "Epoch 312, CIFAR-10 Batch 5:  Loss:     1.0347 Validation Accuracy: 0.545800\n",
      "Epoch 313, CIFAR-10 Batch 1:  Loss:     1.0204 Validation Accuracy: 0.545400\n",
      "Epoch 313, CIFAR-10 Batch 2:  Loss:     1.0409 Validation Accuracy: 0.549200\n",
      "Epoch 313, CIFAR-10 Batch 3:  Loss:     1.0313 Validation Accuracy: 0.550400\n",
      "Epoch 313, CIFAR-10 Batch 4:  Loss:     1.0121 Validation Accuracy: 0.540800\n",
      "Epoch 313, CIFAR-10 Batch 5:  Loss:     1.0362 Validation Accuracy: 0.546800\n",
      "Epoch 314, CIFAR-10 Batch 1:  Loss:     1.0233 Validation Accuracy: 0.543200\n",
      "Epoch 314, CIFAR-10 Batch 2:  Loss:     1.0459 Validation Accuracy: 0.550600\n",
      "Epoch 314, CIFAR-10 Batch 3:  Loss:     1.0270 Validation Accuracy: 0.546800\n",
      "Epoch 314, CIFAR-10 Batch 4:  Loss:     1.0133 Validation Accuracy: 0.545400\n",
      "Epoch 314, CIFAR-10 Batch 5:  Loss:     1.0285 Validation Accuracy: 0.550000\n",
      "Epoch 315, CIFAR-10 Batch 1:  Loss:     1.0214 Validation Accuracy: 0.539800\n",
      "Epoch 315, CIFAR-10 Batch 2:  Loss:     1.0387 Validation Accuracy: 0.549600\n",
      "Epoch 315, CIFAR-10 Batch 3:  Loss:     1.0242 Validation Accuracy: 0.549800\n",
      "Epoch 315, CIFAR-10 Batch 4:  Loss:     1.0147 Validation Accuracy: 0.546000\n",
      "Epoch 315, CIFAR-10 Batch 5:  Loss:     1.0331 Validation Accuracy: 0.545600\n",
      "Epoch 316, CIFAR-10 Batch 1:  Loss:     1.0201 Validation Accuracy: 0.542000\n",
      "Epoch 316, CIFAR-10 Batch 2:  Loss:     1.0463 Validation Accuracy: 0.551600\n",
      "Epoch 316, CIFAR-10 Batch 3:  Loss:     1.0283 Validation Accuracy: 0.549400\n",
      "Epoch 316, CIFAR-10 Batch 4:  Loss:     1.0151 Validation Accuracy: 0.545800\n",
      "Epoch 316, CIFAR-10 Batch 5:  Loss:     1.0410 Validation Accuracy: 0.535000\n",
      "Epoch 317, CIFAR-10 Batch 1:  Loss:     1.0160 Validation Accuracy: 0.547200\n",
      "Epoch 317, CIFAR-10 Batch 2:  Loss:     1.0439 Validation Accuracy: 0.551600\n",
      "Epoch 317, CIFAR-10 Batch 3:  Loss:     1.0294 Validation Accuracy: 0.548600\n",
      "Epoch 317, CIFAR-10 Batch 4:  Loss:     1.0149 Validation Accuracy: 0.544600\n",
      "Epoch 317, CIFAR-10 Batch 5:  Loss:     1.0523 Validation Accuracy: 0.528600\n",
      "Epoch 318, CIFAR-10 Batch 1:  Loss:     1.0200 Validation Accuracy: 0.544800\n",
      "Epoch 318, CIFAR-10 Batch 2:  Loss:     1.0452 Validation Accuracy: 0.551200\n",
      "Epoch 318, CIFAR-10 Batch 3:  Loss:     1.0256 Validation Accuracy: 0.549200\n",
      "Epoch 318, CIFAR-10 Batch 4:  Loss:     1.0254 Validation Accuracy: 0.543000\n",
      "Epoch 318, CIFAR-10 Batch 5:  Loss:     1.0369 Validation Accuracy: 0.535600\n",
      "Epoch 319, CIFAR-10 Batch 1:  Loss:     1.0314 Validation Accuracy: 0.544000\n",
      "Epoch 319, CIFAR-10 Batch 2:  Loss:     1.0384 Validation Accuracy: 0.552800\n",
      "Epoch 319, CIFAR-10 Batch 3:  Loss:     1.0244 Validation Accuracy: 0.549200\n",
      "Epoch 319, CIFAR-10 Batch 4:  Loss:     1.0005 Validation Accuracy: 0.546200\n",
      "Epoch 319, CIFAR-10 Batch 5:  Loss:     1.0275 Validation Accuracy: 0.548200\n",
      "Epoch 320, CIFAR-10 Batch 1:  Loss:     1.0231 Validation Accuracy: 0.546600\n",
      "Epoch 320, CIFAR-10 Batch 2:  Loss:     1.0392 Validation Accuracy: 0.554800\n",
      "Epoch 320, CIFAR-10 Batch 3:  Loss:     1.0201 Validation Accuracy: 0.551000\n",
      "Epoch 320, CIFAR-10 Batch 4:  Loss:     1.0003 Validation Accuracy: 0.549400\n",
      "Epoch 320, CIFAR-10 Batch 5:  Loss:     1.0250 Validation Accuracy: 0.547000\n",
      "Epoch 321, CIFAR-10 Batch 1:  Loss:     1.0167 Validation Accuracy: 0.547000\n",
      "Epoch 321, CIFAR-10 Batch 2:  Loss:     1.0397 Validation Accuracy: 0.554000\n",
      "Epoch 321, CIFAR-10 Batch 3:  Loss:     1.0206 Validation Accuracy: 0.550000\n",
      "Epoch 321, CIFAR-10 Batch 4:  Loss:     1.0037 Validation Accuracy: 0.547200\n",
      "Epoch 321, CIFAR-10 Batch 5:  Loss:     1.0278 Validation Accuracy: 0.546600\n",
      "Epoch 322, CIFAR-10 Batch 1:  Loss:     1.0168 Validation Accuracy: 0.541800\n",
      "Epoch 322, CIFAR-10 Batch 2:  Loss:     1.0397 Validation Accuracy: 0.554600\n",
      "Epoch 322, CIFAR-10 Batch 3:  Loss:     1.0214 Validation Accuracy: 0.549400\n",
      "Epoch 322, CIFAR-10 Batch 4:  Loss:     1.0021 Validation Accuracy: 0.547400\n",
      "Epoch 322, CIFAR-10 Batch 5:  Loss:     1.0265 Validation Accuracy: 0.540200\n",
      "Epoch 323, CIFAR-10 Batch 1:  Loss:     1.0107 Validation Accuracy: 0.547400\n",
      "Epoch 323, CIFAR-10 Batch 2:  Loss:     1.0336 Validation Accuracy: 0.553600\n",
      "Epoch 323, CIFAR-10 Batch 3:  Loss:     1.0208 Validation Accuracy: 0.551600\n",
      "Epoch 323, CIFAR-10 Batch 4:  Loss:     1.0062 Validation Accuracy: 0.546800\n",
      "Epoch 323, CIFAR-10 Batch 5:  Loss:     1.0216 Validation Accuracy: 0.547400\n",
      "Epoch 324, CIFAR-10 Batch 1:  Loss:     1.0167 Validation Accuracy: 0.546200\n",
      "Epoch 324, CIFAR-10 Batch 2:  Loss:     1.0325 Validation Accuracy: 0.552400\n",
      "Epoch 324, CIFAR-10 Batch 3:  Loss:     1.0185 Validation Accuracy: 0.553400\n",
      "Epoch 324, CIFAR-10 Batch 4:  Loss:     1.0004 Validation Accuracy: 0.547600\n",
      "Epoch 324, CIFAR-10 Batch 5:  Loss:     1.0319 Validation Accuracy: 0.537600\n",
      "Epoch 325, CIFAR-10 Batch 1:  Loss:     1.0134 Validation Accuracy: 0.547200\n",
      "Epoch 325, CIFAR-10 Batch 2:  Loss:     1.0351 Validation Accuracy: 0.554800\n",
      "Epoch 325, CIFAR-10 Batch 3:  Loss:     1.0165 Validation Accuracy: 0.553600\n",
      "Epoch 325, CIFAR-10 Batch 4:  Loss:     0.9995 Validation Accuracy: 0.545400\n",
      "Epoch 325, CIFAR-10 Batch 5:  Loss:     1.0229 Validation Accuracy: 0.545400\n",
      "Epoch 326, CIFAR-10 Batch 1:  Loss:     1.0113 Validation Accuracy: 0.547400\n",
      "Epoch 326, CIFAR-10 Batch 2:  Loss:     1.0337 Validation Accuracy: 0.552000\n",
      "Epoch 326, CIFAR-10 Batch 3:  Loss:     1.0163 Validation Accuracy: 0.553800\n",
      "Epoch 326, CIFAR-10 Batch 4:  Loss:     1.0053 Validation Accuracy: 0.546800\n",
      "Epoch 326, CIFAR-10 Batch 5:  Loss:     1.0267 Validation Accuracy: 0.543600\n",
      "Epoch 327, CIFAR-10 Batch 1:  Loss:     1.0138 Validation Accuracy: 0.544000\n",
      "Epoch 327, CIFAR-10 Batch 2:  Loss:     1.0339 Validation Accuracy: 0.557200\n",
      "Epoch 327, CIFAR-10 Batch 3:  Loss:     1.0123 Validation Accuracy: 0.553000\n",
      "Epoch 327, CIFAR-10 Batch 4:  Loss:     0.9932 Validation Accuracy: 0.548400\n",
      "Epoch 327, CIFAR-10 Batch 5:  Loss:     1.0132 Validation Accuracy: 0.549000\n",
      "Epoch 328, CIFAR-10 Batch 1:  Loss:     1.0072 Validation Accuracy: 0.548200\n",
      "Epoch 328, CIFAR-10 Batch 2:  Loss:     1.0277 Validation Accuracy: 0.555800\n",
      "Epoch 328, CIFAR-10 Batch 3:  Loss:     1.0130 Validation Accuracy: 0.557000\n",
      "Epoch 328, CIFAR-10 Batch 4:  Loss:     0.9975 Validation Accuracy: 0.549200\n",
      "Epoch 328, CIFAR-10 Batch 5:  Loss:     1.0147 Validation Accuracy: 0.547800\n",
      "Epoch 329, CIFAR-10 Batch 1:  Loss:     1.0052 Validation Accuracy: 0.550600\n",
      "Epoch 329, CIFAR-10 Batch 2:  Loss:     1.0323 Validation Accuracy: 0.551800\n",
      "Epoch 329, CIFAR-10 Batch 3:  Loss:     1.0111 Validation Accuracy: 0.553800\n",
      "Epoch 329, CIFAR-10 Batch 4:  Loss:     0.9949 Validation Accuracy: 0.548800\n",
      "Epoch 329, CIFAR-10 Batch 5:  Loss:     1.0171 Validation Accuracy: 0.546000\n",
      "Epoch 330, CIFAR-10 Batch 1:  Loss:     1.0023 Validation Accuracy: 0.552000\n",
      "Epoch 330, CIFAR-10 Batch 2:  Loss:     1.0305 Validation Accuracy: 0.549800\n",
      "Epoch 330, CIFAR-10 Batch 3:  Loss:     1.0170 Validation Accuracy: 0.554200\n",
      "Epoch 330, CIFAR-10 Batch 4:  Loss:     1.0070 Validation Accuracy: 0.543200\n",
      "Epoch 330, CIFAR-10 Batch 5:  Loss:     1.0185 Validation Accuracy: 0.546200\n",
      "Epoch 331, CIFAR-10 Batch 1:  Loss:     1.0078 Validation Accuracy: 0.547400\n",
      "Epoch 331, CIFAR-10 Batch 2:  Loss:     1.0335 Validation Accuracy: 0.553600\n",
      "Epoch 331, CIFAR-10 Batch 3:  Loss:     1.0156 Validation Accuracy: 0.551400\n",
      "Epoch 331, CIFAR-10 Batch 4:  Loss:     0.9908 Validation Accuracy: 0.547400\n",
      "Epoch 331, CIFAR-10 Batch 5:  Loss:     1.0163 Validation Accuracy: 0.545400\n",
      "Epoch 332, CIFAR-10 Batch 1:  Loss:     1.0092 Validation Accuracy: 0.548200\n",
      "Epoch 332, CIFAR-10 Batch 2:  Loss:     1.0298 Validation Accuracy: 0.555800\n",
      "Epoch 332, CIFAR-10 Batch 3:  Loss:     1.0107 Validation Accuracy: 0.550600\n",
      "Epoch 332, CIFAR-10 Batch 4:  Loss:     0.9954 Validation Accuracy: 0.548400\n",
      "Epoch 332, CIFAR-10 Batch 5:  Loss:     1.0096 Validation Accuracy: 0.550400\n",
      "Epoch 333, CIFAR-10 Batch 1:  Loss:     1.0057 Validation Accuracy: 0.550800\n",
      "Epoch 333, CIFAR-10 Batch 2:  Loss:     1.0260 Validation Accuracy: 0.555200\n",
      "Epoch 333, CIFAR-10 Batch 3:  Loss:     1.0092 Validation Accuracy: 0.553600\n",
      "Epoch 333, CIFAR-10 Batch 4:  Loss:     0.9979 Validation Accuracy: 0.551000\n",
      "Epoch 333, CIFAR-10 Batch 5:  Loss:     1.0176 Validation Accuracy: 0.545600\n",
      "Epoch 334, CIFAR-10 Batch 1:  Loss:     0.9994 Validation Accuracy: 0.552600\n",
      "Epoch 334, CIFAR-10 Batch 2:  Loss:     1.0295 Validation Accuracy: 0.553600\n",
      "Epoch 334, CIFAR-10 Batch 3:  Loss:     1.0091 Validation Accuracy: 0.556400\n",
      "Epoch 334, CIFAR-10 Batch 4:  Loss:     0.9892 Validation Accuracy: 0.548000\n",
      "Epoch 334, CIFAR-10 Batch 5:  Loss:     1.0197 Validation Accuracy: 0.540400\n",
      "Epoch 335, CIFAR-10 Batch 1:  Loss:     0.9987 Validation Accuracy: 0.552200\n",
      "Epoch 335, CIFAR-10 Batch 2:  Loss:     1.0290 Validation Accuracy: 0.553600\n",
      "Epoch 335, CIFAR-10 Batch 3:  Loss:     1.0082 Validation Accuracy: 0.555200\n",
      "Epoch 335, CIFAR-10 Batch 4:  Loss:     0.9877 Validation Accuracy: 0.549200\n",
      "Epoch 335, CIFAR-10 Batch 5:  Loss:     1.0129 Validation Accuracy: 0.547800\n",
      "Epoch 336, CIFAR-10 Batch 1:  Loss:     0.9969 Validation Accuracy: 0.549600\n",
      "Epoch 336, CIFAR-10 Batch 2:  Loss:     1.0306 Validation Accuracy: 0.558400\n",
      "Epoch 336, CIFAR-10 Batch 3:  Loss:     1.0116 Validation Accuracy: 0.553800\n",
      "Epoch 336, CIFAR-10 Batch 4:  Loss:     0.9930 Validation Accuracy: 0.551000\n",
      "Epoch 336, CIFAR-10 Batch 5:  Loss:     1.0110 Validation Accuracy: 0.546600\n",
      "Epoch 337, CIFAR-10 Batch 1:  Loss:     0.9946 Validation Accuracy: 0.555200\n",
      "Epoch 337, CIFAR-10 Batch 2:  Loss:     1.0240 Validation Accuracy: 0.556000\n",
      "Epoch 337, CIFAR-10 Batch 3:  Loss:     1.0134 Validation Accuracy: 0.553600\n",
      "Epoch 337, CIFAR-10 Batch 4:  Loss:     1.0024 Validation Accuracy: 0.545800\n",
      "Epoch 337, CIFAR-10 Batch 5:  Loss:     1.0223 Validation Accuracy: 0.539600\n",
      "Epoch 338, CIFAR-10 Batch 1:  Loss:     1.0011 Validation Accuracy: 0.550800\n",
      "Epoch 338, CIFAR-10 Batch 2:  Loss:     1.0342 Validation Accuracy: 0.555400\n",
      "Epoch 338, CIFAR-10 Batch 3:  Loss:     1.0060 Validation Accuracy: 0.553200\n",
      "Epoch 338, CIFAR-10 Batch 4:  Loss:     0.9908 Validation Accuracy: 0.549600\n",
      "Epoch 338, CIFAR-10 Batch 5:  Loss:     1.0143 Validation Accuracy: 0.543200\n",
      "Epoch 339, CIFAR-10 Batch 1:  Loss:     0.9938 Validation Accuracy: 0.555200\n",
      "Epoch 339, CIFAR-10 Batch 2:  Loss:     1.0255 Validation Accuracy: 0.556400\n",
      "Epoch 339, CIFAR-10 Batch 3:  Loss:     1.0088 Validation Accuracy: 0.556800\n",
      "Epoch 339, CIFAR-10 Batch 4:  Loss:     0.9890 Validation Accuracy: 0.550800\n",
      "Epoch 339, CIFAR-10 Batch 5:  Loss:     1.0173 Validation Accuracy: 0.542600\n",
      "Epoch 340, CIFAR-10 Batch 1:  Loss:     0.9948 Validation Accuracy: 0.553800\n",
      "Epoch 340, CIFAR-10 Batch 2:  Loss:     1.0190 Validation Accuracy: 0.559200\n",
      "Epoch 340, CIFAR-10 Batch 3:  Loss:     1.0085 Validation Accuracy: 0.554600\n",
      "Epoch 340, CIFAR-10 Batch 4:  Loss:     0.9916 Validation Accuracy: 0.550600\n",
      "Epoch 340, CIFAR-10 Batch 5:  Loss:     1.0201 Validation Accuracy: 0.537200\n",
      "Epoch 341, CIFAR-10 Batch 1:  Loss:     0.9960 Validation Accuracy: 0.554000\n",
      "Epoch 341, CIFAR-10 Batch 2:  Loss:     1.0243 Validation Accuracy: 0.556200\n",
      "Epoch 341, CIFAR-10 Batch 3:  Loss:     1.0054 Validation Accuracy: 0.555000\n",
      "Epoch 341, CIFAR-10 Batch 4:  Loss:     0.9955 Validation Accuracy: 0.548400\n",
      "Epoch 341, CIFAR-10 Batch 5:  Loss:     1.0165 Validation Accuracy: 0.541800\n",
      "Epoch 342, CIFAR-10 Batch 1:  Loss:     1.0112 Validation Accuracy: 0.548400\n",
      "Epoch 342, CIFAR-10 Batch 2:  Loss:     1.0265 Validation Accuracy: 0.557400\n",
      "Epoch 342, CIFAR-10 Batch 3:  Loss:     1.0054 Validation Accuracy: 0.557400\n",
      "Epoch 342, CIFAR-10 Batch 4:  Loss:     0.9919 Validation Accuracy: 0.545400\n",
      "Epoch 342, CIFAR-10 Batch 5:  Loss:     1.0100 Validation Accuracy: 0.550800\n",
      "Epoch 343, CIFAR-10 Batch 1:  Loss:     1.0145 Validation Accuracy: 0.547400\n",
      "Epoch 343, CIFAR-10 Batch 2:  Loss:     1.0250 Validation Accuracy: 0.559600\n",
      "Epoch 343, CIFAR-10 Batch 3:  Loss:     1.0039 Validation Accuracy: 0.555200\n",
      "Epoch 343, CIFAR-10 Batch 4:  Loss:     0.9870 Validation Accuracy: 0.551400\n",
      "Epoch 343, CIFAR-10 Batch 5:  Loss:     1.0066 Validation Accuracy: 0.553600\n",
      "Epoch 344, CIFAR-10 Batch 1:  Loss:     1.0099 Validation Accuracy: 0.551000\n",
      "Epoch 344, CIFAR-10 Batch 2:  Loss:     1.0201 Validation Accuracy: 0.559800\n",
      "Epoch 344, CIFAR-10 Batch 3:  Loss:     0.9998 Validation Accuracy: 0.555800\n",
      "Epoch 344, CIFAR-10 Batch 4:  Loss:     0.9796 Validation Accuracy: 0.552800\n",
      "Epoch 344, CIFAR-10 Batch 5:  Loss:     1.0038 Validation Accuracy: 0.551800\n",
      "Epoch 345, CIFAR-10 Batch 1:  Loss:     1.0013 Validation Accuracy: 0.551600\n",
      "Epoch 345, CIFAR-10 Batch 2:  Loss:     1.0202 Validation Accuracy: 0.560600\n",
      "Epoch 345, CIFAR-10 Batch 3:  Loss:     0.9998 Validation Accuracy: 0.556600\n",
      "Epoch 345, CIFAR-10 Batch 4:  Loss:     0.9760 Validation Accuracy: 0.556000\n",
      "Epoch 345, CIFAR-10 Batch 5:  Loss:     0.9997 Validation Accuracy: 0.550200\n",
      "Epoch 346, CIFAR-10 Batch 1:  Loss:     1.0000 Validation Accuracy: 0.554400\n",
      "Epoch 346, CIFAR-10 Batch 2:  Loss:     1.0168 Validation Accuracy: 0.559200\n",
      "Epoch 346, CIFAR-10 Batch 3:  Loss:     0.9996 Validation Accuracy: 0.556600\n",
      "Epoch 346, CIFAR-10 Batch 4:  Loss:     0.9786 Validation Accuracy: 0.553400\n",
      "Epoch 346, CIFAR-10 Batch 5:  Loss:     1.0028 Validation Accuracy: 0.547600\n",
      "Epoch 347, CIFAR-10 Batch 1:  Loss:     1.0017 Validation Accuracy: 0.550000\n",
      "Epoch 347, CIFAR-10 Batch 2:  Loss:     1.0221 Validation Accuracy: 0.560000\n",
      "Epoch 347, CIFAR-10 Batch 3:  Loss:     0.9983 Validation Accuracy: 0.557600\n",
      "Epoch 347, CIFAR-10 Batch 4:  Loss:     0.9735 Validation Accuracy: 0.553400\n",
      "Epoch 347, CIFAR-10 Batch 5:  Loss:     1.0043 Validation Accuracy: 0.546800\n",
      "Epoch 348, CIFAR-10 Batch 1:  Loss:     0.9951 Validation Accuracy: 0.554600\n",
      "Epoch 348, CIFAR-10 Batch 2:  Loss:     1.0157 Validation Accuracy: 0.562000\n",
      "Epoch 348, CIFAR-10 Batch 3:  Loss:     0.9974 Validation Accuracy: 0.557800\n",
      "Epoch 348, CIFAR-10 Batch 4:  Loss:     0.9739 Validation Accuracy: 0.552200\n",
      "Epoch 348, CIFAR-10 Batch 5:  Loss:     1.0031 Validation Accuracy: 0.548200\n",
      "Epoch 349, CIFAR-10 Batch 1:  Loss:     0.9920 Validation Accuracy: 0.553400\n",
      "Epoch 349, CIFAR-10 Batch 2:  Loss:     1.0110 Validation Accuracy: 0.561200\n",
      "Epoch 349, CIFAR-10 Batch 3:  Loss:     0.9991 Validation Accuracy: 0.558400\n",
      "Epoch 349, CIFAR-10 Batch 4:  Loss:     0.9775 Validation Accuracy: 0.551600\n",
      "Epoch 349, CIFAR-10 Batch 5:  Loss:     1.0064 Validation Accuracy: 0.542600\n",
      "Epoch 350, CIFAR-10 Batch 1:  Loss:     0.9938 Validation Accuracy: 0.556600\n",
      "Epoch 350, CIFAR-10 Batch 2:  Loss:     1.0131 Validation Accuracy: 0.561200\n",
      "Epoch 350, CIFAR-10 Batch 3:  Loss:     0.9970 Validation Accuracy: 0.562400\n",
      "Epoch 350, CIFAR-10 Batch 4:  Loss:     0.9695 Validation Accuracy: 0.553600\n",
      "Epoch 350, CIFAR-10 Batch 5:  Loss:     1.0019 Validation Accuracy: 0.548600\n",
      "Epoch 351, CIFAR-10 Batch 1:  Loss:     0.9921 Validation Accuracy: 0.551600\n",
      "Epoch 351, CIFAR-10 Batch 2:  Loss:     1.0176 Validation Accuracy: 0.565800\n",
      "Epoch 351, CIFAR-10 Batch 3:  Loss:     0.9929 Validation Accuracy: 0.559800\n",
      "Epoch 351, CIFAR-10 Batch 4:  Loss:     0.9692 Validation Accuracy: 0.556400\n",
      "Epoch 351, CIFAR-10 Batch 5:  Loss:     0.9919 Validation Accuracy: 0.550400\n",
      "Epoch 352, CIFAR-10 Batch 1:  Loss:     0.9904 Validation Accuracy: 0.553200\n",
      "Epoch 352, CIFAR-10 Batch 2:  Loss:     1.0157 Validation Accuracy: 0.560200\n",
      "Epoch 352, CIFAR-10 Batch 3:  Loss:     0.9945 Validation Accuracy: 0.559200\n",
      "Epoch 352, CIFAR-10 Batch 4:  Loss:     0.9676 Validation Accuracy: 0.557800\n",
      "Epoch 352, CIFAR-10 Batch 5:  Loss:     0.9943 Validation Accuracy: 0.551600\n",
      "Epoch 353, CIFAR-10 Batch 1:  Loss:     0.9799 Validation Accuracy: 0.558200\n",
      "Epoch 353, CIFAR-10 Batch 2:  Loss:     1.0087 Validation Accuracy: 0.561200\n",
      "Epoch 353, CIFAR-10 Batch 3:  Loss:     0.9980 Validation Accuracy: 0.559400\n",
      "Epoch 353, CIFAR-10 Batch 4:  Loss:     0.9708 Validation Accuracy: 0.553200\n",
      "Epoch 353, CIFAR-10 Batch 5:  Loss:     0.9998 Validation Accuracy: 0.555000\n",
      "Epoch 354, CIFAR-10 Batch 1:  Loss:     0.9843 Validation Accuracy: 0.554800\n",
      "Epoch 354, CIFAR-10 Batch 2:  Loss:     1.0200 Validation Accuracy: 0.560000\n",
      "Epoch 354, CIFAR-10 Batch 3:  Loss:     1.0013 Validation Accuracy: 0.553800\n",
      "Epoch 354, CIFAR-10 Batch 4:  Loss:     0.9772 Validation Accuracy: 0.556600\n",
      "Epoch 354, CIFAR-10 Batch 5:  Loss:     0.9965 Validation Accuracy: 0.546800\n",
      "Epoch 355, CIFAR-10 Batch 1:  Loss:     0.9796 Validation Accuracy: 0.560200\n",
      "Epoch 355, CIFAR-10 Batch 2:  Loss:     1.0089 Validation Accuracy: 0.564200\n",
      "Epoch 355, CIFAR-10 Batch 3:  Loss:     0.9920 Validation Accuracy: 0.559600\n",
      "Epoch 355, CIFAR-10 Batch 4:  Loss:     0.9682 Validation Accuracy: 0.555200\n",
      "Epoch 355, CIFAR-10 Batch 5:  Loss:     0.9935 Validation Accuracy: 0.551400\n",
      "Epoch 356, CIFAR-10 Batch 1:  Loss:     0.9864 Validation Accuracy: 0.552400\n",
      "Epoch 356, CIFAR-10 Batch 2:  Loss:     1.0095 Validation Accuracy: 0.562800\n",
      "Epoch 356, CIFAR-10 Batch 3:  Loss:     0.9841 Validation Accuracy: 0.558400\n",
      "Epoch 356, CIFAR-10 Batch 4:  Loss:     0.9695 Validation Accuracy: 0.555400\n",
      "Epoch 356, CIFAR-10 Batch 5:  Loss:     0.9866 Validation Accuracy: 0.554000\n",
      "Epoch 357, CIFAR-10 Batch 1:  Loss:     0.9810 Validation Accuracy: 0.555000\n",
      "Epoch 357, CIFAR-10 Batch 2:  Loss:     1.0103 Validation Accuracy: 0.564200\n",
      "Epoch 357, CIFAR-10 Batch 3:  Loss:     0.9891 Validation Accuracy: 0.559000\n",
      "Epoch 357, CIFAR-10 Batch 4:  Loss:     0.9716 Validation Accuracy: 0.556400\n",
      "Epoch 357, CIFAR-10 Batch 5:  Loss:     0.9914 Validation Accuracy: 0.548800\n",
      "Epoch 358, CIFAR-10 Batch 1:  Loss:     0.9822 Validation Accuracy: 0.551400\n",
      "Epoch 358, CIFAR-10 Batch 2:  Loss:     1.0087 Validation Accuracy: 0.565800\n",
      "Epoch 358, CIFAR-10 Batch 3:  Loss:     0.9839 Validation Accuracy: 0.559800\n",
      "Epoch 358, CIFAR-10 Batch 4:  Loss:     0.9607 Validation Accuracy: 0.556000\n",
      "Epoch 358, CIFAR-10 Batch 5:  Loss:     0.9900 Validation Accuracy: 0.549800\n",
      "Epoch 359, CIFAR-10 Batch 1:  Loss:     0.9758 Validation Accuracy: 0.556800\n",
      "Epoch 359, CIFAR-10 Batch 2:  Loss:     1.0106 Validation Accuracy: 0.561600\n",
      "Epoch 359, CIFAR-10 Batch 3:  Loss:     0.9880 Validation Accuracy: 0.561200\n",
      "Epoch 359, CIFAR-10 Batch 4:  Loss:     0.9687 Validation Accuracy: 0.555800\n",
      "Epoch 359, CIFAR-10 Batch 5:  Loss:     0.9872 Validation Accuracy: 0.553200\n",
      "Epoch 360, CIFAR-10 Batch 1:  Loss:     0.9809 Validation Accuracy: 0.557200\n",
      "Epoch 360, CIFAR-10 Batch 2:  Loss:     1.0115 Validation Accuracy: 0.559200\n",
      "Epoch 360, CIFAR-10 Batch 3:  Loss:     0.9878 Validation Accuracy: 0.558400\n",
      "Epoch 360, CIFAR-10 Batch 4:  Loss:     0.9673 Validation Accuracy: 0.556600\n",
      "Epoch 360, CIFAR-10 Batch 5:  Loss:     0.9864 Validation Accuracy: 0.551200\n",
      "Epoch 361, CIFAR-10 Batch 1:  Loss:     0.9767 Validation Accuracy: 0.556200\n",
      "Epoch 361, CIFAR-10 Batch 2:  Loss:     1.0088 Validation Accuracy: 0.559600\n",
      "Epoch 361, CIFAR-10 Batch 3:  Loss:     0.9822 Validation Accuracy: 0.562000\n",
      "Epoch 361, CIFAR-10 Batch 4:  Loss:     0.9611 Validation Accuracy: 0.554600\n",
      "Epoch 361, CIFAR-10 Batch 5:  Loss:     0.9862 Validation Accuracy: 0.553000\n",
      "Epoch 362, CIFAR-10 Batch 1:  Loss:     0.9741 Validation Accuracy: 0.556400\n",
      "Epoch 362, CIFAR-10 Batch 2:  Loss:     1.0050 Validation Accuracy: 0.561000\n",
      "Epoch 362, CIFAR-10 Batch 3:  Loss:     0.9824 Validation Accuracy: 0.560200\n",
      "Epoch 362, CIFAR-10 Batch 4:  Loss:     0.9632 Validation Accuracy: 0.557400\n",
      "Epoch 362, CIFAR-10 Batch 5:  Loss:     0.9832 Validation Accuracy: 0.554000\n",
      "Epoch 363, CIFAR-10 Batch 1:  Loss:     0.9783 Validation Accuracy: 0.559600\n",
      "Epoch 363, CIFAR-10 Batch 2:  Loss:     1.0198 Validation Accuracy: 0.555600\n",
      "Epoch 363, CIFAR-10 Batch 3:  Loss:     0.9879 Validation Accuracy: 0.560000\n",
      "Epoch 363, CIFAR-10 Batch 4:  Loss:     0.9651 Validation Accuracy: 0.551600\n",
      "Epoch 363, CIFAR-10 Batch 5:  Loss:     0.9868 Validation Accuracy: 0.552600\n",
      "Epoch 364, CIFAR-10 Batch 1:  Loss:     0.9754 Validation Accuracy: 0.553800\n",
      "Epoch 364, CIFAR-10 Batch 2:  Loss:     1.0092 Validation Accuracy: 0.558400\n",
      "Epoch 364, CIFAR-10 Batch 3:  Loss:     0.9820 Validation Accuracy: 0.556400\n",
      "Epoch 364, CIFAR-10 Batch 4:  Loss:     0.9523 Validation Accuracy: 0.556000\n",
      "Epoch 364, CIFAR-10 Batch 5:  Loss:     0.9810 Validation Accuracy: 0.552200\n",
      "Epoch 365, CIFAR-10 Batch 1:  Loss:     0.9737 Validation Accuracy: 0.556200\n",
      "Epoch 365, CIFAR-10 Batch 2:  Loss:     1.0123 Validation Accuracy: 0.559000\n",
      "Epoch 365, CIFAR-10 Batch 3:  Loss:     0.9880 Validation Accuracy: 0.556400\n",
      "Epoch 365, CIFAR-10 Batch 4:  Loss:     0.9630 Validation Accuracy: 0.555400\n",
      "Epoch 365, CIFAR-10 Batch 5:  Loss:     0.9834 Validation Accuracy: 0.549400\n",
      "Epoch 366, CIFAR-10 Batch 1:  Loss:     0.9701 Validation Accuracy: 0.555000\n",
      "Epoch 366, CIFAR-10 Batch 2:  Loss:     1.0105 Validation Accuracy: 0.560600\n",
      "Epoch 366, CIFAR-10 Batch 3:  Loss:     0.9859 Validation Accuracy: 0.559400\n",
      "Epoch 366, CIFAR-10 Batch 4:  Loss:     0.9589 Validation Accuracy: 0.553200\n",
      "Epoch 366, CIFAR-10 Batch 5:  Loss:     0.9781 Validation Accuracy: 0.552200\n",
      "Epoch 367, CIFAR-10 Batch 1:  Loss:     0.9664 Validation Accuracy: 0.558400\n",
      "Epoch 367, CIFAR-10 Batch 2:  Loss:     1.0032 Validation Accuracy: 0.559200\n",
      "Epoch 367, CIFAR-10 Batch 3:  Loss:     0.9873 Validation Accuracy: 0.558400\n",
      "Epoch 367, CIFAR-10 Batch 4:  Loss:     0.9639 Validation Accuracy: 0.554400\n",
      "Epoch 367, CIFAR-10 Batch 5:  Loss:     0.9895 Validation Accuracy: 0.546000\n",
      "Epoch 368, CIFAR-10 Batch 1:  Loss:     0.9836 Validation Accuracy: 0.553200\n",
      "Epoch 368, CIFAR-10 Batch 2:  Loss:     1.0224 Validation Accuracy: 0.555000\n",
      "Epoch 368, CIFAR-10 Batch 3:  Loss:     0.9902 Validation Accuracy: 0.557000\n",
      "Epoch 368, CIFAR-10 Batch 4:  Loss:     0.9641 Validation Accuracy: 0.553400\n",
      "Epoch 368, CIFAR-10 Batch 5:  Loss:     0.9955 Validation Accuracy: 0.546800\n",
      "Epoch 369, CIFAR-10 Batch 1:  Loss:     0.9676 Validation Accuracy: 0.556400\n",
      "Epoch 369, CIFAR-10 Batch 2:  Loss:     1.0139 Validation Accuracy: 0.561200\n",
      "Epoch 369, CIFAR-10 Batch 3:  Loss:     0.9886 Validation Accuracy: 0.556000\n",
      "Epoch 369, CIFAR-10 Batch 4:  Loss:     0.9616 Validation Accuracy: 0.556200\n",
      "Epoch 369, CIFAR-10 Batch 5:  Loss:     0.9922 Validation Accuracy: 0.550400\n",
      "Epoch 370, CIFAR-10 Batch 1:  Loss:     0.9645 Validation Accuracy: 0.556400\n",
      "Epoch 370, CIFAR-10 Batch 2:  Loss:     1.0111 Validation Accuracy: 0.559800\n",
      "Epoch 370, CIFAR-10 Batch 3:  Loss:     0.9920 Validation Accuracy: 0.553600\n",
      "Epoch 370, CIFAR-10 Batch 4:  Loss:     0.9787 Validation Accuracy: 0.553000\n",
      "Epoch 370, CIFAR-10 Batch 5:  Loss:     0.9933 Validation Accuracy: 0.547400\n",
      "Epoch 371, CIFAR-10 Batch 1:  Loss:     0.9728 Validation Accuracy: 0.563400\n",
      "Epoch 371, CIFAR-10 Batch 2:  Loss:     1.0007 Validation Accuracy: 0.566200\n",
      "Epoch 371, CIFAR-10 Batch 3:  Loss:     0.9839 Validation Accuracy: 0.558800\n",
      "Epoch 371, CIFAR-10 Batch 4:  Loss:     0.9736 Validation Accuracy: 0.547800\n",
      "Epoch 371, CIFAR-10 Batch 5:  Loss:     0.9999 Validation Accuracy: 0.549600\n",
      "Epoch 372, CIFAR-10 Batch 1:  Loss:     0.9886 Validation Accuracy: 0.552600\n",
      "Epoch 372, CIFAR-10 Batch 2:  Loss:     1.0090 Validation Accuracy: 0.560200\n",
      "Epoch 372, CIFAR-10 Batch 3:  Loss:     0.9775 Validation Accuracy: 0.563600\n",
      "Epoch 372, CIFAR-10 Batch 4:  Loss:     0.9660 Validation Accuracy: 0.545200\n",
      "Epoch 372, CIFAR-10 Batch 5:  Loss:     0.9880 Validation Accuracy: 0.552400\n",
      "Epoch 373, CIFAR-10 Batch 1:  Loss:     1.0021 Validation Accuracy: 0.551400\n",
      "Epoch 373, CIFAR-10 Batch 2:  Loss:     1.0034 Validation Accuracy: 0.564800\n",
      "Epoch 373, CIFAR-10 Batch 3:  Loss:     0.9838 Validation Accuracy: 0.558200\n",
      "Epoch 373, CIFAR-10 Batch 4:  Loss:     0.9477 Validation Accuracy: 0.559200\n",
      "Epoch 373, CIFAR-10 Batch 5:  Loss:     0.9735 Validation Accuracy: 0.558600\n",
      "Epoch 374, CIFAR-10 Batch 1:  Loss:     1.0050 Validation Accuracy: 0.551800\n",
      "Epoch 374, CIFAR-10 Batch 2:  Loss:     1.0048 Validation Accuracy: 0.560800\n",
      "Epoch 374, CIFAR-10 Batch 3:  Loss:     0.9894 Validation Accuracy: 0.556000\n",
      "Epoch 374, CIFAR-10 Batch 4:  Loss:     0.9475 Validation Accuracy: 0.560800\n",
      "Epoch 374, CIFAR-10 Batch 5:  Loss:     0.9695 Validation Accuracy: 0.558600\n",
      "Epoch 375, CIFAR-10 Batch 1:  Loss:     0.9838 Validation Accuracy: 0.552200\n",
      "Epoch 375, CIFAR-10 Batch 2:  Loss:     0.9947 Validation Accuracy: 0.564800\n",
      "Epoch 375, CIFAR-10 Batch 3:  Loss:     0.9774 Validation Accuracy: 0.562400\n",
      "Epoch 375, CIFAR-10 Batch 4:  Loss:     0.9463 Validation Accuracy: 0.557000\n",
      "Epoch 375, CIFAR-10 Batch 5:  Loss:     0.9670 Validation Accuracy: 0.559400\n",
      "Epoch 376, CIFAR-10 Batch 1:  Loss:     0.9810 Validation Accuracy: 0.557200\n",
      "Epoch 376, CIFAR-10 Batch 2:  Loss:     0.9969 Validation Accuracy: 0.563200\n",
      "Epoch 376, CIFAR-10 Batch 3:  Loss:     0.9751 Validation Accuracy: 0.560800\n",
      "Epoch 376, CIFAR-10 Batch 4:  Loss:     0.9542 Validation Accuracy: 0.557000\n",
      "Epoch 376, CIFAR-10 Batch 5:  Loss:     0.9701 Validation Accuracy: 0.558200\n",
      "Epoch 377, CIFAR-10 Batch 1:  Loss:     0.9766 Validation Accuracy: 0.557400\n",
      "Epoch 377, CIFAR-10 Batch 2:  Loss:     0.9965 Validation Accuracy: 0.565800\n",
      "Epoch 377, CIFAR-10 Batch 3:  Loss:     0.9727 Validation Accuracy: 0.561600\n",
      "Epoch 377, CIFAR-10 Batch 4:  Loss:     0.9478 Validation Accuracy: 0.556800\n",
      "Epoch 377, CIFAR-10 Batch 5:  Loss:     0.9765 Validation Accuracy: 0.556600\n",
      "Epoch 378, CIFAR-10 Batch 1:  Loss:     0.9698 Validation Accuracy: 0.557000\n",
      "Epoch 378, CIFAR-10 Batch 2:  Loss:     0.9921 Validation Accuracy: 0.562000\n",
      "Epoch 378, CIFAR-10 Batch 3:  Loss:     0.9776 Validation Accuracy: 0.556800\n",
      "Epoch 378, CIFAR-10 Batch 4:  Loss:     0.9471 Validation Accuracy: 0.555400\n",
      "Epoch 378, CIFAR-10 Batch 5:  Loss:     0.9709 Validation Accuracy: 0.557200\n",
      "Epoch 379, CIFAR-10 Batch 1:  Loss:     0.9734 Validation Accuracy: 0.560600\n",
      "Epoch 379, CIFAR-10 Batch 2:  Loss:     0.9956 Validation Accuracy: 0.564200\n",
      "Epoch 379, CIFAR-10 Batch 3:  Loss:     0.9725 Validation Accuracy: 0.566200\n",
      "Epoch 379, CIFAR-10 Batch 4:  Loss:     0.9466 Validation Accuracy: 0.561200\n",
      "Epoch 379, CIFAR-10 Batch 5:  Loss:     0.9752 Validation Accuracy: 0.558200\n",
      "Epoch 380, CIFAR-10 Batch 1:  Loss:     0.9635 Validation Accuracy: 0.558800\n",
      "Epoch 380, CIFAR-10 Batch 2:  Loss:     0.9863 Validation Accuracy: 0.566800\n",
      "Epoch 380, CIFAR-10 Batch 3:  Loss:     0.9742 Validation Accuracy: 0.564000\n",
      "Epoch 380, CIFAR-10 Batch 4:  Loss:     0.9451 Validation Accuracy: 0.559000\n",
      "Epoch 380, CIFAR-10 Batch 5:  Loss:     0.9718 Validation Accuracy: 0.557800\n",
      "Epoch 381, CIFAR-10 Batch 1:  Loss:     0.9599 Validation Accuracy: 0.561600\n",
      "Epoch 381, CIFAR-10 Batch 2:  Loss:     0.9941 Validation Accuracy: 0.564600\n",
      "Epoch 381, CIFAR-10 Batch 3:  Loss:     0.9786 Validation Accuracy: 0.559800\n",
      "Epoch 381, CIFAR-10 Batch 4:  Loss:     0.9545 Validation Accuracy: 0.560400\n",
      "Epoch 381, CIFAR-10 Batch 5:  Loss:     0.9801 Validation Accuracy: 0.550400\n",
      "Epoch 382, CIFAR-10 Batch 1:  Loss:     0.9597 Validation Accuracy: 0.560800\n",
      "Epoch 382, CIFAR-10 Batch 2:  Loss:     0.9942 Validation Accuracy: 0.565200\n",
      "Epoch 382, CIFAR-10 Batch 3:  Loss:     0.9791 Validation Accuracy: 0.560400\n",
      "Epoch 382, CIFAR-10 Batch 4:  Loss:     0.9495 Validation Accuracy: 0.554800\n",
      "Epoch 382, CIFAR-10 Batch 5:  Loss:     0.9894 Validation Accuracy: 0.548600\n",
      "Epoch 383, CIFAR-10 Batch 1:  Loss:     0.9623 Validation Accuracy: 0.557200\n",
      "Epoch 383, CIFAR-10 Batch 2:  Loss:     1.0124 Validation Accuracy: 0.559000\n",
      "Epoch 383, CIFAR-10 Batch 3:  Loss:     0.9724 Validation Accuracy: 0.563200\n",
      "Epoch 383, CIFAR-10 Batch 4:  Loss:     0.9472 Validation Accuracy: 0.556200\n",
      "Epoch 383, CIFAR-10 Batch 5:  Loss:     0.9766 Validation Accuracy: 0.554400\n",
      "Epoch 384, CIFAR-10 Batch 1:  Loss:     0.9680 Validation Accuracy: 0.557600\n",
      "Epoch 384, CIFAR-10 Batch 2:  Loss:     0.9905 Validation Accuracy: 0.564600\n",
      "Epoch 384, CIFAR-10 Batch 3:  Loss:     0.9683 Validation Accuracy: 0.559200\n",
      "Epoch 384, CIFAR-10 Batch 4:  Loss:     0.9500 Validation Accuracy: 0.554400\n",
      "Epoch 384, CIFAR-10 Batch 5:  Loss:     0.9688 Validation Accuracy: 0.559200\n",
      "Epoch 385, CIFAR-10 Batch 1:  Loss:     0.9758 Validation Accuracy: 0.561400\n",
      "Epoch 385, CIFAR-10 Batch 2:  Loss:     0.9894 Validation Accuracy: 0.567400\n",
      "Epoch 385, CIFAR-10 Batch 3:  Loss:     0.9665 Validation Accuracy: 0.562800\n",
      "Epoch 385, CIFAR-10 Batch 4:  Loss:     0.9427 Validation Accuracy: 0.558600\n",
      "Epoch 385, CIFAR-10 Batch 5:  Loss:     0.9588 Validation Accuracy: 0.561800\n",
      "Epoch 386, CIFAR-10 Batch 1:  Loss:     0.9644 Validation Accuracy: 0.559600\n",
      "Epoch 386, CIFAR-10 Batch 2:  Loss:     0.9863 Validation Accuracy: 0.564600\n",
      "Epoch 386, CIFAR-10 Batch 3:  Loss:     0.9672 Validation Accuracy: 0.561800\n",
      "Epoch 386, CIFAR-10 Batch 4:  Loss:     0.9409 Validation Accuracy: 0.559000\n",
      "Epoch 386, CIFAR-10 Batch 5:  Loss:     0.9671 Validation Accuracy: 0.559600\n",
      "Epoch 387, CIFAR-10 Batch 1:  Loss:     0.9808 Validation Accuracy: 0.553800\n",
      "Epoch 387, CIFAR-10 Batch 2:  Loss:     1.0031 Validation Accuracy: 0.558400\n",
      "Epoch 387, CIFAR-10 Batch 3:  Loss:     0.9693 Validation Accuracy: 0.564400\n",
      "Epoch 387, CIFAR-10 Batch 4:  Loss:     0.9368 Validation Accuracy: 0.557000\n",
      "Epoch 387, CIFAR-10 Batch 5:  Loss:     0.9626 Validation Accuracy: 0.560800\n",
      "Epoch 388, CIFAR-10 Batch 1:  Loss:     0.9724 Validation Accuracy: 0.559000\n",
      "Epoch 388, CIFAR-10 Batch 2:  Loss:     0.9836 Validation Accuracy: 0.563800\n",
      "Epoch 388, CIFAR-10 Batch 3:  Loss:     0.9627 Validation Accuracy: 0.563200\n",
      "Epoch 388, CIFAR-10 Batch 4:  Loss:     0.9362 Validation Accuracy: 0.557200\n",
      "Epoch 388, CIFAR-10 Batch 5:  Loss:     0.9614 Validation Accuracy: 0.562800\n",
      "Epoch 389, CIFAR-10 Batch 1:  Loss:     0.9682 Validation Accuracy: 0.559200\n",
      "Epoch 389, CIFAR-10 Batch 2:  Loss:     0.9883 Validation Accuracy: 0.566200\n",
      "Epoch 389, CIFAR-10 Batch 3:  Loss:     0.9666 Validation Accuracy: 0.563800\n",
      "Epoch 389, CIFAR-10 Batch 4:  Loss:     0.9342 Validation Accuracy: 0.559600\n",
      "Epoch 389, CIFAR-10 Batch 5:  Loss:     0.9579 Validation Accuracy: 0.562000\n",
      "Epoch 390, CIFAR-10 Batch 1:  Loss:     0.9694 Validation Accuracy: 0.558800\n",
      "Epoch 390, CIFAR-10 Batch 2:  Loss:     0.9895 Validation Accuracy: 0.565000\n",
      "Epoch 390, CIFAR-10 Batch 3:  Loss:     0.9642 Validation Accuracy: 0.567400\n",
      "Epoch 390, CIFAR-10 Batch 4:  Loss:     0.9374 Validation Accuracy: 0.558200\n",
      "Epoch 390, CIFAR-10 Batch 5:  Loss:     0.9547 Validation Accuracy: 0.561600\n",
      "Epoch 391, CIFAR-10 Batch 1:  Loss:     0.9640 Validation Accuracy: 0.558600\n",
      "Epoch 391, CIFAR-10 Batch 2:  Loss:     0.9815 Validation Accuracy: 0.566600\n",
      "Epoch 391, CIFAR-10 Batch 3:  Loss:     0.9584 Validation Accuracy: 0.567400\n",
      "Epoch 391, CIFAR-10 Batch 4:  Loss:     0.9399 Validation Accuracy: 0.560600\n",
      "Epoch 391, CIFAR-10 Batch 5:  Loss:     0.9567 Validation Accuracy: 0.561200\n",
      "Epoch 392, CIFAR-10 Batch 1:  Loss:     0.9550 Validation Accuracy: 0.560800\n",
      "Epoch 392, CIFAR-10 Batch 2:  Loss:     0.9921 Validation Accuracy: 0.560600\n",
      "Epoch 392, CIFAR-10 Batch 3:  Loss:     0.9598 Validation Accuracy: 0.568800\n",
      "Epoch 392, CIFAR-10 Batch 4:  Loss:     0.9304 Validation Accuracy: 0.563600\n",
      "Epoch 392, CIFAR-10 Batch 5:  Loss:     0.9558 Validation Accuracy: 0.562200\n",
      "Epoch 393, CIFAR-10 Batch 1:  Loss:     0.9563 Validation Accuracy: 0.557400\n",
      "Epoch 393, CIFAR-10 Batch 2:  Loss:     0.9844 Validation Accuracy: 0.565400\n",
      "Epoch 393, CIFAR-10 Batch 3:  Loss:     0.9620 Validation Accuracy: 0.564000\n",
      "Epoch 393, CIFAR-10 Batch 4:  Loss:     0.9271 Validation Accuracy: 0.564600\n",
      "Epoch 393, CIFAR-10 Batch 5:  Loss:     0.9516 Validation Accuracy: 0.563600\n",
      "Epoch 394, CIFAR-10 Batch 1:  Loss:     0.9643 Validation Accuracy: 0.557600\n",
      "Epoch 394, CIFAR-10 Batch 2:  Loss:     0.9830 Validation Accuracy: 0.570600\n",
      "Epoch 394, CIFAR-10 Batch 3:  Loss:     0.9612 Validation Accuracy: 0.562600\n",
      "Epoch 394, CIFAR-10 Batch 4:  Loss:     0.9299 Validation Accuracy: 0.560800\n",
      "Epoch 394, CIFAR-10 Batch 5:  Loss:     0.9498 Validation Accuracy: 0.565200\n",
      "Epoch 395, CIFAR-10 Batch 1:  Loss:     0.9613 Validation Accuracy: 0.558400\n",
      "Epoch 395, CIFAR-10 Batch 2:  Loss:     0.9815 Validation Accuracy: 0.562800\n",
      "Epoch 395, CIFAR-10 Batch 3:  Loss:     0.9589 Validation Accuracy: 0.562400\n",
      "Epoch 395, CIFAR-10 Batch 4:  Loss:     0.9283 Validation Accuracy: 0.564000\n",
      "Epoch 395, CIFAR-10 Batch 5:  Loss:     0.9481 Validation Accuracy: 0.563800\n",
      "Epoch 396, CIFAR-10 Batch 1:  Loss:     0.9632 Validation Accuracy: 0.559000\n",
      "Epoch 396, CIFAR-10 Batch 2:  Loss:     0.9793 Validation Accuracy: 0.564400\n",
      "Epoch 396, CIFAR-10 Batch 3:  Loss:     0.9582 Validation Accuracy: 0.562400\n",
      "Epoch 396, CIFAR-10 Batch 4:  Loss:     0.9303 Validation Accuracy: 0.559000\n",
      "Epoch 396, CIFAR-10 Batch 5:  Loss:     0.9483 Validation Accuracy: 0.564400\n",
      "Epoch 397, CIFAR-10 Batch 1:  Loss:     0.9510 Validation Accuracy: 0.559600\n",
      "Epoch 397, CIFAR-10 Batch 2:  Loss:     0.9758 Validation Accuracy: 0.563600\n",
      "Epoch 397, CIFAR-10 Batch 3:  Loss:     0.9594 Validation Accuracy: 0.562000\n",
      "Epoch 397, CIFAR-10 Batch 4:  Loss:     0.9263 Validation Accuracy: 0.559200\n",
      "Epoch 397, CIFAR-10 Batch 5:  Loss:     0.9457 Validation Accuracy: 0.563000\n",
      "Epoch 398, CIFAR-10 Batch 1:  Loss:     0.9549 Validation Accuracy: 0.560000\n",
      "Epoch 398, CIFAR-10 Batch 2:  Loss:     0.9780 Validation Accuracy: 0.570200\n",
      "Epoch 398, CIFAR-10 Batch 3:  Loss:     0.9563 Validation Accuracy: 0.566000\n",
      "Epoch 398, CIFAR-10 Batch 4:  Loss:     0.9292 Validation Accuracy: 0.560400\n",
      "Epoch 398, CIFAR-10 Batch 5:  Loss:     0.9549 Validation Accuracy: 0.558800\n",
      "Epoch 399, CIFAR-10 Batch 1:  Loss:     0.9578 Validation Accuracy: 0.558400\n",
      "Epoch 399, CIFAR-10 Batch 2:  Loss:     0.9890 Validation Accuracy: 0.562400\n",
      "Epoch 399, CIFAR-10 Batch 3:  Loss:     0.9599 Validation Accuracy: 0.565000\n",
      "Epoch 399, CIFAR-10 Batch 4:  Loss:     0.9340 Validation Accuracy: 0.564200\n",
      "Epoch 399, CIFAR-10 Batch 5:  Loss:     0.9464 Validation Accuracy: 0.562600\n",
      "Epoch 400, CIFAR-10 Batch 1:  Loss:     0.9482 Validation Accuracy: 0.564000\n",
      "Epoch 400, CIFAR-10 Batch 2:  Loss:     0.9863 Validation Accuracy: 0.560000\n",
      "Epoch 400, CIFAR-10 Batch 3:  Loss:     0.9534 Validation Accuracy: 0.565800\n",
      "Epoch 400, CIFAR-10 Batch 4:  Loss:     0.9302 Validation Accuracy: 0.564200\n",
      "Epoch 400, CIFAR-10 Batch 5:  Loss:     0.9439 Validation Accuracy: 0.562800\n",
      "Epoch 401, CIFAR-10 Batch 1:  Loss:     0.9465 Validation Accuracy: 0.559800\n",
      "Epoch 401, CIFAR-10 Batch 2:  Loss:     0.9775 Validation Accuracy: 0.561400\n",
      "Epoch 401, CIFAR-10 Batch 3:  Loss:     0.9544 Validation Accuracy: 0.564400\n",
      "Epoch 401, CIFAR-10 Batch 4:  Loss:     0.9266 Validation Accuracy: 0.560200\n",
      "Epoch 401, CIFAR-10 Batch 5:  Loss:     0.9455 Validation Accuracy: 0.562600\n",
      "Epoch 402, CIFAR-10 Batch 1:  Loss:     0.9513 Validation Accuracy: 0.560800\n",
      "Epoch 402, CIFAR-10 Batch 2:  Loss:     0.9848 Validation Accuracy: 0.562800\n",
      "Epoch 402, CIFAR-10 Batch 3:  Loss:     0.9568 Validation Accuracy: 0.567800\n",
      "Epoch 402, CIFAR-10 Batch 4:  Loss:     0.9257 Validation Accuracy: 0.562600\n",
      "Epoch 402, CIFAR-10 Batch 5:  Loss:     0.9441 Validation Accuracy: 0.562000\n",
      "Epoch 403, CIFAR-10 Batch 1:  Loss:     0.9384 Validation Accuracy: 0.562800\n",
      "Epoch 403, CIFAR-10 Batch 2:  Loss:     0.9773 Validation Accuracy: 0.562600\n",
      "Epoch 403, CIFAR-10 Batch 3:  Loss:     0.9509 Validation Accuracy: 0.561400\n",
      "Epoch 403, CIFAR-10 Batch 4:  Loss:     0.9256 Validation Accuracy: 0.556400\n",
      "Epoch 403, CIFAR-10 Batch 5:  Loss:     0.9470 Validation Accuracy: 0.560000\n",
      "Epoch 404, CIFAR-10 Batch 1:  Loss:     0.9461 Validation Accuracy: 0.560200\n",
      "Epoch 404, CIFAR-10 Batch 2:  Loss:     0.9783 Validation Accuracy: 0.565800\n",
      "Epoch 404, CIFAR-10 Batch 3:  Loss:     0.9491 Validation Accuracy: 0.561600\n",
      "Epoch 404, CIFAR-10 Batch 4:  Loss:     0.9244 Validation Accuracy: 0.560800\n",
      "Epoch 404, CIFAR-10 Batch 5:  Loss:     0.9392 Validation Accuracy: 0.561600\n",
      "Epoch 405, CIFAR-10 Batch 1:  Loss:     0.9414 Validation Accuracy: 0.561600\n",
      "Epoch 405, CIFAR-10 Batch 2:  Loss:     0.9776 Validation Accuracy: 0.563600\n",
      "Epoch 405, CIFAR-10 Batch 3:  Loss:     0.9466 Validation Accuracy: 0.565600\n",
      "Epoch 405, CIFAR-10 Batch 4:  Loss:     0.9238 Validation Accuracy: 0.565200\n",
      "Epoch 405, CIFAR-10 Batch 5:  Loss:     0.9399 Validation Accuracy: 0.563200\n",
      "Epoch 406, CIFAR-10 Batch 1:  Loss:     0.9413 Validation Accuracy: 0.560400\n",
      "Epoch 406, CIFAR-10 Batch 2:  Loss:     0.9774 Validation Accuracy: 0.561800\n",
      "Epoch 406, CIFAR-10 Batch 3:  Loss:     0.9454 Validation Accuracy: 0.568200\n",
      "Epoch 406, CIFAR-10 Batch 4:  Loss:     0.9204 Validation Accuracy: 0.562600\n",
      "Epoch 406, CIFAR-10 Batch 5:  Loss:     0.9407 Validation Accuracy: 0.564200\n",
      "Epoch 407, CIFAR-10 Batch 1:  Loss:     0.9390 Validation Accuracy: 0.564800\n",
      "Epoch 407, CIFAR-10 Batch 2:  Loss:     0.9680 Validation Accuracy: 0.567200\n",
      "Epoch 407, CIFAR-10 Batch 3:  Loss:     0.9459 Validation Accuracy: 0.566600\n",
      "Epoch 407, CIFAR-10 Batch 4:  Loss:     0.9200 Validation Accuracy: 0.562400\n",
      "Epoch 407, CIFAR-10 Batch 5:  Loss:     0.9391 Validation Accuracy: 0.564800\n",
      "Epoch 408, CIFAR-10 Batch 1:  Loss:     0.9393 Validation Accuracy: 0.564000\n",
      "Epoch 408, CIFAR-10 Batch 2:  Loss:     0.9702 Validation Accuracy: 0.566000\n",
      "Epoch 408, CIFAR-10 Batch 3:  Loss:     0.9448 Validation Accuracy: 0.568000\n",
      "Epoch 408, CIFAR-10 Batch 4:  Loss:     0.9216 Validation Accuracy: 0.561800\n",
      "Epoch 408, CIFAR-10 Batch 5:  Loss:     0.9373 Validation Accuracy: 0.565600\n",
      "Epoch 409, CIFAR-10 Batch 1:  Loss:     0.9369 Validation Accuracy: 0.562800\n",
      "Epoch 409, CIFAR-10 Batch 2:  Loss:     0.9722 Validation Accuracy: 0.563200\n",
      "Epoch 409, CIFAR-10 Batch 3:  Loss:     0.9478 Validation Accuracy: 0.569000\n",
      "Epoch 409, CIFAR-10 Batch 4:  Loss:     0.9226 Validation Accuracy: 0.564600\n",
      "Epoch 409, CIFAR-10 Batch 5:  Loss:     0.9401 Validation Accuracy: 0.558000\n",
      "Epoch 410, CIFAR-10 Batch 1:  Loss:     0.9419 Validation Accuracy: 0.562400\n",
      "Epoch 410, CIFAR-10 Batch 2:  Loss:     0.9759 Validation Accuracy: 0.562200\n",
      "Epoch 410, CIFAR-10 Batch 3:  Loss:     0.9444 Validation Accuracy: 0.570000\n",
      "Epoch 410, CIFAR-10 Batch 4:  Loss:     0.9231 Validation Accuracy: 0.564200\n",
      "Epoch 410, CIFAR-10 Batch 5:  Loss:     0.9369 Validation Accuracy: 0.559600\n",
      "Epoch 411, CIFAR-10 Batch 1:  Loss:     0.9426 Validation Accuracy: 0.561800\n",
      "Epoch 411, CIFAR-10 Batch 2:  Loss:     0.9943 Validation Accuracy: 0.552000\n",
      "Epoch 411, CIFAR-10 Batch 3:  Loss:     0.9603 Validation Accuracy: 0.560200\n",
      "Epoch 411, CIFAR-10 Batch 4:  Loss:     0.9462 Validation Accuracy: 0.558200\n",
      "Epoch 411, CIFAR-10 Batch 5:  Loss:     0.9448 Validation Accuracy: 0.557600\n",
      "Epoch 412, CIFAR-10 Batch 1:  Loss:     0.9356 Validation Accuracy: 0.562200\n",
      "Epoch 412, CIFAR-10 Batch 2:  Loss:     0.9843 Validation Accuracy: 0.551600\n",
      "Epoch 412, CIFAR-10 Batch 3:  Loss:     0.9474 Validation Accuracy: 0.567000\n",
      "Epoch 412, CIFAR-10 Batch 4:  Loss:     0.9422 Validation Accuracy: 0.553400\n",
      "Epoch 412, CIFAR-10 Batch 5:  Loss:     0.9600 Validation Accuracy: 0.557800\n",
      "Epoch 413, CIFAR-10 Batch 1:  Loss:     0.9291 Validation Accuracy: 0.564200\n",
      "Epoch 413, CIFAR-10 Batch 2:  Loss:     0.9840 Validation Accuracy: 0.554800\n",
      "Epoch 413, CIFAR-10 Batch 3:  Loss:     0.9530 Validation Accuracy: 0.561200\n",
      "Epoch 413, CIFAR-10 Batch 4:  Loss:     0.9350 Validation Accuracy: 0.563600\n",
      "Epoch 413, CIFAR-10 Batch 5:  Loss:     0.9395 Validation Accuracy: 0.564000\n",
      "Epoch 414, CIFAR-10 Batch 1:  Loss:     0.9324 Validation Accuracy: 0.562200\n",
      "Epoch 414, CIFAR-10 Batch 2:  Loss:     0.9779 Validation Accuracy: 0.556800\n",
      "Epoch 414, CIFAR-10 Batch 3:  Loss:     0.9429 Validation Accuracy: 0.567600\n",
      "Epoch 414, CIFAR-10 Batch 4:  Loss:     0.9199 Validation Accuracy: 0.563000\n",
      "Epoch 414, CIFAR-10 Batch 5:  Loss:     0.9342 Validation Accuracy: 0.563200\n",
      "Epoch 415, CIFAR-10 Batch 1:  Loss:     0.9256 Validation Accuracy: 0.565000\n",
      "Epoch 415, CIFAR-10 Batch 2:  Loss:     0.9710 Validation Accuracy: 0.560800\n",
      "Epoch 415, CIFAR-10 Batch 3:  Loss:     0.9408 Validation Accuracy: 0.568000\n",
      "Epoch 415, CIFAR-10 Batch 4:  Loss:     0.9193 Validation Accuracy: 0.563800\n",
      "Epoch 415, CIFAR-10 Batch 5:  Loss:     0.9303 Validation Accuracy: 0.564000\n",
      "Epoch 416, CIFAR-10 Batch 1:  Loss:     0.9265 Validation Accuracy: 0.567000\n",
      "Epoch 416, CIFAR-10 Batch 2:  Loss:     0.9746 Validation Accuracy: 0.561600\n",
      "Epoch 416, CIFAR-10 Batch 3:  Loss:     0.9477 Validation Accuracy: 0.568600\n",
      "Epoch 416, CIFAR-10 Batch 4:  Loss:     0.9231 Validation Accuracy: 0.567000\n",
      "Epoch 416, CIFAR-10 Batch 5:  Loss:     0.9379 Validation Accuracy: 0.557000\n",
      "Epoch 417, CIFAR-10 Batch 1:  Loss:     0.9270 Validation Accuracy: 0.565600\n",
      "Epoch 417, CIFAR-10 Batch 2:  Loss:     0.9787 Validation Accuracy: 0.559400\n",
      "Epoch 417, CIFAR-10 Batch 3:  Loss:     0.9481 Validation Accuracy: 0.568600\n",
      "Epoch 417, CIFAR-10 Batch 4:  Loss:     0.9169 Validation Accuracy: 0.563200\n",
      "Epoch 417, CIFAR-10 Batch 5:  Loss:     0.9339 Validation Accuracy: 0.559200\n",
      "Epoch 418, CIFAR-10 Batch 1:  Loss:     0.9299 Validation Accuracy: 0.562000\n",
      "Epoch 418, CIFAR-10 Batch 2:  Loss:     0.9685 Validation Accuracy: 0.560200\n",
      "Epoch 418, CIFAR-10 Batch 3:  Loss:     0.9374 Validation Accuracy: 0.569200\n",
      "Epoch 418, CIFAR-10 Batch 4:  Loss:     0.9116 Validation Accuracy: 0.562800\n",
      "Epoch 418, CIFAR-10 Batch 5:  Loss:     0.9377 Validation Accuracy: 0.557400\n",
      "Epoch 419, CIFAR-10 Batch 1:  Loss:     0.9242 Validation Accuracy: 0.564000\n",
      "Epoch 419, CIFAR-10 Batch 2:  Loss:     0.9686 Validation Accuracy: 0.563400\n",
      "Epoch 419, CIFAR-10 Batch 3:  Loss:     0.9393 Validation Accuracy: 0.568200\n",
      "Epoch 419, CIFAR-10 Batch 4:  Loss:     0.9130 Validation Accuracy: 0.565800\n",
      "Epoch 419, CIFAR-10 Batch 5:  Loss:     0.9364 Validation Accuracy: 0.558400\n",
      "Epoch 420, CIFAR-10 Batch 1:  Loss:     0.9249 Validation Accuracy: 0.566000\n",
      "Epoch 420, CIFAR-10 Batch 2:  Loss:     0.9648 Validation Accuracy: 0.563800\n",
      "Epoch 420, CIFAR-10 Batch 3:  Loss:     0.9403 Validation Accuracy: 0.567000\n",
      "Epoch 420, CIFAR-10 Batch 4:  Loss:     0.9178 Validation Accuracy: 0.563800\n",
      "Epoch 420, CIFAR-10 Batch 5:  Loss:     0.9335 Validation Accuracy: 0.561000\n",
      "Epoch 421, CIFAR-10 Batch 1:  Loss:     0.9299 Validation Accuracy: 0.561200\n",
      "Epoch 421, CIFAR-10 Batch 2:  Loss:     0.9763 Validation Accuracy: 0.559200\n",
      "Epoch 421, CIFAR-10 Batch 3:  Loss:     0.9408 Validation Accuracy: 0.570400\n",
      "Epoch 421, CIFAR-10 Batch 4:  Loss:     0.9193 Validation Accuracy: 0.562800\n",
      "Epoch 421, CIFAR-10 Batch 5:  Loss:     0.9296 Validation Accuracy: 0.565800\n",
      "Epoch 422, CIFAR-10 Batch 1:  Loss:     0.9203 Validation Accuracy: 0.565000\n",
      "Epoch 422, CIFAR-10 Batch 2:  Loss:     0.9650 Validation Accuracy: 0.563200\n",
      "Epoch 422, CIFAR-10 Batch 3:  Loss:     0.9367 Validation Accuracy: 0.569000\n",
      "Epoch 422, CIFAR-10 Batch 4:  Loss:     0.9146 Validation Accuracy: 0.564800\n",
      "Epoch 422, CIFAR-10 Batch 5:  Loss:     0.9311 Validation Accuracy: 0.564000\n",
      "Epoch 423, CIFAR-10 Batch 1:  Loss:     0.9243 Validation Accuracy: 0.563600\n",
      "Epoch 423, CIFAR-10 Batch 2:  Loss:     0.9699 Validation Accuracy: 0.563200\n",
      "Epoch 423, CIFAR-10 Batch 3:  Loss:     0.9394 Validation Accuracy: 0.568400\n",
      "Epoch 423, CIFAR-10 Batch 4:  Loss:     0.9194 Validation Accuracy: 0.566600\n",
      "Epoch 423, CIFAR-10 Batch 5:  Loss:     0.9286 Validation Accuracy: 0.560600\n",
      "Epoch 424, CIFAR-10 Batch 1:  Loss:     0.9186 Validation Accuracy: 0.568000\n",
      "Epoch 424, CIFAR-10 Batch 2:  Loss:     0.9628 Validation Accuracy: 0.562000\n",
      "Epoch 424, CIFAR-10 Batch 3:  Loss:     0.9395 Validation Accuracy: 0.568400\n",
      "Epoch 424, CIFAR-10 Batch 4:  Loss:     0.9132 Validation Accuracy: 0.562200\n",
      "Epoch 424, CIFAR-10 Batch 5:  Loss:     0.9221 Validation Accuracy: 0.564400\n",
      "Epoch 425, CIFAR-10 Batch 1:  Loss:     0.9137 Validation Accuracy: 0.567600\n",
      "Epoch 425, CIFAR-10 Batch 2:  Loss:     0.9611 Validation Accuracy: 0.565200\n",
      "Epoch 425, CIFAR-10 Batch 3:  Loss:     0.9372 Validation Accuracy: 0.571200\n",
      "Epoch 425, CIFAR-10 Batch 4:  Loss:     0.9131 Validation Accuracy: 0.563000\n",
      "Epoch 425, CIFAR-10 Batch 5:  Loss:     0.9270 Validation Accuracy: 0.562200\n",
      "Epoch 426, CIFAR-10 Batch 1:  Loss:     0.9213 Validation Accuracy: 0.566400\n",
      "Epoch 426, CIFAR-10 Batch 2:  Loss:     0.9680 Validation Accuracy: 0.559200\n",
      "Epoch 426, CIFAR-10 Batch 3:  Loss:     0.9367 Validation Accuracy: 0.568600\n",
      "Epoch 426, CIFAR-10 Batch 4:  Loss:     0.9124 Validation Accuracy: 0.560200\n",
      "Epoch 426, CIFAR-10 Batch 5:  Loss:     0.9304 Validation Accuracy: 0.556600\n",
      "Epoch 427, CIFAR-10 Batch 1:  Loss:     0.9251 Validation Accuracy: 0.562000\n",
      "Epoch 427, CIFAR-10 Batch 2:  Loss:     0.9847 Validation Accuracy: 0.549800\n",
      "Epoch 427, CIFAR-10 Batch 3:  Loss:     0.9451 Validation Accuracy: 0.566800\n",
      "Epoch 427, CIFAR-10 Batch 4:  Loss:     0.9133 Validation Accuracy: 0.560600\n",
      "Epoch 427, CIFAR-10 Batch 5:  Loss:     0.9281 Validation Accuracy: 0.561200\n",
      "Epoch 428, CIFAR-10 Batch 1:  Loss:     0.9209 Validation Accuracy: 0.565600\n",
      "Epoch 428, CIFAR-10 Batch 2:  Loss:     0.9762 Validation Accuracy: 0.553600\n",
      "Epoch 428, CIFAR-10 Batch 3:  Loss:     0.9451 Validation Accuracy: 0.564600\n",
      "Epoch 428, CIFAR-10 Batch 4:  Loss:     0.9213 Validation Accuracy: 0.560800\n",
      "Epoch 428, CIFAR-10 Batch 5:  Loss:     0.9280 Validation Accuracy: 0.563000\n",
      "Epoch 429, CIFAR-10 Batch 1:  Loss:     0.9201 Validation Accuracy: 0.561600\n",
      "Epoch 429, CIFAR-10 Batch 2:  Loss:     0.9779 Validation Accuracy: 0.553400\n",
      "Epoch 429, CIFAR-10 Batch 3:  Loss:     0.9380 Validation Accuracy: 0.566800\n",
      "Epoch 429, CIFAR-10 Batch 4:  Loss:     0.9166 Validation Accuracy: 0.560600\n",
      "Epoch 429, CIFAR-10 Batch 5:  Loss:     0.9191 Validation Accuracy: 0.566600\n",
      "Epoch 430, CIFAR-10 Batch 1:  Loss:     0.9187 Validation Accuracy: 0.565600\n",
      "Epoch 430, CIFAR-10 Batch 2:  Loss:     0.9743 Validation Accuracy: 0.553600\n",
      "Epoch 430, CIFAR-10 Batch 3:  Loss:     0.9371 Validation Accuracy: 0.567400\n",
      "Epoch 430, CIFAR-10 Batch 4:  Loss:     0.9161 Validation Accuracy: 0.560200\n",
      "Epoch 430, CIFAR-10 Batch 5:  Loss:     0.9209 Validation Accuracy: 0.568600\n",
      "Epoch 431, CIFAR-10 Batch 1:  Loss:     0.9144 Validation Accuracy: 0.566800\n",
      "Epoch 431, CIFAR-10 Batch 2:  Loss:     0.9654 Validation Accuracy: 0.559600\n",
      "Epoch 431, CIFAR-10 Batch 3:  Loss:     0.9470 Validation Accuracy: 0.563400\n",
      "Epoch 431, CIFAR-10 Batch 4:  Loss:     0.9305 Validation Accuracy: 0.556400\n",
      "Epoch 431, CIFAR-10 Batch 5:  Loss:     0.9178 Validation Accuracy: 0.568800\n",
      "Epoch 432, CIFAR-10 Batch 1:  Loss:     0.9195 Validation Accuracy: 0.564400\n",
      "Epoch 432, CIFAR-10 Batch 2:  Loss:     0.9655 Validation Accuracy: 0.558200\n",
      "Epoch 432, CIFAR-10 Batch 3:  Loss:     0.9412 Validation Accuracy: 0.564000\n",
      "Epoch 432, CIFAR-10 Batch 4:  Loss:     0.9401 Validation Accuracy: 0.557200\n",
      "Epoch 432, CIFAR-10 Batch 5:  Loss:     0.9264 Validation Accuracy: 0.568200\n",
      "Epoch 433, CIFAR-10 Batch 1:  Loss:     0.9217 Validation Accuracy: 0.562600\n",
      "Epoch 433, CIFAR-10 Batch 2:  Loss:     0.9583 Validation Accuracy: 0.559200\n",
      "Epoch 433, CIFAR-10 Batch 3:  Loss:     0.9321 Validation Accuracy: 0.569400\n",
      "Epoch 433, CIFAR-10 Batch 4:  Loss:     0.9190 Validation Accuracy: 0.559800\n",
      "Epoch 433, CIFAR-10 Batch 5:  Loss:     0.9407 Validation Accuracy: 0.563200\n",
      "Epoch 434, CIFAR-10 Batch 1:  Loss:     0.9400 Validation Accuracy: 0.558800\n",
      "Epoch 434, CIFAR-10 Batch 2:  Loss:     0.9563 Validation Accuracy: 0.569000\n",
      "Epoch 434, CIFAR-10 Batch 3:  Loss:     0.9432 Validation Accuracy: 0.564800\n",
      "Epoch 434, CIFAR-10 Batch 4:  Loss:     0.9042 Validation Accuracy: 0.566600\n",
      "Epoch 434, CIFAR-10 Batch 5:  Loss:     0.9261 Validation Accuracy: 0.563000\n",
      "Epoch 435, CIFAR-10 Batch 1:  Loss:     0.9168 Validation Accuracy: 0.564800\n",
      "Epoch 435, CIFAR-10 Batch 2:  Loss:     0.9523 Validation Accuracy: 0.567200\n",
      "Epoch 435, CIFAR-10 Batch 3:  Loss:     0.9375 Validation Accuracy: 0.567200\n",
      "Epoch 435, CIFAR-10 Batch 4:  Loss:     0.9069 Validation Accuracy: 0.562400\n",
      "Epoch 435, CIFAR-10 Batch 5:  Loss:     0.9321 Validation Accuracy: 0.561600\n",
      "Epoch 436, CIFAR-10 Batch 1:  Loss:     0.9124 Validation Accuracy: 0.561600\n",
      "Epoch 436, CIFAR-10 Batch 2:  Loss:     0.9489 Validation Accuracy: 0.569800\n",
      "Epoch 436, CIFAR-10 Batch 3:  Loss:     0.9412 Validation Accuracy: 0.567000\n",
      "Epoch 436, CIFAR-10 Batch 4:  Loss:     0.9170 Validation Accuracy: 0.562600\n",
      "Epoch 436, CIFAR-10 Batch 5:  Loss:     0.9381 Validation Accuracy: 0.559200\n",
      "Epoch 437, CIFAR-10 Batch 1:  Loss:     0.9140 Validation Accuracy: 0.561400\n",
      "Epoch 437, CIFAR-10 Batch 2:  Loss:     0.9463 Validation Accuracy: 0.569000\n",
      "Epoch 437, CIFAR-10 Batch 3:  Loss:     0.9459 Validation Accuracy: 0.562000\n",
      "Epoch 437, CIFAR-10 Batch 4:  Loss:     0.9074 Validation Accuracy: 0.564000\n",
      "Epoch 437, CIFAR-10 Batch 5:  Loss:     0.9467 Validation Accuracy: 0.554400\n",
      "Epoch 438, CIFAR-10 Batch 1:  Loss:     0.9054 Validation Accuracy: 0.568600\n",
      "Epoch 438, CIFAR-10 Batch 2:  Loss:     0.9555 Validation Accuracy: 0.564800\n",
      "Epoch 438, CIFAR-10 Batch 3:  Loss:     0.9421 Validation Accuracy: 0.562800\n",
      "Epoch 438, CIFAR-10 Batch 4:  Loss:     0.9147 Validation Accuracy: 0.560000\n",
      "Epoch 438, CIFAR-10 Batch 5:  Loss:     0.9388 Validation Accuracy: 0.562600\n",
      "Epoch 439, CIFAR-10 Batch 1:  Loss:     0.9221 Validation Accuracy: 0.563000\n",
      "Epoch 439, CIFAR-10 Batch 2:  Loss:     0.9580 Validation Accuracy: 0.567400\n",
      "Epoch 439, CIFAR-10 Batch 3:  Loss:     0.9274 Validation Accuracy: 0.569200\n",
      "Epoch 439, CIFAR-10 Batch 4:  Loss:     0.9096 Validation Accuracy: 0.559600\n",
      "Epoch 439, CIFAR-10 Batch 5:  Loss:     0.9272 Validation Accuracy: 0.564400\n",
      "Epoch 440, CIFAR-10 Batch 1:  Loss:     0.9177 Validation Accuracy: 0.564800\n",
      "Epoch 440, CIFAR-10 Batch 2:  Loss:     0.9497 Validation Accuracy: 0.573600\n",
      "Epoch 440, CIFAR-10 Batch 3:  Loss:     0.9277 Validation Accuracy: 0.567200\n",
      "Epoch 440, CIFAR-10 Batch 4:  Loss:     0.9140 Validation Accuracy: 0.558400\n",
      "Epoch 440, CIFAR-10 Batch 5:  Loss:     0.9293 Validation Accuracy: 0.559800\n",
      "Epoch 441, CIFAR-10 Batch 1:  Loss:     0.9263 Validation Accuracy: 0.563800\n",
      "Epoch 441, CIFAR-10 Batch 2:  Loss:     0.9496 Validation Accuracy: 0.572200\n",
      "Epoch 441, CIFAR-10 Batch 3:  Loss:     0.9267 Validation Accuracy: 0.569000\n",
      "Epoch 441, CIFAR-10 Batch 4:  Loss:     0.9110 Validation Accuracy: 0.559800\n",
      "Epoch 441, CIFAR-10 Batch 5:  Loss:     0.9247 Validation Accuracy: 0.564200\n",
      "Epoch 442, CIFAR-10 Batch 1:  Loss:     0.9350 Validation Accuracy: 0.560800\n",
      "Epoch 442, CIFAR-10 Batch 2:  Loss:     0.9601 Validation Accuracy: 0.569600\n",
      "Epoch 442, CIFAR-10 Batch 3:  Loss:     0.9273 Validation Accuracy: 0.568600\n",
      "Epoch 442, CIFAR-10 Batch 4:  Loss:     0.9027 Validation Accuracy: 0.559200\n",
      "Epoch 442, CIFAR-10 Batch 5:  Loss:     0.9182 Validation Accuracy: 0.566000\n",
      "Epoch 443, CIFAR-10 Batch 1:  Loss:     0.9399 Validation Accuracy: 0.563400\n",
      "Epoch 443, CIFAR-10 Batch 2:  Loss:     0.9647 Validation Accuracy: 0.562600\n",
      "Epoch 443, CIFAR-10 Batch 3:  Loss:     0.9403 Validation Accuracy: 0.562600\n",
      "Epoch 443, CIFAR-10 Batch 4:  Loss:     0.8964 Validation Accuracy: 0.561400\n",
      "Epoch 443, CIFAR-10 Batch 5:  Loss:     0.9186 Validation Accuracy: 0.567800\n",
      "Epoch 444, CIFAR-10 Batch 1:  Loss:     0.9349 Validation Accuracy: 0.560400\n",
      "Epoch 444, CIFAR-10 Batch 2:  Loss:     0.9463 Validation Accuracy: 0.573400\n",
      "Epoch 444, CIFAR-10 Batch 3:  Loss:     0.9325 Validation Accuracy: 0.564200\n",
      "Epoch 444, CIFAR-10 Batch 4:  Loss:     0.8979 Validation Accuracy: 0.559600\n",
      "Epoch 444, CIFAR-10 Batch 5:  Loss:     0.9110 Validation Accuracy: 0.567400\n",
      "Epoch 445, CIFAR-10 Batch 1:  Loss:     0.9290 Validation Accuracy: 0.562000\n",
      "Epoch 445, CIFAR-10 Batch 2:  Loss:     0.9489 Validation Accuracy: 0.563000\n",
      "Epoch 445, CIFAR-10 Batch 3:  Loss:     0.9322 Validation Accuracy: 0.565200\n",
      "Epoch 445, CIFAR-10 Batch 4:  Loss:     0.8952 Validation Accuracy: 0.563200\n",
      "Epoch 445, CIFAR-10 Batch 5:  Loss:     0.9087 Validation Accuracy: 0.567400\n",
      "Epoch 446, CIFAR-10 Batch 1:  Loss:     0.9192 Validation Accuracy: 0.561600\n",
      "Epoch 446, CIFAR-10 Batch 2:  Loss:     0.9443 Validation Accuracy: 0.568400\n",
      "Epoch 446, CIFAR-10 Batch 3:  Loss:     0.9229 Validation Accuracy: 0.567600\n",
      "Epoch 446, CIFAR-10 Batch 4:  Loss:     0.8927 Validation Accuracy: 0.563000\n",
      "Epoch 446, CIFAR-10 Batch 5:  Loss:     0.9104 Validation Accuracy: 0.568800\n",
      "Epoch 447, CIFAR-10 Batch 1:  Loss:     0.9151 Validation Accuracy: 0.563400\n",
      "Epoch 447, CIFAR-10 Batch 2:  Loss:     0.9535 Validation Accuracy: 0.563400\n",
      "Epoch 447, CIFAR-10 Batch 3:  Loss:     0.9231 Validation Accuracy: 0.565600\n",
      "Epoch 447, CIFAR-10 Batch 4:  Loss:     0.8929 Validation Accuracy: 0.563800\n",
      "Epoch 447, CIFAR-10 Batch 5:  Loss:     0.9165 Validation Accuracy: 0.568400\n",
      "Epoch 448, CIFAR-10 Batch 1:  Loss:     0.9070 Validation Accuracy: 0.566200\n",
      "Epoch 448, CIFAR-10 Batch 2:  Loss:     0.9370 Validation Accuracy: 0.568600\n",
      "Epoch 448, CIFAR-10 Batch 3:  Loss:     0.9200 Validation Accuracy: 0.570600\n",
      "Epoch 448, CIFAR-10 Batch 4:  Loss:     0.8940 Validation Accuracy: 0.564000\n",
      "Epoch 448, CIFAR-10 Batch 5:  Loss:     0.9111 Validation Accuracy: 0.566800\n",
      "Epoch 449, CIFAR-10 Batch 1:  Loss:     0.9006 Validation Accuracy: 0.565000\n",
      "Epoch 449, CIFAR-10 Batch 2:  Loss:     0.9362 Validation Accuracy: 0.567400\n",
      "Epoch 449, CIFAR-10 Batch 3:  Loss:     0.9165 Validation Accuracy: 0.573200\n",
      "Epoch 449, CIFAR-10 Batch 4:  Loss:     0.8950 Validation Accuracy: 0.564200\n",
      "Epoch 449, CIFAR-10 Batch 5:  Loss:     0.9115 Validation Accuracy: 0.567200\n",
      "Epoch 450, CIFAR-10 Batch 1:  Loss:     0.9063 Validation Accuracy: 0.565400\n",
      "Epoch 450, CIFAR-10 Batch 2:  Loss:     0.9365 Validation Accuracy: 0.570800\n",
      "Epoch 450, CIFAR-10 Batch 3:  Loss:     0.9175 Validation Accuracy: 0.568400\n",
      "Epoch 450, CIFAR-10 Batch 4:  Loss:     0.8992 Validation Accuracy: 0.563000\n",
      "Epoch 450, CIFAR-10 Batch 5:  Loss:     0.9170 Validation Accuracy: 0.571200\n",
      "Epoch 451, CIFAR-10 Batch 1:  Loss:     0.9125 Validation Accuracy: 0.565200\n",
      "Epoch 451, CIFAR-10 Batch 2:  Loss:     0.9333 Validation Accuracy: 0.570400\n",
      "Epoch 451, CIFAR-10 Batch 3:  Loss:     0.9160 Validation Accuracy: 0.570400\n",
      "Epoch 451, CIFAR-10 Batch 4:  Loss:     0.8980 Validation Accuracy: 0.563600\n",
      "Epoch 451, CIFAR-10 Batch 5:  Loss:     0.9148 Validation Accuracy: 0.568000\n",
      "Epoch 452, CIFAR-10 Batch 1:  Loss:     0.9082 Validation Accuracy: 0.567200\n",
      "Epoch 452, CIFAR-10 Batch 2:  Loss:     0.9372 Validation Accuracy: 0.567200\n",
      "Epoch 452, CIFAR-10 Batch 3:  Loss:     0.9141 Validation Accuracy: 0.571000\n",
      "Epoch 452, CIFAR-10 Batch 4:  Loss:     0.8954 Validation Accuracy: 0.562800\n",
      "Epoch 452, CIFAR-10 Batch 5:  Loss:     0.9026 Validation Accuracy: 0.569000\n",
      "Epoch 453, CIFAR-10 Batch 1:  Loss:     0.9041 Validation Accuracy: 0.567000\n",
      "Epoch 453, CIFAR-10 Batch 2:  Loss:     0.9474 Validation Accuracy: 0.564400\n",
      "Epoch 453, CIFAR-10 Batch 3:  Loss:     0.9164 Validation Accuracy: 0.571600\n",
      "Epoch 453, CIFAR-10 Batch 4:  Loss:     0.8958 Validation Accuracy: 0.562600\n",
      "Epoch 453, CIFAR-10 Batch 5:  Loss:     0.9017 Validation Accuracy: 0.565200\n",
      "Epoch 454, CIFAR-10 Batch 1:  Loss:     0.9063 Validation Accuracy: 0.564800\n",
      "Epoch 454, CIFAR-10 Batch 2:  Loss:     0.9534 Validation Accuracy: 0.563000\n",
      "Epoch 454, CIFAR-10 Batch 3:  Loss:     0.9253 Validation Accuracy: 0.565400\n",
      "Epoch 454, CIFAR-10 Batch 4:  Loss:     0.8874 Validation Accuracy: 0.563000\n",
      "Epoch 454, CIFAR-10 Batch 5:  Loss:     0.9036 Validation Accuracy: 0.565000\n",
      "Epoch 455, CIFAR-10 Batch 1:  Loss:     0.9074 Validation Accuracy: 0.568200\n",
      "Epoch 455, CIFAR-10 Batch 2:  Loss:     0.9410 Validation Accuracy: 0.562800\n",
      "Epoch 455, CIFAR-10 Batch 3:  Loss:     0.9139 Validation Accuracy: 0.571000\n",
      "Epoch 455, CIFAR-10 Batch 4:  Loss:     0.8875 Validation Accuracy: 0.564200\n",
      "Epoch 455, CIFAR-10 Batch 5:  Loss:     0.9004 Validation Accuracy: 0.569400\n",
      "Epoch 456, CIFAR-10 Batch 1:  Loss:     0.9031 Validation Accuracy: 0.565800\n",
      "Epoch 456, CIFAR-10 Batch 2:  Loss:     0.9330 Validation Accuracy: 0.569200\n",
      "Epoch 456, CIFAR-10 Batch 3:  Loss:     0.9104 Validation Accuracy: 0.573000\n",
      "Epoch 456, CIFAR-10 Batch 4:  Loss:     0.8977 Validation Accuracy: 0.563200\n",
      "Epoch 456, CIFAR-10 Batch 5:  Loss:     0.9045 Validation Accuracy: 0.569600\n",
      "Epoch 457, CIFAR-10 Batch 1:  Loss:     0.9071 Validation Accuracy: 0.566000\n",
      "Epoch 457, CIFAR-10 Batch 2:  Loss:     0.9422 Validation Accuracy: 0.564200\n",
      "Epoch 457, CIFAR-10 Batch 3:  Loss:     0.9132 Validation Accuracy: 0.570000\n",
      "Epoch 457, CIFAR-10 Batch 4:  Loss:     0.8892 Validation Accuracy: 0.564400\n",
      "Epoch 457, CIFAR-10 Batch 5:  Loss:     0.8973 Validation Accuracy: 0.571000\n",
      "Epoch 458, CIFAR-10 Batch 1:  Loss:     0.9044 Validation Accuracy: 0.565400\n",
      "Epoch 458, CIFAR-10 Batch 2:  Loss:     0.9372 Validation Accuracy: 0.567000\n",
      "Epoch 458, CIFAR-10 Batch 3:  Loss:     0.9120 Validation Accuracy: 0.572800\n",
      "Epoch 458, CIFAR-10 Batch 4:  Loss:     0.8923 Validation Accuracy: 0.562600\n",
      "Epoch 458, CIFAR-10 Batch 5:  Loss:     0.8987 Validation Accuracy: 0.569000\n",
      "Epoch 459, CIFAR-10 Batch 1:  Loss:     0.9055 Validation Accuracy: 0.567800\n",
      "Epoch 459, CIFAR-10 Batch 2:  Loss:     0.9402 Validation Accuracy: 0.560600\n",
      "Epoch 459, CIFAR-10 Batch 3:  Loss:     0.9134 Validation Accuracy: 0.565400\n",
      "Epoch 459, CIFAR-10 Batch 4:  Loss:     0.8927 Validation Accuracy: 0.563800\n",
      "Epoch 459, CIFAR-10 Batch 5:  Loss:     0.8972 Validation Accuracy: 0.570600\n",
      "Epoch 460, CIFAR-10 Batch 1:  Loss:     0.9155 Validation Accuracy: 0.562000\n",
      "Epoch 460, CIFAR-10 Batch 2:  Loss:     0.9413 Validation Accuracy: 0.562000\n",
      "Epoch 460, CIFAR-10 Batch 3:  Loss:     0.9114 Validation Accuracy: 0.566800\n",
      "Epoch 460, CIFAR-10 Batch 4:  Loss:     0.8886 Validation Accuracy: 0.566000\n",
      "Epoch 460, CIFAR-10 Batch 5:  Loss:     0.8973 Validation Accuracy: 0.571000\n",
      "Epoch 461, CIFAR-10 Batch 1:  Loss:     0.8957 Validation Accuracy: 0.568200\n",
      "Epoch 461, CIFAR-10 Batch 2:  Loss:     0.9348 Validation Accuracy: 0.565000\n",
      "Epoch 461, CIFAR-10 Batch 3:  Loss:     0.9083 Validation Accuracy: 0.569400\n",
      "Epoch 461, CIFAR-10 Batch 4:  Loss:     0.8853 Validation Accuracy: 0.564400\n",
      "Epoch 461, CIFAR-10 Batch 5:  Loss:     0.8943 Validation Accuracy: 0.569800\n",
      "Epoch 462, CIFAR-10 Batch 1:  Loss:     0.8948 Validation Accuracy: 0.566800\n",
      "Epoch 462, CIFAR-10 Batch 2:  Loss:     0.9315 Validation Accuracy: 0.566800\n",
      "Epoch 462, CIFAR-10 Batch 3:  Loss:     0.9053 Validation Accuracy: 0.572200\n",
      "Epoch 462, CIFAR-10 Batch 4:  Loss:     0.8827 Validation Accuracy: 0.565000\n",
      "Epoch 462, CIFAR-10 Batch 5:  Loss:     0.8962 Validation Accuracy: 0.571800\n",
      "Epoch 463, CIFAR-10 Batch 1:  Loss:     0.8925 Validation Accuracy: 0.566600\n",
      "Epoch 463, CIFAR-10 Batch 2:  Loss:     0.9336 Validation Accuracy: 0.564200\n",
      "Epoch 463, CIFAR-10 Batch 3:  Loss:     0.9063 Validation Accuracy: 0.571800\n",
      "Epoch 463, CIFAR-10 Batch 4:  Loss:     0.8856 Validation Accuracy: 0.566200\n",
      "Epoch 463, CIFAR-10 Batch 5:  Loss:     0.8934 Validation Accuracy: 0.571200\n",
      "Epoch 464, CIFAR-10 Batch 1:  Loss:     0.8958 Validation Accuracy: 0.568000\n",
      "Epoch 464, CIFAR-10 Batch 2:  Loss:     0.9270 Validation Accuracy: 0.570400\n",
      "Epoch 464, CIFAR-10 Batch 3:  Loss:     0.9038 Validation Accuracy: 0.569600\n",
      "Epoch 464, CIFAR-10 Batch 4:  Loss:     0.8842 Validation Accuracy: 0.567800\n",
      "Epoch 464, CIFAR-10 Batch 5:  Loss:     0.8927 Validation Accuracy: 0.571400\n",
      "Epoch 465, CIFAR-10 Batch 1:  Loss:     0.8959 Validation Accuracy: 0.567800\n",
      "Epoch 465, CIFAR-10 Batch 2:  Loss:     0.9273 Validation Accuracy: 0.569200\n",
      "Epoch 465, CIFAR-10 Batch 3:  Loss:     0.9029 Validation Accuracy: 0.571200\n",
      "Epoch 465, CIFAR-10 Batch 4:  Loss:     0.8866 Validation Accuracy: 0.565400\n",
      "Epoch 465, CIFAR-10 Batch 5:  Loss:     0.8938 Validation Accuracy: 0.570000\n",
      "Epoch 466, CIFAR-10 Batch 1:  Loss:     0.8971 Validation Accuracy: 0.565600\n",
      "Epoch 466, CIFAR-10 Batch 2:  Loss:     0.9304 Validation Accuracy: 0.566800\n",
      "Epoch 466, CIFAR-10 Batch 3:  Loss:     0.9015 Validation Accuracy: 0.570000\n",
      "Epoch 466, CIFAR-10 Batch 4:  Loss:     0.8826 Validation Accuracy: 0.565400\n",
      "Epoch 466, CIFAR-10 Batch 5:  Loss:     0.8944 Validation Accuracy: 0.572400\n",
      "Epoch 467, CIFAR-10 Batch 1:  Loss:     0.9083 Validation Accuracy: 0.566400\n",
      "Epoch 467, CIFAR-10 Batch 2:  Loss:     0.9366 Validation Accuracy: 0.567400\n",
      "Epoch 467, CIFAR-10 Batch 3:  Loss:     0.9040 Validation Accuracy: 0.572200\n",
      "Epoch 467, CIFAR-10 Batch 4:  Loss:     0.8831 Validation Accuracy: 0.566000\n",
      "Epoch 467, CIFAR-10 Batch 5:  Loss:     0.8911 Validation Accuracy: 0.570000\n",
      "Epoch 468, CIFAR-10 Batch 1:  Loss:     0.9000 Validation Accuracy: 0.567800\n",
      "Epoch 468, CIFAR-10 Batch 2:  Loss:     0.9378 Validation Accuracy: 0.563600\n",
      "Epoch 468, CIFAR-10 Batch 3:  Loss:     0.9066 Validation Accuracy: 0.570000\n",
      "Epoch 468, CIFAR-10 Batch 4:  Loss:     0.8848 Validation Accuracy: 0.568000\n",
      "Epoch 468, CIFAR-10 Batch 5:  Loss:     0.8881 Validation Accuracy: 0.571000\n",
      "Epoch 469, CIFAR-10 Batch 1:  Loss:     0.9054 Validation Accuracy: 0.561800\n",
      "Epoch 469, CIFAR-10 Batch 2:  Loss:     0.9529 Validation Accuracy: 0.551800\n",
      "Epoch 469, CIFAR-10 Batch 3:  Loss:     0.9209 Validation Accuracy: 0.559200\n",
      "Epoch 469, CIFAR-10 Batch 4:  Loss:     0.8832 Validation Accuracy: 0.565400\n",
      "Epoch 469, CIFAR-10 Batch 5:  Loss:     0.8868 Validation Accuracy: 0.570400\n",
      "Epoch 470, CIFAR-10 Batch 1:  Loss:     0.8857 Validation Accuracy: 0.568000\n",
      "Epoch 470, CIFAR-10 Batch 2:  Loss:     0.9403 Validation Accuracy: 0.555600\n",
      "Epoch 470, CIFAR-10 Batch 3:  Loss:     0.9066 Validation Accuracy: 0.568000\n",
      "Epoch 470, CIFAR-10 Batch 4:  Loss:     0.8800 Validation Accuracy: 0.567000\n",
      "Epoch 470, CIFAR-10 Batch 5:  Loss:     0.8902 Validation Accuracy: 0.573200\n",
      "Epoch 471, CIFAR-10 Batch 1:  Loss:     0.8848 Validation Accuracy: 0.569600\n",
      "Epoch 471, CIFAR-10 Batch 2:  Loss:     0.9326 Validation Accuracy: 0.561600\n",
      "Epoch 471, CIFAR-10 Batch 3:  Loss:     0.8976 Validation Accuracy: 0.570400\n",
      "Epoch 471, CIFAR-10 Batch 4:  Loss:     0.8853 Validation Accuracy: 0.565400\n",
      "Epoch 471, CIFAR-10 Batch 5:  Loss:     0.9075 Validation Accuracy: 0.570000\n",
      "Epoch 472, CIFAR-10 Batch 1:  Loss:     0.8974 Validation Accuracy: 0.568000\n",
      "Epoch 472, CIFAR-10 Batch 2:  Loss:     0.9221 Validation Accuracy: 0.571000\n",
      "Epoch 472, CIFAR-10 Batch 3:  Loss:     0.8984 Validation Accuracy: 0.568600\n",
      "Epoch 472, CIFAR-10 Batch 4:  Loss:     0.8849 Validation Accuracy: 0.567200\n",
      "Epoch 472, CIFAR-10 Batch 5:  Loss:     0.8964 Validation Accuracy: 0.572200\n",
      "Epoch 473, CIFAR-10 Batch 1:  Loss:     0.8923 Validation Accuracy: 0.568600\n",
      "Epoch 473, CIFAR-10 Batch 2:  Loss:     0.9217 Validation Accuracy: 0.569200\n",
      "Epoch 473, CIFAR-10 Batch 3:  Loss:     0.8969 Validation Accuracy: 0.571400\n",
      "Epoch 473, CIFAR-10 Batch 4:  Loss:     0.8863 Validation Accuracy: 0.565200\n",
      "Epoch 473, CIFAR-10 Batch 5:  Loss:     0.8892 Validation Accuracy: 0.575200\n",
      "Epoch 474, CIFAR-10 Batch 1:  Loss:     0.8855 Validation Accuracy: 0.570000\n",
      "Epoch 474, CIFAR-10 Batch 2:  Loss:     0.9294 Validation Accuracy: 0.563000\n",
      "Epoch 474, CIFAR-10 Batch 3:  Loss:     0.8980 Validation Accuracy: 0.572600\n",
      "Epoch 474, CIFAR-10 Batch 4:  Loss:     0.8828 Validation Accuracy: 0.566200\n",
      "Epoch 474, CIFAR-10 Batch 5:  Loss:     0.8910 Validation Accuracy: 0.572400\n",
      "Epoch 475, CIFAR-10 Batch 1:  Loss:     0.8872 Validation Accuracy: 0.566000\n",
      "Epoch 475, CIFAR-10 Batch 2:  Loss:     0.9314 Validation Accuracy: 0.561200\n",
      "Epoch 475, CIFAR-10 Batch 3:  Loss:     0.8959 Validation Accuracy: 0.574600\n",
      "Epoch 475, CIFAR-10 Batch 4:  Loss:     0.8899 Validation Accuracy: 0.567600\n",
      "Epoch 475, CIFAR-10 Batch 5:  Loss:     0.8922 Validation Accuracy: 0.571400\n",
      "Epoch 476, CIFAR-10 Batch 1:  Loss:     0.8798 Validation Accuracy: 0.568400\n",
      "Epoch 476, CIFAR-10 Batch 2:  Loss:     0.9207 Validation Accuracy: 0.571000\n",
      "Epoch 476, CIFAR-10 Batch 3:  Loss:     0.8939 Validation Accuracy: 0.572600\n",
      "Epoch 476, CIFAR-10 Batch 4:  Loss:     0.8804 Validation Accuracy: 0.565000\n",
      "Epoch 476, CIFAR-10 Batch 5:  Loss:     0.8862 Validation Accuracy: 0.575400\n",
      "Epoch 477, CIFAR-10 Batch 1:  Loss:     0.8838 Validation Accuracy: 0.569200\n",
      "Epoch 477, CIFAR-10 Batch 2:  Loss:     0.9299 Validation Accuracy: 0.562000\n",
      "Epoch 477, CIFAR-10 Batch 3:  Loss:     0.9032 Validation Accuracy: 0.568000\n",
      "Epoch 477, CIFAR-10 Batch 4:  Loss:     0.8799 Validation Accuracy: 0.565600\n",
      "Epoch 477, CIFAR-10 Batch 5:  Loss:     0.8894 Validation Accuracy: 0.567800\n",
      "Epoch 478, CIFAR-10 Batch 1:  Loss:     0.8820 Validation Accuracy: 0.564400\n",
      "Epoch 478, CIFAR-10 Batch 2:  Loss:     0.9480 Validation Accuracy: 0.548200\n",
      "Epoch 478, CIFAR-10 Batch 3:  Loss:     0.9152 Validation Accuracy: 0.566400\n",
      "Epoch 478, CIFAR-10 Batch 4:  Loss:     0.8910 Validation Accuracy: 0.567600\n",
      "Epoch 478, CIFAR-10 Batch 5:  Loss:     0.9065 Validation Accuracy: 0.561200\n",
      "Epoch 479, CIFAR-10 Batch 1:  Loss:     0.8868 Validation Accuracy: 0.561800\n",
      "Epoch 479, CIFAR-10 Batch 2:  Loss:     0.9250 Validation Accuracy: 0.564400\n",
      "Epoch 479, CIFAR-10 Batch 3:  Loss:     0.9034 Validation Accuracy: 0.571000\n",
      "Epoch 479, CIFAR-10 Batch 4:  Loss:     0.8811 Validation Accuracy: 0.564600\n",
      "Epoch 479, CIFAR-10 Batch 5:  Loss:     0.9122 Validation Accuracy: 0.562600\n",
      "Epoch 480, CIFAR-10 Batch 1:  Loss:     0.8812 Validation Accuracy: 0.564400\n",
      "Epoch 480, CIFAR-10 Batch 2:  Loss:     0.9421 Validation Accuracy: 0.559600\n",
      "Epoch 480, CIFAR-10 Batch 3:  Loss:     0.9017 Validation Accuracy: 0.568000\n",
      "Epoch 480, CIFAR-10 Batch 4:  Loss:     0.8740 Validation Accuracy: 0.565600\n",
      "Epoch 480, CIFAR-10 Batch 5:  Loss:     0.8901 Validation Accuracy: 0.564400\n",
      "Epoch 481, CIFAR-10 Batch 1:  Loss:     0.8845 Validation Accuracy: 0.568400\n",
      "Epoch 481, CIFAR-10 Batch 2:  Loss:     0.9371 Validation Accuracy: 0.564400\n",
      "Epoch 481, CIFAR-10 Batch 3:  Loss:     0.8893 Validation Accuracy: 0.572800\n",
      "Epoch 481, CIFAR-10 Batch 4:  Loss:     0.8681 Validation Accuracy: 0.567600\n",
      "Epoch 481, CIFAR-10 Batch 5:  Loss:     0.8911 Validation Accuracy: 0.567000\n",
      "Epoch 482, CIFAR-10 Batch 1:  Loss:     0.8801 Validation Accuracy: 0.573800\n",
      "Epoch 482, CIFAR-10 Batch 2:  Loss:     0.9280 Validation Accuracy: 0.566200\n",
      "Epoch 482, CIFAR-10 Batch 3:  Loss:     0.8902 Validation Accuracy: 0.573000\n",
      "Epoch 482, CIFAR-10 Batch 4:  Loss:     0.8706 Validation Accuracy: 0.565200\n",
      "Epoch 482, CIFAR-10 Batch 5:  Loss:     0.8904 Validation Accuracy: 0.568600\n",
      "Epoch 483, CIFAR-10 Batch 1:  Loss:     0.8819 Validation Accuracy: 0.571800\n",
      "Epoch 483, CIFAR-10 Batch 2:  Loss:     0.9234 Validation Accuracy: 0.566600\n",
      "Epoch 483, CIFAR-10 Batch 3:  Loss:     0.8936 Validation Accuracy: 0.571000\n",
      "Epoch 483, CIFAR-10 Batch 4:  Loss:     0.8752 Validation Accuracy: 0.567400\n",
      "Epoch 483, CIFAR-10 Batch 5:  Loss:     0.8814 Validation Accuracy: 0.570800\n",
      "Epoch 484, CIFAR-10 Batch 1:  Loss:     0.8824 Validation Accuracy: 0.569800\n",
      "Epoch 484, CIFAR-10 Batch 2:  Loss:     0.9374 Validation Accuracy: 0.554400\n",
      "Epoch 484, CIFAR-10 Batch 3:  Loss:     0.8987 Validation Accuracy: 0.564800\n",
      "Epoch 484, CIFAR-10 Batch 4:  Loss:     0.8718 Validation Accuracy: 0.569600\n",
      "Epoch 484, CIFAR-10 Batch 5:  Loss:     0.8810 Validation Accuracy: 0.573800\n",
      "Epoch 485, CIFAR-10 Batch 1:  Loss:     0.8719 Validation Accuracy: 0.571800\n",
      "Epoch 485, CIFAR-10 Batch 2:  Loss:     0.9191 Validation Accuracy: 0.567200\n",
      "Epoch 485, CIFAR-10 Batch 3:  Loss:     0.8857 Validation Accuracy: 0.573200\n",
      "Epoch 485, CIFAR-10 Batch 4:  Loss:     0.8771 Validation Accuracy: 0.565600\n",
      "Epoch 485, CIFAR-10 Batch 5:  Loss:     0.8917 Validation Accuracy: 0.572400\n",
      "Epoch 486, CIFAR-10 Batch 1:  Loss:     0.8731 Validation Accuracy: 0.572600\n",
      "Epoch 486, CIFAR-10 Batch 2:  Loss:     0.9171 Validation Accuracy: 0.565600\n",
      "Epoch 486, CIFAR-10 Batch 3:  Loss:     0.8864 Validation Accuracy: 0.573600\n",
      "Epoch 486, CIFAR-10 Batch 4:  Loss:     0.8760 Validation Accuracy: 0.565800\n",
      "Epoch 486, CIFAR-10 Batch 5:  Loss:     0.8812 Validation Accuracy: 0.572800\n",
      "Epoch 487, CIFAR-10 Batch 1:  Loss:     0.8723 Validation Accuracy: 0.568600\n",
      "Epoch 487, CIFAR-10 Batch 2:  Loss:     0.9258 Validation Accuracy: 0.561400\n",
      "Epoch 487, CIFAR-10 Batch 3:  Loss:     0.8866 Validation Accuracy: 0.572800\n",
      "Epoch 487, CIFAR-10 Batch 4:  Loss:     0.8737 Validation Accuracy: 0.567800\n",
      "Epoch 487, CIFAR-10 Batch 5:  Loss:     0.8853 Validation Accuracy: 0.574600\n",
      "Epoch 488, CIFAR-10 Batch 1:  Loss:     0.8780 Validation Accuracy: 0.573600\n",
      "Epoch 488, CIFAR-10 Batch 2:  Loss:     0.9194 Validation Accuracy: 0.564600\n",
      "Epoch 488, CIFAR-10 Batch 3:  Loss:     0.8869 Validation Accuracy: 0.574000\n",
      "Epoch 488, CIFAR-10 Batch 4:  Loss:     0.8702 Validation Accuracy: 0.565600\n",
      "Epoch 488, CIFAR-10 Batch 5:  Loss:     0.8790 Validation Accuracy: 0.575000\n",
      "Epoch 489, CIFAR-10 Batch 1:  Loss:     0.8816 Validation Accuracy: 0.568000\n",
      "Epoch 489, CIFAR-10 Batch 2:  Loss:     0.9359 Validation Accuracy: 0.552800\n",
      "Epoch 489, CIFAR-10 Batch 3:  Loss:     0.8878 Validation Accuracy: 0.571200\n",
      "Epoch 489, CIFAR-10 Batch 4:  Loss:     0.8763 Validation Accuracy: 0.566800\n",
      "Epoch 489, CIFAR-10 Batch 5:  Loss:     0.8864 Validation Accuracy: 0.569200\n",
      "Epoch 490, CIFAR-10 Batch 1:  Loss:     0.8715 Validation Accuracy: 0.563800\n",
      "Epoch 490, CIFAR-10 Batch 2:  Loss:     0.9275 Validation Accuracy: 0.558200\n",
      "Epoch 490, CIFAR-10 Batch 3:  Loss:     0.8848 Validation Accuracy: 0.570800\n",
      "Epoch 490, CIFAR-10 Batch 4:  Loss:     0.8793 Validation Accuracy: 0.568000\n",
      "Epoch 490, CIFAR-10 Batch 5:  Loss:     0.8867 Validation Accuracy: 0.572400\n",
      "Epoch 491, CIFAR-10 Batch 1:  Loss:     0.8693 Validation Accuracy: 0.566600\n",
      "Epoch 491, CIFAR-10 Batch 2:  Loss:     0.9382 Validation Accuracy: 0.554400\n",
      "Epoch 491, CIFAR-10 Batch 3:  Loss:     0.8865 Validation Accuracy: 0.570600\n",
      "Epoch 491, CIFAR-10 Batch 4:  Loss:     0.8735 Validation Accuracy: 0.573800\n",
      "Epoch 491, CIFAR-10 Batch 5:  Loss:     0.8783 Validation Accuracy: 0.568200\n",
      "Epoch 492, CIFAR-10 Batch 1:  Loss:     0.8723 Validation Accuracy: 0.563800\n",
      "Epoch 492, CIFAR-10 Batch 2:  Loss:     0.9397 Validation Accuracy: 0.552200\n",
      "Epoch 492, CIFAR-10 Batch 3:  Loss:     0.8817 Validation Accuracy: 0.574400\n",
      "Epoch 492, CIFAR-10 Batch 4:  Loss:     0.9052 Validation Accuracy: 0.563000\n",
      "Epoch 492, CIFAR-10 Batch 5:  Loss:     0.8914 Validation Accuracy: 0.565800\n",
      "Epoch 493, CIFAR-10 Batch 1:  Loss:     0.8717 Validation Accuracy: 0.563600\n",
      "Epoch 493, CIFAR-10 Batch 2:  Loss:     0.9224 Validation Accuracy: 0.559600\n",
      "Epoch 493, CIFAR-10 Batch 3:  Loss:     0.9043 Validation Accuracy: 0.572000\n",
      "Epoch 493, CIFAR-10 Batch 4:  Loss:     0.8905 Validation Accuracy: 0.567200\n",
      "Epoch 493, CIFAR-10 Batch 5:  Loss:     0.9214 Validation Accuracy: 0.560000\n",
      "Epoch 494, CIFAR-10 Batch 1:  Loss:     0.8743 Validation Accuracy: 0.563800\n",
      "Epoch 494, CIFAR-10 Batch 2:  Loss:     0.9458 Validation Accuracy: 0.559200\n",
      "Epoch 494, CIFAR-10 Batch 3:  Loss:     0.8908 Validation Accuracy: 0.575800\n",
      "Epoch 494, CIFAR-10 Batch 4:  Loss:     0.8868 Validation Accuracy: 0.556400\n",
      "Epoch 494, CIFAR-10 Batch 5:  Loss:     0.8939 Validation Accuracy: 0.564600\n",
      "Epoch 495, CIFAR-10 Batch 1:  Loss:     0.9117 Validation Accuracy: 0.558800\n",
      "Epoch 495, CIFAR-10 Batch 2:  Loss:     0.9458 Validation Accuracy: 0.555000\n",
      "Epoch 495, CIFAR-10 Batch 3:  Loss:     0.8968 Validation Accuracy: 0.565800\n",
      "Epoch 495, CIFAR-10 Batch 4:  Loss:     0.9098 Validation Accuracy: 0.560000\n",
      "Epoch 495, CIFAR-10 Batch 5:  Loss:     0.8810 Validation Accuracy: 0.568800\n",
      "Epoch 496, CIFAR-10 Batch 1:  Loss:     0.9054 Validation Accuracy: 0.551200\n",
      "Epoch 496, CIFAR-10 Batch 2:  Loss:     0.9314 Validation Accuracy: 0.563600\n",
      "Epoch 496, CIFAR-10 Batch 3:  Loss:     0.9296 Validation Accuracy: 0.552800\n",
      "Epoch 496, CIFAR-10 Batch 4:  Loss:     0.9004 Validation Accuracy: 0.560600\n",
      "Epoch 496, CIFAR-10 Batch 5:  Loss:     0.9251 Validation Accuracy: 0.546200\n",
      "Epoch 497, CIFAR-10 Batch 1:  Loss:     0.8767 Validation Accuracy: 0.570400\n",
      "Epoch 497, CIFAR-10 Batch 2:  Loss:     0.9313 Validation Accuracy: 0.571400\n",
      "Epoch 497, CIFAR-10 Batch 3:  Loss:     0.8983 Validation Accuracy: 0.565200\n",
      "Epoch 497, CIFAR-10 Batch 4:  Loss:     0.9089 Validation Accuracy: 0.556600\n",
      "Epoch 497, CIFAR-10 Batch 5:  Loss:     0.9017 Validation Accuracy: 0.564600\n",
      "Epoch 498, CIFAR-10 Batch 1:  Loss:     0.9056 Validation Accuracy: 0.562600\n",
      "Epoch 498, CIFAR-10 Batch 2:  Loss:     0.9153 Validation Accuracy: 0.571800\n",
      "Epoch 498, CIFAR-10 Batch 3:  Loss:     0.8956 Validation Accuracy: 0.565600\n",
      "Epoch 498, CIFAR-10 Batch 4:  Loss:     0.8866 Validation Accuracy: 0.565200\n",
      "Epoch 498, CIFAR-10 Batch 5:  Loss:     0.8965 Validation Accuracy: 0.557200\n",
      "Epoch 499, CIFAR-10 Batch 1:  Loss:     0.9005 Validation Accuracy: 0.562800\n",
      "Epoch 499, CIFAR-10 Batch 2:  Loss:     0.9223 Validation Accuracy: 0.570400\n",
      "Epoch 499, CIFAR-10 Batch 3:  Loss:     0.9056 Validation Accuracy: 0.566400\n",
      "Epoch 499, CIFAR-10 Batch 4:  Loss:     0.8652 Validation Accuracy: 0.571200\n",
      "Epoch 499, CIFAR-10 Batch 5:  Loss:     0.8870 Validation Accuracy: 0.560400\n",
      "Epoch 500, CIFAR-10 Batch 1:  Loss:     0.8792 Validation Accuracy: 0.566800\n",
      "Epoch 500, CIFAR-10 Batch 2:  Loss:     0.9209 Validation Accuracy: 0.570000\n",
      "Epoch 500, CIFAR-10 Batch 3:  Loss:     0.9084 Validation Accuracy: 0.564200\n",
      "Epoch 500, CIFAR-10 Batch 4:  Loss:     0.8687 Validation Accuracy: 0.571800\n",
      "Epoch 500, CIFAR-10 Batch 5:  Loss:     0.8994 Validation Accuracy: 0.554000\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "save_model_path = './image_classification'\n",
    "\n",
    "print('Training...')\n",
    "with tf.Session() as sess:\n",
    "    # Initializing the variables\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    # Training cycle\n",
    "    for epoch in range(epochs):\n",
    "        # Loop over all batches\n",
    "        n_batches = 5\n",
    "        for batch_i in range(1, n_batches + 1):\n",
    "            for batch_features, batch_labels in helper.load_preprocess_training_batch(batch_i, batch_size):\n",
    "                train_neural_network(sess, optimizer, keep_probability, batch_features, batch_labels)\n",
    "            print('Epoch {:>2}, CIFAR-10 Batch {}:  '.format(epoch + 1, batch_i), end='')\n",
    "            print_stats(sess, batch_features, batch_labels, cost, accuracy)\n",
    "            \n",
    "    # Save Model\n",
    "    saver = tf.train.Saver()\n",
    "    save_path = saver.save(sess, save_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Checkpoint\n",
    "The model has been saved to disk.\n",
    "## Test Model\n",
    "Test your model against the test dataset.  This will be your final accuracy. You should have an accuracy greater than 50%. If you don't, keep tweaking the model architecture and parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Accuracy: 0.5579657554626465\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAscAAAJ/CAYAAACUb342AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nxyIiIiIiiSbHIiIiIiLJ/weJ37riZSerKAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f8ed6b44198>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 319,
       "width": 355
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import tensorflow as tf\n",
    "import pickle\n",
    "import helper\n",
    "import random\n",
    "\n",
    "# Set batch size if not already set\n",
    "try:\n",
    "    if batch_size:\n",
    "        pass\n",
    "except NameError:\n",
    "    batch_size = 64\n",
    "\n",
    "save_model_path = './image_classification'\n",
    "n_samples = 4\n",
    "top_n_predictions = 3\n",
    "\n",
    "def test_model():\n",
    "    \"\"\"\n",
    "    Test the saved model against the test dataset\n",
    "    \"\"\"\n",
    "\n",
    "    test_features, test_labels = pickle.load(open('preprocess_test.p', mode='rb'))\n",
    "    loaded_graph = tf.Graph()\n",
    "\n",
    "    with tf.Session(graph=loaded_graph) as sess:\n",
    "        # Load model\n",
    "        loader = tf.train.import_meta_graph(save_model_path + '.meta')\n",
    "        loader.restore(sess, save_model_path)\n",
    "\n",
    "        # Get Tensors from loaded model\n",
    "        loaded_x = loaded_graph.get_tensor_by_name('x:0')\n",
    "        loaded_y = loaded_graph.get_tensor_by_name('y:0')\n",
    "        loaded_keep_prob = loaded_graph.get_tensor_by_name('keep_prob:0')\n",
    "        loaded_logits = loaded_graph.get_tensor_by_name('logits:0')\n",
    "        loaded_acc = loaded_graph.get_tensor_by_name('accuracy:0')\n",
    "        \n",
    "        # Get accuracy in batches for memory limitations\n",
    "        test_batch_acc_total = 0\n",
    "        test_batch_count = 0\n",
    "        \n",
    "        for test_feature_batch, test_label_batch in helper.batch_features_labels(test_features, test_labels, batch_size):\n",
    "            test_batch_acc_total += sess.run(\n",
    "                loaded_acc,\n",
    "                feed_dict={loaded_x: test_feature_batch, loaded_y: test_label_batch, loaded_keep_prob: 1.0})\n",
    "            test_batch_count += 1\n",
    "\n",
    "        print('Testing Accuracy: {}\\n'.format(test_batch_acc_total/test_batch_count))\n",
    "\n",
    "        # Print Random Samples\n",
    "        random_test_features, random_test_labels = tuple(zip(*random.sample(list(zip(test_features, test_labels)), n_samples)))\n",
    "        random_test_predictions = sess.run(\n",
    "            tf.nn.top_k(tf.nn.softmax(loaded_logits), top_n_predictions),\n",
    "            feed_dict={loaded_x: random_test_features, loaded_y: random_test_labels, loaded_keep_prob: 1.0})\n",
    "        helper.display_image_predictions(random_test_features, random_test_labels, random_test_predictions)\n",
    "\n",
    "\n",
    "test_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Why 50-80% Accuracy?\n",
    "You might be wondering why you can't get an accuracy any higher. First things first, 50% isn't bad for a simple CNN.  Pure guessing would get you 10% accuracy. However, you might notice people are getting scores [well above 80%](http://rodrigob.github.io/are_we_there_yet/build/classification_datasets_results.html#43494641522d3130).  That's because we haven't taught you all there is to know about neural networks. We still need to cover a few more techniques.\n",
    "## Submitting This Project\n",
    "When submitting this project, make sure to run all the cells before saving the notebook.  Save the notebook file as \"dlnd_image_classification.ipynb\" and save it as a HTML file under \"File\" -> \"Download as\".  Include the \"helper.py\" and \"problem_unittests.py\" files in your submission."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
